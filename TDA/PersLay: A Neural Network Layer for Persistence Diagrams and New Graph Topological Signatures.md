# PersLay: A Neural Network Layer for Persistence Diagrams and New Graph Topological Signatures

**주요 주장 및 기여:**  
이 논문은 그래프 데이터를 위한 새로운 **확장 지속성 다이어그램**(extended persistence diagrams)과, 이를 신경망에 통합할 수 있는 범용 레이어 **PersLay**를 제안한다. 확장 지속성 다이어그램은 히트 커널 서명(Heat Kernel Signature, HKS)을 기반으로 그래프의 위상학적 특성을 안정적으로 캡처하며, PersLay는 이러한 다이어그램을 **자동 미분 가능**한 방식으로 벡터화하여 기계 학습 모델에 직접 학습시키는 프레임워크를 제공한다.[1]

***

## 1. 해결하고자 하는 문제  
- **비유클리드 공간**인 지속성 다이어그램을 머신러닝 입력으로 활용하기 어려움.  
- 기존 벡터화 기법(유한 차원 임베딩, 커널)은 **학습 가능한 매개변수 부족**, **메모리 및 계산 비용** 문제를 가짐.  
- 그래프 위상 정보(연결 요소, 루프 등)를 포괄적으로 인코딩하고, 작업(task)에 맞춰 벡터화를 **학습**할 필요성.

***

## 2. 제안 방법  
### 2.1 확장 지속성 다이어그램  
- 그래프의 노드 함수로 HKS $$hks_{G,t}(v) = \sum_{k=1}^n e^{-t\lambda_k} \varphi_k(v)^2$$ 정의.  
- **서브레벨** 및 **슈퍼레벨** 필터링으로 4가지 위상 특징(Ord0, Rel1, Ext0, Ext1)을 캡처.  
- 이론적으로 **입력 그래프** 및 **파라미터 $$t$$** 변화에 대해 **Lipschitz 안정성** 보장:  

$$d_B(Dg(G,t),Dg(G',t)) \le C\,\|L_G - L_{G'}\|_F,\quad d_B(Dg(G,t),Dg(G,t')) \le 2|t-t'|$$ [1].

### 2.2 PersLay 레이어  
- 지속성 다이어그램 $$D$$를 벡터화하는 일반식:  

```math
\mathrm{PersLay}(D) = \mathrm{op}\bigl\{w(p)\,\phi(p)\mid p\in D\bigr\},
```
  
  where  
  -  $$\mathrm{op}$$: sum, max, k-th largest 등 **순열 불변 연산**  
  -  $$w: \mathbb{R}^2\to\mathbb{R}$$: 학습 가능한 **가중치 함수**  
  -  $$\phi: \mathbb{R}^2\to\mathbb{R}^q$$: 점 변환(point transformation), 예) 삼각 함수, 가우시안, 선형 투영  
- 이 구조는 기존 벡터화 기법(지속성 랜드스케이프, 실루엣, 표면, 스liced Wasserstein 등)을 **특수 사례**로 포함하며, 매개변수 $$\phi, w$$를 **end-to-end 학습** 가능.

***

## 3. 모델 구조  
- **단일 레이어**: PersLay로 다이어그램 처리 → 정규화 → 완전연결층으로 예측.  
- **그래프 분류**: 그래프마다 HKS 확장 다이어그램 생성(여러 $$t$$ 샘플) → 각 유형별(Ord0, Rel1, Ext0, Ext1) PersLay 인스턴스 적용 → 결과 벡터 결합 → 분류기.[1]

***

## 4. 성능 및 한계  
- **합성 궤도 분류**(ORBIT5K, ORBIT100K):  
  -  ORBIT5K: 87.7% (기존 최대 85.9%)  
  -  ORBIT100K: 89.2% (대규모에서의 확장성 입증)  
- **그래프 분류**(REDDIT5K 등 10개 데이터셋):  
  -  대부분 기존 그래프 신경망 및 커널 방법과 **비교 가능** 또는 우수한 정확도  
  -  NCI 데이터셋에서는 위상 정보가 비판별적임 관측  
- **한계**:  
  -  HKS 파라미터 $$t$$ 최적화 시 다이어그램 재계산 비용으로 **학습 시간 증가**  
  -  매우 큰 다이어그램 및 고차원 $$q$$에 대한 **메모리 부담** 가능

***

## 5. 일반화 성능 향상 가능성  
- **학습 가능한 가중치 함수** $$w$$가 다이어그램의 중요한 점을 강조하여 **과적합 방지** 및 **특성 추출 적응성** 제공.  
- **여러 $$t$$ 샘플**을 통해 다양한 스케일의 위상 구조 학습, **다중 스케일 일반화** 가능.  
- PersLay는 **다른 네트워크 아키텍처**(CNN, GNN 등)와 결합하여 **하이브리드 모델**로 확장 가능, 다양한 도메인에 일반화 잠재력 높음.

***

## 6. 향후 연구 영향 및 고려 사항  
- **영향**: PersLay는 TDA(Topological Data Analysis)를 딥러닝 파이프라인에 통합하는 **표준 툴**로 자리매김할 수 있음.  
- **고려점**:  
  -  **파라미터 $$t$$** 및 $$\phi$$ 종류 선택은 작업별 **교차 검증** 또는 **메타러닝** 필요  
  -  대규모, 고차원 데이터에서의 **효율적 구현**(GPU 가속, 근사 알고리즘) 연구  
  -  **응용 분야**(의료 영상, 분자 그래프, 사회 네트워크 등)별 위상 특징 중요도 분석  

PersLay는 위상 특징의 학습 가능성이 결합된 강력한 프레임워크로, 향후 다양한 머신러닝 과제에 **새로운 차원의 일반화 성능**을 제공할 전망이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/789a28ed-747b-4aaa-8d22-c12cdce37019/PersLay-A-Neural-Network-Layer-for-Persistence-Diagrams-and-New-Graph-Topological-Signatures.pdf)
