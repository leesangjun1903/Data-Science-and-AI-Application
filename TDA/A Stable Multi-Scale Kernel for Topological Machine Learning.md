# A Stable Multi-Scale Kernel for Topological Machine Learning

**핵심 요약 (한눈에 보기)**  
- **문제**: 그래프나 이미지 같은 데이터에서 토폴로지(형태) 특징을 요약한 ‘퍼시스턴스 다이어그램’을 머신러닝에 바로 쓸 수 없음  
- **해결책**: 퍼시스턴스 다이어그램을 연속적인 함수 공간(L² 공간)에 매핑(mapping)하는 *스케일-스페이스 커널* kₛₙ을 정의  
- **주요 장점**  
  1. **양의 정부호(positive definite)**: 커널 기법(SVM, PCA 등)에 바로 적용 가능  
  2. **안정성(stability)**: 데이터 변화에 비례해 커널 값이 크게 흔들리지 않음  
  3. **노이즈 강인성(noise robustness)**: 스케일 σ로 작은(노이즈) 특징을 약하게, 큰(주요) 특징을 강하게 반영  

## 1. 연구 배경과 목표  

### 1.1 토폴로지와 퍼시스턴스 다이어그램  
- **토폴로지(topology)**: 도형이나 공간의 모양을 변형해도(늘리거나 구부려도) 변하지 않는 성질(예: 구멍의 개수) 연구  
- **퍼시스턴스 다이어그램(persistence diagram)**: 데이터의 토폴로지 변화를 시간 축(또는 필터 값) 따라 기록  
  - 각 점 (b, d)는 어떤 위상 특징(구멍 등)이 ‘생기기(birth)’ 시작한 값 b와 ‘사라지기(death)’ 끝난 값 d을 의미  
  - 점이 대각선( b = d )에 가까울수록 ‘짧게’ 나타난(노이즈) 특징, 멀수록 ‘오래’ 유지된(주요) 특징  

### 1.2 커널 기법이 필요한 이유  
- SVM, 커널 PCA 등은 데이터를 **히르베르트 공간(Hilbert space)**에 임베딩해야 작동  
- 퍼시스턴스 다이어그램은 거리만 정의된 **메트릭 공간(metric space)**이어서 직접 쓸 수 없음  

**목표**  
퍼시스턴스 다이어그램을 함수(신호)로 바꾸어 히르베르트 공간 구조를 부여하고, 이 함수를 이용해 커널을 정의하자.

## 2. 제안된 방법: 스케일-스페이스 커널 kₛₙ  

### 2.1 아이디어: 히트 디퓨전(heat diffusion)  
1. 퍼시스턴스 다이어그램 D의 각 점 p를 **디락 델타(Dirac delta)** 함수로 표현  
   - $δₚ(x) = x = p$ 일 때 무한대, 그 외 0 (점 형태 신호)  
2. 이 신호를 열전달 방정식(heat equation)에 초기값(initial condition)으로 넣고 확산(diffusion)시킴  
   - 열전달 방정식: $∂u/∂t = Δu $ 
   - 경계조건: 대각선 위에서 값이 0 (Dirichlet boundary) → 대각선 근처 노이즈 억제  
3. 시간 t = σ(스케일)에서의 해 u(x, σ)를 **특징 맵 Φₛₙ(D)**로 사용  
4. 두 다이어그램 F, G의 커널 값은  
   kₛₙ(F, G) = ⟨Φₛₙ(F), Φₛₙ(G)⟩ₗ₂  (L² 내부(inner) 곱)

### 2.2 닫힌 형태 공식 (계산 효율성)  
계산 복잡도를 O(|F|·|G|)로 줄이기 위해 유도된 식  

```math
k_\sigma(F,G)
=\frac{1}{8\pi\sigma}\sum_{p\in F}\sum_{q\in G}
\bigl(e^{-\frac{\|p-q\|^2}{8\sigma}}
- e^{-\frac{\|p-\bar q\|^2}{8\sigma}}\bigr),
```

- $$\bar q$$: 점 q를 대각선에 대칭 이동한 좌표  
- 첫 항: 원 신호 간 유사도, 둘째 항: 대각선 반영 노이즈 보정  

## 3. 주요 성질  

### 3.1 양의 정부호성 (Positive Definiteness)  
- 커널이 **히르베르트 공간의 내적**이므로, **SVM**, **커널 PCA** 등 커널 기법에 바로 사용 가능  

### 3.2 안정성 (Stability)  
- **1-워서스타인 거리** $$d_{W,1}$$에 대해 Lipschitz 연속  

$$
  \|\Phi_\sigma(F) - \Phi_\sigma(G)\|\_{L^2}
  \;\le\;\frac1{\sigma\sqrt{8\pi}}\,d_{W,1}(F,G).
$$

- **Lipschitz 연속(Lipschitz continuity)**: 두 입력 거리가 Δ라면, 출력 거리가 C·Δ 이내로만 변함 → 과적합 감소  

### 3.3 노이즈 강인성 (Noise Robustness)  
- 스케일 σ 증가 → 짧은 지속(노이즈) 점 기여 지수 함수로 급감 → 실제 특징만 강조  

## 4. 어려운 용어 정리  

| 용어                | 설명                                                                                             |
|---------------------|--------------------------------------------------------------------------------------------------|
| 디락 델타/Dirac delta | “무한히 좁고 높은” 점 신호. 적분 시 해당 점을 샘플링하는 역할.                                     |
| 히르베르트 공간      | 내적(inner product)이 정의된 완비된(Banach) 벡터 공간. 거리·각도 등 기하학적 해석 가능.             |
| 워서스타인 거리     | 두 퍼시스턴스 다이어그램 점 모음을 최적으로 매칭(matching)했을 때 이동 비용의 총합(또는 평균).        |
| Lipschitz 연속      | 입력이 Δ만큼 바뀌면 출력이 C⋅Δ 이내로만 바뀜을 보장. 모델 안정성과 일반화 성능 향상.               |


L² 공간       | 함수 x↦u(x) 에서 $\int|u(x)|^2 dx$ 가 유한한 함수들의 공간. 신호 에너지 측정에 적합.         

## 5. 요약 및 전망  

- **요약**: 토폴로지 정보인 퍼시스턴스 다이어그램을 L² 함수로 바꿔 커널을 만든 뒤, 커널 기법에 적용하여 안정적·효율적 특징 추출  
- **영향**: 다양한 도메인(이미지, 3D 형태, 시계열)에서 토폴로지 기반 머신러닝 확장 기대  
- **앞으로 고려할 점**  
  1. **계산 효율화**: 대규모 데이터에서 빠른 근사 기법 필요  
  2. **자동 σ 선택**: 데이터별 최적 스케일 자동화  
  3. **p>1 워서스타인 안정성**: 이론적 확장도 흥미로운 연구 과제  

이 커널은 토폴로지 특징을 “모든 커널 기법”에 쉽게 통합하도록 해 주며, 데이터의 형태 정보를 안정적으로 학습에 활용할 수 있게 해 줍니다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/6b52e0a7-3cc9-4ba6-9a9d-260278dae518/1412.6821v1.pdf

**핵심 주장**  
제안된 다중 스케일 커널 $$k_\sigma$$는 퍼시스턴스 다이어그램의 1-워서스타인 거리($$d_{W,1}$$)에 대해 리프시츠 연속성을 유지하며, 스케일 파라미터 $$\sigma$$로 노이즈에 대한 강인성을 조절할 수 있는 이론적·실용적 커널이다[1].

## 1. 해결하고자 하는 문제  
퍼시스턴스 다이어그램은 토폴로지 특징의 안정적 요약이나 메트릭 구조($$d_{W,p}$$)를 제공하지만, 커널 기반 기계학습(SVM, 커널 PCA 등)에 바로 적용할 수 있는 힐베르트 공간 구조를 갖지 못한다. 기존 접근(워서스타인 거리 기반, 퍼시스턴스 랜드스케이프 등)은  
1) **커널 양정(positive definiteness)** 혹은  
2) **안정성(stability)**  
중 하나를 보장하지 못하거나, 하이퍼파라미터 조정이 까다롭다.

## 2. 제안 방법  

### 2.1. 퍼시스턴스 스케일-스페이스 커널 정의  
퍼시스턴스 다이어그램 $$D\subset\{(b,d)\in\mathbb R^2:d\ge b\}$$를 디락 델타 분포의 합으로 보고, 이들을 초기 조건으로 하는 열 방정식(heat diffusion)에 디리클레 경계($$x_2=x_1$$)를 부과해 다음을 푼다:

```math
\begin{cases}
\partial_t u(x,t) = \Delta_x u(x,t), & x_2\ge x_1,\ t>0,\\
u|_{t=0}=\sum_{p\in D}\delta_p,\quad u|_{x_2=x_1}=0.
\end{cases}
```

스케일 $$\sigma>0$$에서의 해 $$u(x,\sigma)=\Phi_\sigma(D)(x)\in L^2$$를 피처 맵으로 정의하고,  

$$
k_\sigma(F,G)=\langle \Phi_\sigma(F),\,\Phi_\sigma(G)\rangle_{L^2}
$$

로 커널을 정의한다.  

### 2.2. 닫힌형식(formula)  

$$
k_\sigma(F,G)
=\frac{1}{8\pi\sigma}\sum_{p\in F}\sum_{q\in G}
\Bigl(e^{-\frac{\|p-q\|^2}{8\sigma}}-e^{-\frac{\|p-\bar q\|^2}{8\sigma}}\Bigr),
$$

여기서 $$\bar q$$는 대각선 미러링된 점이다[1].

## 3. 이론적 성질  

1. **양의 준정부호성(Positive Definiteness)**  
   $$\Phi_\sigma$$가 $$L^2$$로 사상되므로 $$k_\sigma$$는 명백히 p.d. 커널이다.  

2. **1-워서스타인 안정성**  

$$
   \|\Phi_\sigma(F)-\Phi_\sigma(G)\|\_{L^2}\le 
   \frac{1}{\sigma\sqrt{8\pi}}\,d_{W,1}(F,G).
  $$

   즉, $$d_{k_\sigma}(F,G)\le C\cdot d_{W,1}(F,G)$$로 안정적이다[1].  

3. **스케일 파라미터 효과**  
   $$\sigma$$ 증가 시 작은(노이즈성) 퍼시스턴스 점들의 기여가 급격히 감소하여 노이즈 강인성을 조절할 수 있다.

## 4. 모델 구조 및 구현  
- 입력: 함수 $$f$$의 퍼시스턴스 다이어그램(예: 이미지, 메쉬, 점군)  
- 피처 추출: 위의 스케일-스페이스 해를 $$L^2$$ 함수로 맵핑  
- 커널 SVM/C–PCA: $$k_\sigma$$ 사용, 하이퍼파라미터 $$\sigma$$, SVM의 $$C$$ 교차검증으로 최적화  

## 5. 성능 향상 및 한계  

| 과제               | 비교군            | 성능 향상                                        |
|--------------------|-------------------|--------------------------------------------------|
| 3D 형태 분류      | 퍼시스턴스 랜드스케이프 | 최대 35%↑ (HKS 파라미터별)[1]                     |
| 3D 형태 검색      | 랜드스케이프 커널 | NN 정확도 77%→95% (스케일 최적화)[1]              |
| 텍스처 분류       | CLBP-χ² 히스토그램 | 순수 토폴로지: 58%→69% (CLBP-S)[1]; 단독으로는 미흡 |

**한계**  
- 대용량 데이터에서 $$O(|F|\cdot|G|)$$ 계산 비용 부담  
- $$p>1$$ 워서스타인 거리 안정성 미확보  
- 순수 토폴로지만으로는 일부 과제에서 전통적 특징 대비 성능 열위  

## 6. 일반화 성능 향상 관점  
- **노이즈 강인성**: $$\sigma$$ 조정으로 학습 시점에 노이즈 대비 범용성 확보  
- **안정적 피처 맵**: 워서스타인 거리 기반 변화에 민감도 제한 → 과적합 감소  
- **다중 커널 학습(MKL)**: 전통 특징·토폴로지 특징 결합 시 상보적 성능 시너지  

## 7. 향후 연구 영향 및 고려사항  

- **대규모 스케일링**: 근사 기법(점 샘플링, 커널 압축)으로 계산량 최적화  
- **다변량·시계열 데이터**: 고차원 퍼시스턴스 다이어그램 적용 연구  
- **이론 확장**: $$p>1$$ 워서스타인 안정성, 최적 스케일 자동화 기법  
- **응용 확대**: 바이오이미징, 그래프 머신러닝, 딥러닝 통합 등 다양한 도메인과의 융합 연구 촉진  

이 커널은 토폴로지적 불변성·안정성을 보존하면서 커널 기반 기계학습 전반에 손쉽게 통합할 수 있어, 향후 토포로지 데이터 분석과 기계학습의 결합을 가속화할 것으로 기대된다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/6b52e0a7-3cc9-4ba6-9a9d-260278dae518/1412.6821v1.pdf
