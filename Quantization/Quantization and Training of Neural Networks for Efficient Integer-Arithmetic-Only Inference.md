# Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference

**Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference** 논문은 **모바일 및 임베디드 디바이스**에서 실시간 딥러닝 추론을 위해 32비트 부동소수점 연산을 8비트 정수 연산으로 완전히 대체하는 **정량화(quantization) 기법**과 이를 고려한 **공동 설계된 훈련(framework)**을 제안한다. 주요 기여는 다음과 같다:  
- **정량화 스킴**: 가중치(weights)와 활성화(activations)를 8비트 정수로, 바이어스(bias)만 32비트 정수로 표현하는 아핀 변환 $$r = S(q - Z)$$ 정의.  
- **정수 전용 추론 프레임워크**: Qualcomm Hexagon 및 ARM NEON 상에서 부동소수점 없이 정수만으로 효율적 구현.  
- **시뮬레이션 기반 정량화 훈련**: 순전파 단계에 “가짜 정량화(fake quantization)” 노드를 삽입해 양자화 오차를 최소화하며 최종 정확도 손실을 억제.  
- **모바일 네트워크 적용**: MobileNet 계열 모델에 적용하여 ImageNet 분류, COCO 물체 검출에서 **지연 시간(latency) 대비 정확도** 우수성 실증.  

# 문제 정의 및 제안 기법  
## 해결하고자 하는 문제  
기존 양자화 방식은  
1) **과도하게 파라미터화된** AlexNet/VGG/GoogLeNet만 대상  
2) 1·2비트 극단적 양자화는 기기 최적화 미흡 시 정확도 급감  
3) 실제 하드웨어 성능 개선 검증 부족  
  
→ **이미 효율적인 아키텍처(MobileNets)**를 8비트만으로 정수 추론할 수 있게 하여, 정확도 손실 없이 지연 시간을 대폭 단축  

## 제안 방법  
1. 정량화 스킴:  
   - 아핀 변환 $$r = S(q - Z)$$ (식 (1)), $$S$$: scale, $$Z$$: zero-point  
   - 8비트 $$q\in$$, 바이어스만 32비트 정수
2. 정수 전용 매트릭스 곱:  
   - 실수 행렬곱 $$r_3 = r_1 r_2$$를 정수값 $$q$$로 변환  
   - 핵심식  

$$
       q_3 = Z_3 + M\sum_j(q_{1j} - Z_1)(q_{2j} - Z_2),\quad M=\frac{S_1S_2}{S_3}
     $$  
   
   - $$M$$을 고정소수점으로 근사 후 시프트 연산으로 구현(식 (4)–(6))  
3. 제자리 연산 효율화:  
   - 제로 포인트 보정 및 바이어스 합산을 O($$N^2$$)로 최적화(식 (7)–(9))  
4. 정량화 훈련:  
   - 순전파에 “fake quant” 노드 삽입(식 (12))  
   - 가중치는 층별 최소값/최댓값, 활성화는 EMA로 동적 범위 학습  
   - 배치정규화 파라미터 사전 병합(folding) 후 양자화(식 (14))  

# 모델 구조 및 구현  
- 베이스: MobileNet(depth-wise + point-wise 분리 합성곱)  
- 연산 단위: uint8 입력·가중치 × int32 누적 → 바이어스(32bit) 더하고, 고정소수점 곱셈·시프트 후 ReLU6 클램프 → uint8 출력  
- ARM NEON 및 gemmlowp SIMD 활용 최적 커널 제공  

# 성능 평가 및 한계  
| 작업        | 모델               | 정확도 차이   | 지연 시간 개선        |  
|-----------|------------------|-------------|-----------------------|  
| ImageNet 분류 | MobileNet-1.0     | −0.3% 내외   | 최대 10% 단축         |  
| COCO 검출   | MobileNet SSD     | −0.4% 내외   | 최대 50% 단축         |  
| 얼굴 검출   | MobileNet SSD     | −2% 내외     | 최대 2× 단축          |  

- **정확도 손실**이 8비트 양자화 기준으로 $$<2\%$$ 수준으로 매우 작음  
- **지연 시간**은 하드웨어별(FP 최적화 정도) 차이가 있으나 일관된 감소 관측  
- **한계**: 덧셈·Concatenation 연산은 스케일 재조정 비용 발생, 모델 확장 시 비정수 연산 유닛이 병목될 수 있음  

# 일반화 성능 향상 관점  
- 양자화 훈련 시 **가짜 정량화**가 일종의 **노이즈 주입(regularization)** 효과를 가져와, 과적합을 억제하고 모델의 **강건성(robustness)**을 높일 가능성  
- ReLU6 클램프 범위 고정이 채널별 범위 편차를 줄여 **내재적 정규화** 효과  
- 실제 데이터 분포 변화에 대한 적응성, 도메인 전이(transfer) 시 일반화 성능 추가 검증 필요  

# 향후 연구 영향 및 고려 사항  
- **임베디드 비전**: 실시간 앱, AR/VR, IoT 디바이스에 32비트 연산 없이 고성능 추론 제공  
- **자동 양자화 범위 학습**: 활성화 범위 추정 자동화 및 적응형 클램핑 연구  
- **더 저비트 양자화**(4–6bit)와 정확도-지연 균형 탐색  
- **비전 외 영역**(NLP, 음성) 적용 시, 연산 패턴 차이에 따른 양자화 효과·일반화 고려  
- **하드웨어 공조 설계**: ASIC/내장형 프로세서에서 비트 시프트 및 고정소수점 유닛 최적화 방향 모색

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/c6792c60-e1d0-47da-9671-a00462eb651e/1712.05877v1.pdf)
