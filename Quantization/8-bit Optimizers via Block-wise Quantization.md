# 8-bit Optimizers via Block-wise Quantization

## 1. 핵심 주장 및 주요 기여  
이 논문은 **32비트 옵티마이저 상태(state)를 8비트로 줄이면서도 원래 성능을 유지**하는 방법을 제안한다.  
- 블록 단위로 텐서를 분할해 각 블록별로 독립적인 동적 양자화를 적용함으로써  
  1) 아웃라이어(outlier)에 의한 왜곡 최소화  
  2) 연산 효율성(코어 간 동기화 불필요)  
  3) 안정성 확보  
를 동시에 달성한다.  
- 추가로, **동적 양자화(dynamic quantization)**와 **안정적 임베딩 레이어(stable embedding layer)** 를 결합해 대규모 언어 모델(1.5B 파라미터)부터 이미지 분류, 기계 번역 등 다양한 과제에서 32비트 성능을 전혀 손상 없이 재현한다.  
- 구현이 간단해, 현존하는 코드에 단 두 줄만 수정하면 바로 사용할 수 있다.

## 2. 문제 정의 및 제안 기법

### 2.1 문제점  
일반적으로 Adam·Momentum 같은 상태 기반 옵티마이저는 과거 기울기를 지수적으로 누적 관리하며 학습 속도를 높이지만, 그 메모리 사용량이 모델 파라미터 크기 대비 33–75%에 달해 대형 모델 훈련을 제약한다.  

### 2.2 제안 방법  
1) 블록 단위 동적 양자화 (Block-wise Dynamic Quantization)  
   - 옵티마이저 상태 텐서를 크기 B=2048인 블록으로 분할  
   - 각 블록별 절댓값 최대치 $N_i = \max(|T_{block}|)$ 로 정규화  
   - 정규화된 값에 대해 8비트 동적 트리 양자화(dynamic tree quantization) 수행  
   - 비트 인덱스만 저장, 복원 시 인덱스→값→Ni 곱으로 신속하게 복원  
   수식:  

$$
     T^Q_{bi} = \underset{j\in}{\mathrm{argmin}}\Bigl|Q_{\text{map},j} - \tfrac{T_{bi}}{N_b}\Bigr|
   $$  

2) 동적 양자화 (Dynamic Quantization)  
   - 기존 동적 트리 양자화에서 사인(sign) 비트를 재활용하고, 부동소수점 분수(fraction) 비트를 고정해 큰 값과 작은 값 모두 정밀도 유지  

3) 안정적 임베딩 레이어 (Stable Embedding Layer)  
   - 임베딩 가중치는 Xavier 균등 초기화  
   - 위치 임베딩 추가 전 레이어 정규화(layer normalization) 적용  
   - 임베딩 레이어만 32비트 옵티마이저 상태 사용  
   → 희소 입력 분포로 인한 극단적 기울기 분산 완화  

### 2.3 모델 구조  
기존 모델(Transformer, ResNet 등)과 동일하며, 오직 옵티마이저 상태 표현과 임베딩 레이어만 위 세 구성요소로 교체·확장하여 사용한다.

## 3. 성능 평가 및 한계

### 3.1 주요 벤치마크 성능  
- GLUE, ImageNet, WMT’14 번역, RoBERTa·GPT3 언어 모델 등 전 과제에서 **32비트 옵티마이저와 동일한 평균 정확도·BLEU·퍼플렉서티**를 달성  
- 최대 8.5 GB GPU 메모리 절감, 훈련 속도 일부 향상  
- 배치 크기 1 기준, 6 GB GPU에서 RoBERTa-large(355M)→MT5-base(580M)까지 핀튜닝 가능  

### 3.2 일반화 성능 향상 가능성  
- 메모리 절감으로 **더 큰 배치 크기 또는 더 큰 모델** 사용이 가능해져 일반화 성능 개선 여지  
- 블록 단위로 아웃라이어를 격리해 양자화 오류를 균등 분산시키므로, 최적화가 안정적이고 **과적합 위험 감소**  
- 안정적 임베딩 층은 NLP 과제의 희소성·다양한 문맥 분포에 대한 **일관된 표현 학습**을 촉진  

### 3.3 한계  
- **합성곱 네트워크처럼 활성화 메모리가 큰 모델**에는 메모리 절감 효과 제한  
- 1B 파라미터 이상 모델에서 간헐적 “캐스케이딩 발산(cascading instability)” 현상 관찰  
- 극소수 파라미터 이상치가 훈련 불안정 초래 가능성, 아직 완전 해명되지 않음  

## 4. 향후 연구 방향 및 고려 사항  
- 아웃라이어 원인 규명 및 자동 완화 메커니즘 연구  
- 8비트 양자화와 **다른 메모리 절감 기법(예: 옵티마이저 셰어링, 체크포인팅)** 병용 전략  
- 더 낮은 비트(4비트 이하) 양자화 안정화 방안 탐색  
- 대규모 배치·분산 학습에서 블록 크기(B)·정규화 방식 최적화  
- 안정적 임베딩 레이어를 **다양한 희소 입력 과제**(지식 그래프, 추천 시스템)에 적용  

> **결론**: 블록 단위 동적 양자화는 대규모 모델의 메모리 병목을 해소하고, 일반화 성능을 희생 없이 유지·향상시킬 수 있는 **실용적이고 확장성 높은** 솔루션이다. 앞으로 대형 AI 시스템의 접근성과 효율성을 높이는 핵심 기술로 자리매김할 것으로 기대된다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/97b41bb2-b94f-4db9-95eb-ff40f1d070d3/2110.02861v2.pdf)
