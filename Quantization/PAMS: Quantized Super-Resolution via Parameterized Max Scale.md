# PAMS: Quantized Super-Resolution via Parameterized Max Scale

**핵심 주장 및 주요 기여**  
PAMS는 배치 정규화(BN) 없는 최신 SISR(super-resolution) 모델의 동적 범위 문제를 해결하기 위해, 활성화와 가중치를 저비트 양자화하면서도 성능 저하를 최소화하는 **Parameterized Max Scale (PAMS)** 기법을 제안한다.  
1. **동적 범위 적응형 클램핑**: 활성화 양자화 범위 상한을 학습 가능한 파라미터 α로 두어, 입력 분포에 맞춰 클램프 구간 [–α,α]를 자동 조정.  
2. **구조적 지식 전이(SK﻿T)**: 풀프리시전 네트워크의 고수준 특성 맵 구조를 양자화 네트워크에 전이함으로써, 픽셀 단위 특징 정합을 학습하도록 유도.  
3. EDSR/RDN 백본에서 8-bit 양자화 시 원본 대비 PSNR 손실이 0.0x dB 내외로 극히 적으며, 4-bit에서도 합리적 성능을 달성. 모델 크기는 최대 86%까지 압축.  

***

## 1. 해결 문제  
- **배치 정규화 제거로 인한 활성화 동적 범위 과다 변동**  
  - SR 모델(EDSR, RDN)에서는 BN 제거 후 활성화 값의 최대치가 샘플마다 크게 달라져, 고정 클램핑 범위 지정 시 성능 저하[그림 Fig. 2] 발생.  
- **저비트 양자화 시 범위 결정 어려움**  
  - 기존 방식(고정 max scale) 또는 PACT(양수 범위만 학습) 모두 음수 범위를 무시하거나 범위 결정에 한계.

***

## 2. 제안 방법  

### 2.1 양자화 함수  
모든 채널의 요소 x∈X를 대칭 모드로 n-bit 양자화:  

$$
Q(x,n)=\bigl\lfloor\,\tfrac{f(x)}{s(n)}\bigr\rceil\,s(n),
$$  

여기서  

$$
f(x)=\max\bigl(\min(x,\alpha),\,-\alpha\bigr),\quad
s(n)=\tfrac{\alpha}{2^{\,n-1}-1}.
$$  

### 2.2 학습 가능한 상한 α  
- 활성화마다 상·하한을 ±α로 두고, α를 SGD로 업데이트[식 (3)(4)].  
- 초기화는 EMA로 과거 배치의 최대값 통계 반영[식 (4)].  

### 2.3 구조적 지식 전이(SK﻿T)  
- 풀프리시전 교사 모델 T의 고수준 특성맵 $$F_T$$와 학생 모델 S의 $$F_S$$ 공간적 크기를 정규화 후 p-norm으로 정합:  

$$
\mathcal{L}_{\mathrm{SKT}}
=\Bigl\|\frac{F_S}{\|F_S\|_2}-\frac{F_T}{\|F_T\|_2}\Bigr\|_p.
$$  

### 2.4 전체 손실  

```math
\mathcal{L} = \lambda_p\,\mathcal{L}_{\mathrm{pixel}} 
+\lambda_s\,\mathcal{L}_{\mathrm{SKT}},
\quad \lambda_p=1,\;\lambda_s=10^3.
```

***

## 3. 모델 구조  
- **백본**: EDSR(잔차블록 기반) 및 RDN(잔차-밀집블록 기반)  
- **양자화 적용 영역**: 고수준 특성 추출기 내의 모든 합성곱 블록 가중치·활성화만 양자화.  
- 저수준 추출 및 재구성 모듈은 32-bit 유지하여 저성능 소실 최소화.  

***

## 4. 성능 향상 및 한계  

### 4.1 압축·정확도  
|모델|비트수(W/A)|압축률|BSD100 PSNR(dB)|  
|---|---|---|---|  
|EDSR (32-bit)|32/32|–|27.562|  
|PAMS-EDSR (8-bit)|8/8|58.4%|27.565|  
|PAMS-EDSR (4-bit)|4/4|68.1%|27.322|  
|RDN (32-bit)|32/32|–|27.627|  
|PAMS-RDN (8-bit)|8/8|73.9%|27.644|  
|PAMS-RDN (4-bit)|4/4|86.2%|26.869|  

- 8-bit 양자화 시 PSNR 손실 ≤0.01 dB, 4-bit 시 ≤0.24 dB로 **실질적 시각 품질 유지**[Table 1][Table 3].  
- PACT·Tensorflow Lite 대비 8-bit에서 최대 1.8 dB, 4-bit에서 0.5 dB 이상 우수[Table 2].  

### 4.2 일반화 성능  
- **α 학습 효과**: 층별 α 값이 서로 다른 수렴 경향을 보이며, 고정 스케일 대비 **범위 최적화로 양자화 오차 최소화**[Fig. 5].  
- **SKT 유무 비교**: 저비트(4-bit)에서 SKT 적용 시 Urban100 PSNR Δ+0.071 dB로 큰 향상[Table 6].  
- BN 제거 모델에도 α 조정으로 **정규화 손실 없는 범용성** 확보[Table 4].  

### 4.3 한계  
- α 추가 학습 파라미터로 연산 비용 소폭 증가.  
- 저수준 모듈 비양자화에 따라 극한 압축 요구 상황엔 제약 발생.  
- 영상 도메인 외의 다른 픽셀 단위 회귀 과제 일반화 검증 필요.  

***

## 5. 향후 연구 방향 및 고려 사항  
- **완전 양자화**: 저수준 모듈까지 포함한 엔드-투-엔드 4-bit 양자화 연구.  
- **경량화 결합**: NAS·프루닝과 α 학습 결합해 추가 구조 최적화.  
- **도메인 확장**: 비SR 픽셀 단위 과제(예: 초해상도 의료영상)로 일반화 성능 검증.  
- **효율적 α 초기화**: 적응적 β 또는 데이터 의존 초기화 기법 연구.  

PAMS는 **동적 범위 적응 양자화**와 **교사–학생 구조적 정합**을 통해 SR 모델의 압축과 정확도 상쇄 문제를 극복하며, 향후 다양한 컴퓨터 비전 회귀 과제에서 보편적 경량화 기법으로 발전할 잠재력을 제시한다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/cf33a7db-40bf-49c3-a1dd-ce2939bc8680/2011.04212v1.pdf)
