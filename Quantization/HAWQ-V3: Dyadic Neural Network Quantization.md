# HAWQ-V3: Dyadic Neural Network Quantization

## 핵심 주장 및 주요 기여  
HAWQ-V3는 **완전한 정수 연산(integer-only inference)** 만으로 신경망 추론을 수행하면서, 성능 저하를 최소화하고 하드웨어 가속 이점을 극대화하는 새로운 **혼합 정밀도(mixed-precision) 양자화** 프레임워크이다.  
1. **정수 전용 연산**: 곱셈, 덧셈, 비트 시프팅만을 사용해 활성화·가중치·배치 정규화(batch norm)·잔차 연결(residual connection)까지 순수 정수로 계산.  
2. **하드웨어 인식 ILP(bit-precision ILP)**: 모델 교란(model perturbation)을 최소화하면서 모델 크기, 지연(latency), 비트 연산량(BOPS) 같은 제약을 만족하는 최적 비트 배분을 정수 선형 계획(integer linear programming)으로 빠르게(1초 이내) 탐색.  
3. **INT4 지원 TVM 구현**: TVM을 확장하여 GPU Tensor Core에서 4-bit 및 혼합 4/8-bit 연산을 자동 튜닝, 실제 하드웨어상에서 최대 1.47× 속도 향상을 검증.  
4. **광범위한 실험**: ResNet18/50, InceptionV3에 대해 INT8, INT4, 혼합 4/8-bit 양자화 결과를 제시. 종전 정수 전용 연구 대비 정확도 최대 +5% 향상, 혼합 양자화로 지연 23% 단축 유지하면서 Top-1 76.73% 달성.  

## 문제 정의  
최첨단 신경망은 크고 무거워 실시간·에지 추론에 부적합하다. 기존 양자화 기법은  
- 시뮬레이션(fake quantization) 방식으로 FP32 내에서만 동작하여 실제 하드웨어 가속 이점을 살리지 못하고,  
- 배치 정규화 파라미터나 잔차 연결에서 여전히 FP32 연산을 필요로 하여 **정수 전용 하드웨어** 구현이 불가능하다.  

이를 해결하기 위해 HAWQ-V3는 모든 연산을 **완전 정수**로 구현하고, 하드웨어별 지연 특성을 반영한 혼합 정밀도 비트 배분을 제안한다.

## 제안 방법  
1. **정수 전용 추론**  
   -  활성화 $$h$$와 가중치 $$W$$를 각각 정수 $$q_h, q_W$$와 스케일 $$S_h, S_W$$로 표현  
   -  정수 곱셈·누산 후, $$S_W S_h/S_a = b/2^c$$ 형태의 **dyadic scaling** 으로 비트 시프트만으로 재양자화  
   -  배치 정규화 및 잔차 연결도 전부 dyadic 정수 연산으로 융합(fusion) 및 구현  
2. **혼합 정밀도 ILP**  
   -  각 레이어의 **감도(sensitivity)** $$\Omega_i(b_i)$$와 하드웨어별 지연 $$Q_i(b_i)$$, 비트 연산량 $$G_i(b_i)$$, 모델 크기 $$M_i(b_i)$$ 사전 측정  
   -   

$$
     \min_{b_i}\sum_i\Omega_i(b_i)\quad
     \text{s.t.}\quad\sum_iM_i(b_i)\le S_{\max},\quad\sum_iG_i(b_i)\le B_{\max},\quad\sum_iQ_i(b_i)\le L_{\max}
   $$  
   
를 PULP 라이브러리로 1초 이내에 최적화  
3. **TVM 확장 및 하드웨어 검증**  
   -  4-bit 데이터 패킹·스케줄링, 텐서 코어 WMMA 매핑 등 TVM IR 및 스케줄러 수정  
   -  실제 PyTorch와 TVM 간 각 레이어 출력 일치 검증 후, 지연 및 정확도 측정  

## 성능 향상  
- **정수 전용 INT8**: 종전 대비 ResNet50 Top-1 +2.68%  
- **정수 전용 INT4**: ResNet50 74.24% (FP32 대비 3.48%↓)  
- **혼합 4/8-bit**: ResNet50 76.73% 유지하면서 지연 23% 단축  
- **ILP 제약별 사례**: 동일 정확도 유지를 위해 모델 크기를 절반으로 줄이거나, 지연 목표에 맞춰 4-bit 레이어 할당 조정  

## 모델 일반화 성능 향상  
- 다차원 제약(크기·지연·BOPS) 고려로 **민감도 높은 레이어는 고정밀도**, 민감도 낮고 가속 이득 큰 레이어는 저정밀도 선택  
- 혼합 정밀도 설정이 고정 4-bit 대비 **일반화 성능(Top-1) 2–4% 포인트** 이상 개선  
- **지연-정확도 Pareto 최적** 경로 탐색으로 실환경 제약 하에서도 높은 일반화 성능 보존

## 한계  
- **추가 계산 비용**: 각 레이어 감도 측정(Hessian trace) 30분, ILP 사전 입력 계산 필요  
- **하드웨어 종속성**: T4 GPU 특성 반영, 다른 가속기에서 지연 특성이 달라질 수 있음  
- **양자화 이후 구조 변경 미적용**: 아키텍처 경량화와 결합 시 추가 최적화 여지

## 향후 연구 영향 및 고려 사항  
- **다양한 하드웨어 지원**: FPGA·ASIC·다른 GPU에 맞춘 지연 측정 및 ILP 확장  
- **더 낮은 비트폭 탐색**: 2-bit, 1-bit 혼합 정밀도 및 비대칭 양자화 연구  
- **자동화 통합**: 모델 구조 탐색(NAS)과 ILP 기반 양자화 동시 최적화  
- **추론 에너지 효율**: 지연 이외에 전력·온도 제약을 반영한 다목적 ILP 제약  
- **감도 평가 개선**: Hessian 외 다른 민감도 측정 및 비선형 효과 고려한 모델링  

HAWQ-V3는 **완전 정수 전용 추론**과 **하드웨어 인식 혼합 정밀도 ILP**를 결합해 실환경 제약 하에서도 높은 정확도와 가속 성능을 달성함으로써, 향후 **경량화 신경망**과 **하드웨어 가속기 설계**에 중요한 기반을 제공할 것이다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/498c83f2-ead9-488d-9727-b4d90118c67a/2011.10680v3.pdf)
