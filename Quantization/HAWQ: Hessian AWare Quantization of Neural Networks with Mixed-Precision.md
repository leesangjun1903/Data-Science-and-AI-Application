# HAWQ: Hessian AWare Quantization of Neural Networks with Mixed-Precision

## 1. 논문의 핵심 주장 및 주요 기여  
HAWQ는 **신경망의 각 블록에 대한 헤시안(2차 미분) 정보를 활용**하여  
1) 블록별로 **혼합 정밀도(mixed-precision) 양자화** 수준을 자동 결정하고  
2) 다단계 미세 조정(fine-tuning) 순서를 **헤시안 스펙트럼 기반**으로 체계화함으로써  
   - 초저비트(2–4비트) 양자화 시에도 **정확도 손실을 최소화**  
   - 모델 크기와 활성화(activations) 메모리 사용량을 **대폭 절감**  
라는 두 가지 난제를 동시에 해결한다.

## 2. 해결 과제  
- 균일 정밀도 양자화 시 **전체 모델 정확도 급락**  
- 서로 다른 레이어의 양자화 민감도가 달라, 혼합 정밀도 선택 공간이 **지수적으로 증가**  
- 다단계 양자화 후 미세 조정 순서 선택이 **계승적(factorial) 복잡도**  

## 3. 제안 방법  
### 3.1 블록별 헤시안 기반 민감도 측정  
- 각 블록 $$B_i$$의 파라미터 $$W_i$$에 대한 손실 함수의 헤시안 행렬 $$H_i$$의 **최대 고유값** $$\lambda_i$$를 power-iteration으로 계산  
- 블록 크기 $$n_i$$와 결합한 민감도 지표  

$$
    S_i = \frac{\lambda_i}{n_i}
  $$  
  
  값이 클수록 **높은 비트 수**를 할당  

### 3.2 미세 조정 순서 결정  
- 각 블록을 정량화했을 때 발생하는 파라미터 편차 크기 $$\|\Delta W_i\|_2$$와 $$\lambda_i$$를 결합한 순서 지표  

$$
    \Omega_i = \lambda_i\,\|\Delta W_i\|_2
  $$  
  
  이 값이 큰 블록을 **먼저** 미세 조정하도록 순서를 정함  

### 3.3 전체 알고리즘 흐름  
1. 사전 학습된 네트워크 각 블록의 $$\lambda_i$$ 계산  
2. $$S_i$$ 기반으로 정밀도 할당(2–8비트)  
3. 순차적 양자화 및 $$\Omega_i$$ 기반 블록별 미세 조정  
4. 최종 모델 병합 및 평가

## 4. 모델 구조 및 성능 향상  
| 모델            | 비트 구성 (가중치/활성화) | Top-1 정확도 개선 | 모델 크기 감소 | 활성화 압축비 |
|----------------|----------------------------|-------------------|---------------|-------------|
| ResNet20(CIFAR-10) | 2 MP / 4 MP                | 92.22% (Δ–0.15%)  | 13.1×        | 8×          |
| Inception-V3    | 2 MP / 4 MP               | 75.52% (Δ–1.93%)  | 12.0×        | –           |
| ResNet50        | 2 MP / 4 MP               | 75.48% (+0.18%)   | 12.3×        | –           |
| SqueezeNext     | 3 MP / 8 bit              | 68.02% (Δ–1.36%)  | 9.3×         | –           |

- 종전 DNAS, HAQ, RVQuant 대비 **정확도 우위** 또는 **더 높은 압축률** 달성  
- 활성화 메모리 압축 8배 등 **하드웨어 효율성** 대폭 향상  

## 5. 일반화 성능 향상 가능성  
- **헤시안 기반 감쇠:** 평탄한(loss landscape가 flat) 블록은 공격적 양자화에도 강인  
- **순서 최적화:** 민감 블록을 먼저 미세 조정해 **후속 블록 학습 안정화**  
- **다단계 학습 구조:** 단계별 양자화 후 미세 조정을 통해 **손실 최소화**, 전반적인 **일반화 성능 유지**  

## 6. 한계 및 고려 사항  
- 헤시안 최대 고유값 계산을 위한 **추가 연산 비용** (~블록당 20회 역전파)  
- 모델별 절대 비트 수 결정은 여전히 **경험적 탐색** 필요  
- **임베디드 하드웨어**에서 혼합 정밀도 구현 복잡성  

## 7. 향후 연구 방향 및 영향  
- 자연어 처리, 객체 검출, 분할 등 **다양한 태스크 확장**  
- 헤시안 정보와 AutoML 기반 탐색(DNAS·HAQ) **결합**으로 탐색 공간 추가 축소  
- **하드웨어 아키텍처 공동 설계**로 완전 자동화된 Mixed-Precision 추론 파이프라인 구축  
- 대규모 분산 환경에서 헤시안 계산 **경량화** 연구  

---  
HAWQ는 **2차 정보**를 통해 양자화 결정과 미세 조정 순서를 체계화함으로써, 저비트 네트워크에서도 높은 **정확도와 효율성**을 달성하며 향후 다양한 응용과 자동화된 최적화 연구의 기반이 될 것으로 기대된다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/ee542d2d-7e2e-494f-8572-27f2b4f52d8f/1905.03696v1.pdf)
