# Fully Quantized Network for Object Detection

## 1. 핵심 주장 및 주요 기여
**핵심 주장**  
- 복잡한 객체 검출(task)에도 공격적인 저비트(4-bit) 양자화가 가능하며, 기존 방법 대비 mAP 손실을 대폭 줄일 수 있다.

**주요 기여**  
- 완전 정수 연산만으로 동작하는 **end-to-end 4-bit 양자화 파이프라인(FQN)** 제안  
- 양자화 미세조정(fine-tuning) 단계의 불안정성 원인(배치 정규화 통계치, 활성화 이상치, 채널별 가중치 스케일 차이) 규명  
- 불안정성 해소 기법 세 가지 도입  
  1. 배치 정규화 통계치 고정(freeze BN)  
  2. 활성화 이상치 제거용 퍼센타일 기반 범위 조정  
  3. 채널별(weight-wise) 양자화  
- COCO 데이터셋에서 4-bit RetinaNet/Faster R-CNN 전 모델에 적용하여, mAP 손실을 기존 대비 3.8× 감소시키며 state-of-the-art 성능 달성  

***

## 2. 문제 정의 및 제안 방법

### 2.1 해결하고자 하는 문제  
- 모바일·임베디드 장치에서 객체 검출 모델을 실행할 때, 32-bit 부동소수점 연산 부담이 크므로 저비트 양자화가 필요  
- 기존 8-bit 양자화 연구는 객체 검출 성능 저하, 특히 4-bit 이하에서 미세조정 도중 **불안정성(instability)** 이 심함  

### 2.2 제안 기법 및 수식

1. **Uniform Quantization (k-bit)**  

$$X_Q = \Delta \bigl\lfloor (X_R - z)/\Delta \rceil + z$$  

$$\Delta = (u_b - l_b)/(2^k - 1)$$, $$l_b, u_b$$는 양자화 범위

2. **채널별 가중치 경계 설정**  
   각 출력 채널 $$c$$별로  

$$
     l_b^{(c)} = \min W^{(c)},\quad
     u_b^{(c)} = \max W^{(c)}
   $$  
   
   → 채널 스케일 차이에 따른 양자화 오차 감소

3. **퍼센타일 기반 활성화 범위 조정**  
   훈련 데이터 20개 배치 샘플링 후, 각 층 활성화 값의 γ·백분위(예: 0.1%–99.9%)로 상한·하한 설정 → 이상치(outlier) 제거

4. **배치 정규화 통계치 고정**  
   미세조정(fine-tuning) 중 배치 통계 $$\mu_b, \sigma_b$$ 대신 학습 완료 시 $$\mu_{EMA}, \sigma_{EMA}$$ 사용하고 업데이트 금지  

$$
     W_{\text{fold}} = \alpha\,\frac{W}{\sqrt{\sigma_{EMA}^2+\epsilon}},\quad
     b_{\text{fold}} = \alpha\,\frac{(b - \mu_{EMA})}{\sqrt{\sigma_{EMA}^2+\epsilon}} + \beta
   $$

***

## 3. 모델 구조 및 구현 세부사항
- **검출기**: RetinaNet (단일 단계)과 Faster R-CNN (이단계)  
- **백본 네트워크**: ResNet-18/34/50, MobileNetV2  
- **훈련**: COCO-2017 train, sync-SGD(총 배치 32), 초기 lr 0.04 → 미세조정 lr 0.004, 4-bit 양자화  
- **추론**: 모든 연산을 정수(int)만으로 수행 (배치 정규화·업샘플링·엘리먼트별 연산 포함)

***

## 4. 성능 향상 및 한계

### 4.1 성능 향상  
- **mAP 손실 대폭 감소**: 4-bit RetinaNet+ResNet50에서 전체 mAP 손실 3.1% (기존 대비 약 3.8× 감소)  
- **빠른 수렴**: 1,000 스텝 내 약 mAP 0.27 회복  
- **경량 백본에서도 안정적**: MobileNetV2+RetinaNet 4-bit에서 mAP 손실 2.0%  

### 4.2 한계  
- **Faster R-CNN**: 두 단계 구조에서 mAP 손실이 상대적으로 큼 (백본 동일 시 RetinaNet 대비 약 +1–2% 손실)  
- **초기 계산 비용**: 활성화 범위·배치 통계 획득 위한 추가 샘플링 단계 필요  
- **초저비트(2-bit 이하)** 적용 가능성은 별도 연구 필요  

***

## 5. 모델 일반화 성능 향상 관점
- **채널별 양자화**로 다양한 구조(ResNet 계열, MobileNetV2)에 모두 효과  
- **퍼센타일 기반 활성화 클램핑**이 데이터 분포 변화에 탄력적(γ 조절로 범위 최적화 가능)  
- **배치 정규화 통계 고정**은 소규모 배치에서도 일관된 추론 분포 유지  
→ 다양한 도메인 및 데이터셋 전이학습에도 **안정적 일반화** 기대

***

## 6. 향후 연구 영향 및 고려 사항
- **산업용 경량 검출기** 설계 시 “완전 정수 연산” 기반 4-bit FQN이 기본 벤치마크가 될 것  
- **더 낮은 비트폭(2/1-bit)** 적용 시 불안정성 해소 및 정밀도 유지 전략 추가 연구 필요  
- **자동γ 탐색** 및 **레이어/채널별 동적 비트폭 할당** 연구로 양자화 효율 극대화  
- **하드웨어 구현**: 제안된 기법들이 실제 엣지 디바이스에서 기대 성능을 내는지 검증 필요  

---  

**결론**: 본 논문은 객체 검출 모델을 4-bit 완전 정수 연산 환경에서 효율적으로 운용하기 위한 실용적 가이드라인과 기법을 제시하여, 향후 저전력·저지연 엣지 비전 응용 연구에 핵심 토대를 제공한다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/557cd0b1-d963-4fda-bf67-18905dffb024/Li_Fully_Quantized_Network_for_Object_Detection_CVPR_2019_paper.pdf)
