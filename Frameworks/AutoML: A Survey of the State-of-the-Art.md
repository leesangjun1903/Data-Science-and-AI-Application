# AutoML: A Survey of the State-of-the-Art

이 논문은 자동화된 머신러닝(AutoML) 분야의 포괄적인 조사연구로, 홍콩 침례대학교의 Xin He, Kaiyong Zhao, Xiaowen Chu가 2021년에 발표한 최신 기술동향 분석입니다.[1]

## 1. 핵심 주장과 주요 기여

### **핵심 주장**
AutoML은 **딥러닝 시스템 구축을 완전 자동화**하여 인간 전문가의 의존성을 제거하는 것이 목표입니다. 논문은 전통적인 수동 모델 설계 방식의 한계를 지적하며, 전문가 개입 없이도 고성능 ML 모델을 생성할 수 있는 자동화 시스템의 필요성을 강조합니다.[1]

### **주요 기여**
1. **완전한 AutoML 파이프라인 제시**: 데이터 준비부터 모델 평가까지의 전 과정을 체계적으로 분류[1]
2. **Neural Architecture Search(NAS) 심층 분석**: NAS가 AutoML의 핵심 기술임을 인식하고 특별히 집중 분석[1]
3. **성능 벤치마크 제공**: CIFAR-10과 ImageNet 데이터셋에서 대표적 NAS 알고리즘들의 성능 비교[1]
4. **미래 연구 방향 제시**: AutoML 분야의 열린 문제들과 향후 연구 방향 제안[1]

## 2. 해결하고자 하는 문제와 제안하는 방법

### **핵심 문제**
딥러닝 모델 설계가 전문가의 시행착오(trial-and-error) 방식에 의존하여 막대한 시간과 자원이 소모되는 문제입니다.[1]

### **제안하는 AutoML 파이프라인**

#### **1) 데이터 준비 (Data Preparation)**
- **데이터 수집**: 웹 데이터 검색과 합성 데이터 생성
- **데이터 정제**: 노이즈 제거 및 품질 향상
- **데이터 증강**: 모델 견고성 향상을 위한 자동 증강 정책 탐색[1]

#### **2) 특성 공학 (Feature Engineering)**
- **특성 선택**: 중요 특성 자동 선별
- **특성 구성**: 새로운 특성 자동 생성
- **특성 추출**: 차원 축소 및 정보 압축[1]

#### **3) 모델 생성 (Model Generation)**
**Neural Architecture Search (NAS)** 중심으로 구성:

**탐색 공간 설계:**
- **전체 구조 탐색**: 완전한 네트워크 구조 설계
- **셀 기반 탐색**: 반복 가능한 셀 구조 최적화
- **계층적 탐색**: 다수준 구조 설계
- **형태학적 탐색**: 기존 모델 개선[1]

**아키텍처 최적화 방법:**

**진화 알고리즘 (EA):**
```
선택 → 교배 → 변이 → 업데이트
```
생물학적 진화 과정을 모방하여 네트워크 구조 최적화[1]

**강화학습 (RL):**
컨트롤러가 행동을 통해 아키텍처를 샘플링하고 보상을 받아 정책 개선[1]

**경사하강법 (GD):**
DARTS 방법론 - 이산적 탐색 공간을 연속 공간으로 완화:

$$o_{i,j}(x) = \sum_{k=1}^{K} \frac{\exp(\alpha_i^k)}{\sum_{l=1}^{K} \exp(\alpha_l^k)} o^k(x)$$

여기서 $$\alpha_i^k$$는 연산 $$o^k$$의 가중치입니다.[1]

**베이지안 최적화 (SMBO):**
과거 평가 결과를 기반으로 surrogate 모델 구축하여 효율적 탐색[1]

#### **4) 모델 평가 가속화**
- **저충실도 평가**: 작은 데이터셋이나 모델로 빠른 성능 추정
- **가중치 공유**: 자식 네트워크간 파라미터 공유로 효율성 향상
- **서로게이트 모델**: 블랙박스 함수 근사로 평가 속도 향상
- **조기 종료**: 성능이 낮을 것으로 예상되는 모델의 훈련 조기 중단[1]

## 3. 일반화 성능 향상과 관련 내용

### **전이성(Transferability) 향상**
**셀 기반 탐색 공간**의 핵심 장점은 모델의 전이성입니다. CIFAR-10에서 탐색된 셀 구조가 ImageNet과 같은 더 큰 데이터셋에서도 효과적으로 작동함이 실험적으로 증명되었습니다.[1]

### **견고성(Robustness) 강화**
**데이터 증강 자동화**를 통해 모델 견고성을 향상시킵니다:
- AutoAugment: 강화학습 기반 증강 정책 자동 탐색
- 다양한 변환 기법: 회전, 크기 조정, 노이즈 추가 등의 조합 최적화[1]

### **특성 공학의 일반화 기여**
**특성 구성(Feature Construction)**은 원본 특성의 표현 능력을 증가시켜 모델의 견고성과 일반화 능력을 향상시킵니다.[1]

### **Progressive 방법론**
P-DARTS와 같은 점진적 접근법이 탐색과 평가 단계 간의 간격을 줄여 일반화 성능을 개선합니다:
- 탐색 단계에서 8개 셀 → 평가 단계에서 20개 셀로 확장 시 발생하는 성능 저하 문제 해결[1]

## 4. 모델 구조와 성능 향상

### **셀 기반 아키텍처**
정상 셀(Normal Cell)과 축소 셀(Reduction Cell)로 구성:
- 정상 셀: 입력과 동일한 공간 차원 유지
- 축소 셀: 특성 맵의 너비/높이를 절반으로, 채널 수는 2배로 조정[1]

### **성능 비교 (CIFAR-10)**
| 방법 | 오류율(%) | 탐색 시간(GPU Days) |
|------|-----------|---------------------|
| AmoebaNet | 2.13 | 3,150 |
| ENAS | 2.89 | 0.45 |
| DARTS | 2.83 | 4 |
| P-DARTS | 2.50 | - |

P-DARTS가 DARTS 대비 0.33% 성능 향상을 보였습니다.[1]

## 5. 한계와 미래 연구 방향

### **현재 한계**
1. **인간 편향 존재**: 모든 탐색 공간이 여전히 인간의 경험과 지식에 기반[1]
2. **NLP 분야 성능 부족**: Computer Vision 대비 자연어처리에서 인간 설계 모델과 큰 성능 차이[1]
3. **계산 비용**: 일부 방법들이 여전히 막대한 GPU 자원 필요[1]

### **미래 연구 방향**
1. **유연한 탐색 공간**: AutoML-Zero처럼 수학적 기본 연산부터 시작하는 편향 없는 탐색[1]
2. **더 많은 영역 확장**: NLP, 네트워크 압축, 연합학습 등으로 적용 확대[1]
3. **평생 학습**: 새로운 데이터 학습과 기존 지식 보존 능력[1]
4. **메타러닝**: 이전 경험을 활용한 새로운 작업 빠른 적응[1]

## 6. 앞으로의 연구에 미치는 영향

### **기술적 영향**
1. **One-shot NAS 발전**: 단일 supernet 훈련으로 효율성 극대화
2. **Joint HAO**: 하이퍼파라미터와 아키텍처 동시 최적화로 성능 향상
3. **Resource-aware NAS**: 하드웨어 제약을 고려한 실용적 설계[1]

### **연구 시 고려사항**
1. **공정한 비교**: NAS-Bench 데이터셋 활용으로 재현 가능한 연구 필요[1]
2. **Kendall Tau 지표**: 단순 정확도 외에 탐색-평가 단계 간 상관관계 고려[1]
3. **실용성 중시**: 학술적 성능뿐만 아니라 실제 배포 가능성 고려[1]
4. **다양성 확보**: Computer Vision 중심에서 벗어나 다양한 도메인으로 확장[1]

이 논문은 AutoML 분야의 포괄적인 현황을 제시하며, 특히 NAS 기술의 체계적 분류와 성능 분석을 통해 향후 연구의 기준점을 제공한다는 점에서 중요한 의미를 가집니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/dd406c55-ce1e-45b5-8d1a-68f1640d8186/1908.00709v6.pdf)
