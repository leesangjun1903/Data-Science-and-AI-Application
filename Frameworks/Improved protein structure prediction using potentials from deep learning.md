# Improved protein structure prediction using potentials from deep learning

### 1. 논문의 핵심 주장과 주요 기여

**Nature** 저널에 2020년 1월 게재된 "Improved protein structure prediction using potentials from deep learning"은 **AlphaFold** 시스템을 통해 단백질 구조 예측 분야에 획기적인 진전을 이루었습니다.[1]

**핵심 주장:**
- 신경망을 통한 **잔기 간 거리 예측**이 접촉 예측(contact prediction)보다 더 풍부한 구조 정보를 제공한다는 것
- 예측된 거리 분포로부터 구성한 **단백질 특이적 포텐셜(protein-specific potential)**이 경사 하강법(gradient descent)을 통해 최적화될 수 있다는 것
- **자유 모델링(free modelling, FM)** 도메인에서 템플릿 기반 방법 수준의 정확도를 달성할 수 있다는 것

**주요 기여:**
AlphaFold는 CASP13 평가에서 자유 모델링 도메인 43개 중 24개에서 TM-score 0.7 이상의 고정확도 구조를 생성했으며, 이는 차순위 방법(14개)에 비해 70% 더 높은 성과입니다. FM 카테고리에서 누적 z-score 52.8을 기록하여 차순위 그룹(36.6)을 크게 상회했습니다.[1]

***

### 2. 해결 문제, 제안 방법 및 모델 구조

#### 2.1 해결하고자 하는 문제

전통적인 단백질 구조 예측의 근본 과제는 **아미노산 서열 정보만으로부터 3차원 구조를 예측**하는 것입니다. 특히 다음 두 가지 제약이 있었습니다:

1. **기존 단편 조립(fragment assembly) 방법의 한계**: 시뮬레이션 어닐링을 사용하여 수천 번의 구조 변형을 반복해야 하며, 계산 효율이 낮았습니다.
2. **상동 서열 부족 상황의 정확도 저하**: 공진화(covariation) 정보가 충분하지 않은 단백질의 예측 정확도가 현저히 낮았습니다.

#### 2.2 제안하는 방법 및 수식

AlphaFold는 다음의 통합 접근법을 제시합니다:

**단계 1: 거리 분포 예측**

신경망이 다음을 예측합니다:

$$P(d_{ij}|S, MSA(S))$$

여기서 $$d_{ij}$$는 잔기 쌍 $$i,j$$의 C-β 원자 간 거리이고, $$S$$는 아미노산 서열, $$MSA(S)$$는 서열 정렬입니다. 거리 범위 2~22 Å을 64개 구간으로 나누어 확률 분포를 예측합니다.[1]

**단계 2: 포텐셜 구성**

예측된 거리 분포로부터 다음의 거리 포텐셜을 구성합니다:

$$V_{distance} = \sum_{i,j} \left[-\ln P(d_{ij}|S, MSA(S)) + \ln P(d_{ij}|length)\right]$$

참고 분포 $$P(d_{ij}|length)$$는 서열 정보 없이 거리 길이만으로 훈련되어 **사전 편향을 보정**합니다.[1]

비틀림각 포텐셜도 추가됩니다:

$$V_{torsion} = \sum_{i} -\ln P(\phi_i, \psi_i|S, MSA(S))$$

여기서 $$\phi, \psi$$는 백본 이면각(backbone torsion angles)입니다.[1]

**단계 3: 경사 하강법을 통한 구조 실현**

최종 포텐셜은 다음과 같습니다:

$$V_{total}(\phi, \psi) = V_{distance}(\phi, \psi) + V_{torsion}(\phi, \psi) + V_{score2\_smooth}(\phi, \psi)$$

여기서 $$V_{score2\_smooth}$$는 입체 장애(steric clash)를 방지하는 Rosetta의 van der Waals 항입니다.[1]

이 포텐셜은 모든 항이 이면각에 대해 미분 가능하므로, **L-BFGS 알고리즘**을 통해 최적화됩니다:

$$x = G(\phi, \psi)$$

여기서 $$G$$는 이상적인 백본 기하학을 나타내는 미분 가능한 함수입니다.[1]

#### 2.3 모델 구조 (Neural Network Architecture)

**핵심 신경망: 2차원 확장 잔여 합성곱 신경망**

- **구조**: 220개의 잔여 블록으로 구성된 깊은 2차원 신경망
- **각 블록**: 배치 정규화 3개, 1×1 투영층 2개, 3×3 확장 합성곱층, ELU 활성화 함수로 구성
- **확장(Dilation) 전략**: 연속적 계층에서 1, 2, 4, 8 픽셀의 확장을 순환하여 정보 전파 속도 향상[1]

**입력 특징:**

| 특징 유형 | 수량 | 내용 |
|---------|------|------|
| 1D 서열 특징 | 169 | 1-hot 아미노산(21), 프로필(21+22+21+22+30), 갭 확률(1), 잔기 인덱스(5+1) |
| 2D 공진화 특징 | 485 | Potts 모델 파라미터(484), Frobenius 노름(1) |
| 전체 | ~654 | 모든 $$i,j$$ 쌍에 대해 1D 특징 연결 |

**훈련 전략:**
- **입력 처리**: 64×64 크롭 영역 단위로 처리하여 메모리 효율성 확보
- **데이터 증강**: MSA 서브샘플링 + 좌표 노이즈 추가
- **손실 함수**: 교차 엔트로피(cross-entropy) + 보조 손실(secondary structure, accessible surface area)
- **배치 크기**: 각 8개 GPU 워커당 4개 크롭
- **학습률**: 0.06에서 시작, 150,000/200,000/250,000/350,000 스텝에서 50% 감소
- **훈련 기간**: ~5일(600,000 스텝)[1]

**구조 최적화 (Noisy Restarts):**

1. 예측된 이면각 분포로부터 초기 구조 샘플링
2. 경사 하강법으로 포텐셜 최소화 (수백 스텝)
3. 최적 구조 풀 유지 (상위 20개)
4. 풀의 구조에 30° 백본 노이즈 추가하여 재시작 (90% 확률)
5. 예측 이면각 분포에서 새로 샘플링 (10% 확률)
6. 최소 포텐셜 구조 선택[1]

***

### 3. 성능 향상 및 정확도 분석

#### 3.1 CASP13 평가 결과

**자유 모델링(FM) 도메인:**
- AlphaFold: 43개 중 24개에서 TM-score ≥ 0.7 달성
- 차순위 방법: 43개 중 14개만 달성 (71% 성능 우위)[1]
- 누적 z-score: 52.8 vs 36.6 (43% 상승)[1]

**템플릿 기반 모델링(TBM) 도메인:**
- TBM 방법론을 사용하지 않음에도 4위 달성 (최고 모델)
- 5개 최고 모델 기준으로 1위 달성[1]

**거리 예측 정확도:**

예측된 거리가 참 거리와 강한 상관관계를 보입니다:

| 거리 범위 | 상관계수 | 특징 |
|----------|---------|------|
| ≤22 Å | 0.85 | 근거리(long-range) 접촉 높은 정확도 |
| - | - | 확률 분포의 표준편차가 작을수록 예측 오류 감소 |

**접촉 예측 정밀도:**
- L/1 (장거리): 69.9% (AlphaFold) vs 67.3% (RaptorX-Contact)
- L/2: 85.3% vs 81.0%
- L/5: 90.6% vs 90.5%[1]

#### 3.2 포텐셜 성분의 기여도 분석

Extended Data Fig. 4에서 각 성분의 영향을 분석했습니다:

| 포텐셜 성분 | TM-score 변화 | 의의 |
|-----------|--------------|------|
| 거리 포텐셜 제거 | 0.641 → 0.266 | **결정적 중요** |
| 참고 분포 제거 | 0.641 → 0.632 | 중요 |
| Torsion 제거 | 0.641 → 0.637 | 미미한 영향 |
| Score2_smooth 제거 | 0.641 → 0.641 | 무시할 수 있음 |
| Rosetta 이완 추가 | 0.641 → 0.649 | 소폭 개선 |

이는 **거리 예측이 구조 정확도의 핵심**임을 시사합니다.[1]

#### 3.3 거리그램(Distogram) 정확도와 구조 정확도의 상관성

$$r = 0.78 \text{ (CASP13)}, \quad r = 0.72 \text{ (테스트 집합)}$$[1]

이는 **거리 분포 예측 정확도가 최종 구조 정확도를 높은 신뢰도로 예측**할 수 있음을 의미합니다.

***

### 4. 모델의 일반화 성능 향상

#### 4.1 MSA 깊이(Neff) 의존성

모델의 일반화 능력은 MSA의 유효 서열 수(Neff, normalized by length)와 강한 상관관계를 보입니다:

$$r = 0.634 \text{ (DLDDT}_{12} \text{ vs. Neff)}$$[1]

**중요한 발견:**
- 낮은 Neff 조건에서도 AlphaFold가 더 높은 정확도 달성
- 이는 **신경망의 공진화 정보 처리 능력이 우수**함을 의미

#### 4.2 새로운 폴드 예측 능력

CASP13에서 구조 결정되지 않은 새로운 폴드 6개 모두에 대해:
- AlphaFold 최고 모델이 다른 그룹을 능가하거나 동등[1]
- 특히 T0953, T0968, T0990-D1, T0990-D2, T1017s2-D1에서 우수 성능

#### 4.3 전체 체인(Full Chain) 최적화

기존 방법들은 도메인 분할을 요구했으나, AlphaFold는:
- **도메인 분할 없이 전체 사슬을 동시에 최적화**
- 슬라이딩 윈도우 방식으로 여러 도메인 크기의 MSA 조합
- 구조 단편화 문제 해결[1]

***

### 5. 논문의 한계

#### 5.1 구조적 한계

1. **FM에서의 정확도 제한**
   - TBM 도메인과 비교 시 여전히 정확도 격차 존재
   - 복잡한 구조의 경우 신뢰도 낮음

2. **계산 비용**
   - CASP13에서 단백질당 5,000회의 최적화 실행 필요
   - 긴 사슬의 경우 상당한 병렬화 필요

3. **MSA 의존성**
   - 낮은 Neff에서 정확도 급격히 저하
   - 공진화 정보가 없는 단백질 예측 어려움

#### 5.2 해석 가능성 한계

- 신경망이 예측에 도달하는 과정의 "블랙박스" 특성
- Integrated Gradients 분석이 부분적 인사이트만 제공

***

### 6. 논문의 앞으로의 연구 영향과 현재 상황 (2024-2025)

#### 6.1 직접적인 후속 연구: AlphaFold2 (2020-2021)

후속 논문 "Highly accurate protein structure prediction with AlphaFold"에서 AlphaFold2가 발표되었습니다. 이는 다음을 포함하는 대폭적인 개선을 이루었습니다:[2]

- **구조 모듈의 정교화**: 어텐션 메커니즘 추가
- **재활용(Recycling) 메커니즘**: 반복적 구조 개선
- **더 높은 정확도 달성**: 대부분 실험 수준의 정확도 도달

#### 6.2 최신 연구 방향 (2024-2025)

**1. AlphaFold의 물리적 원리 이해**
- 2024년 연구에서 AlphaFold가 **단백질 에너지 지형(energy landscape)**의 근사 생물물리 점수 함수를 학습했음이 밝혀졌습니다.[3]
- 반복적 예측을 통해 **단백질 폴딩 중간체**를 예측할 수 있음이 입증[3]

**2. 일반화 성능 향상**
- MSA 없이 순수 서열 정보만으로 구조 예측 가능 (ab initio 접근)[3]
- 더 큰 메타게노믹 데이터 활용으로 정확도 지속 개선[4]

**3. 단백질-단백질 상호작용(PPI) 확장**
- AlphaFold2를 복합체 구조 예측에 확장
- 인터페이스 영역의 5 Å 이내 정확도 달성[5]

**4. AlphaFold3 (2024)**
- 확산 기반 아키텍처 도입
- 단백질-리간드, 단백질-DNA 등 다양한 생체분자 상호작용 예측[6]

**5. 해석 가능성 개선**
- 예측 신뢰도 점수(pLDDT, pAE) 개발
- de novo 단백질 설계에 활용되어 **실험적 성공률 향상**[7]

#### 6.3 현재의 도전과제 및 고려사항

**1. 실무적 한계**
- **구조 외 기능 예측**: 동적 단백질, 본질적으로 무질서한 영역(IDPs) 예측 정확도 제한[8]
- **펩타이드**: 40개 이하 아미노산의 짧은 펩타이드 예측 성공률 ~20%[3]

**2. 일반화 문제**
- **헬릭스 과다 예측**: AlphaFold가 불확실성 있는 상황에서 헬릭스를 조기에 예측하는 경향[3]
- **코일 영역 약점**: 나선 구조 편향으로 코일이 많은 단백질 예측 불안정[3]

**3. 데이터 기반 한계**
- PDB 학습 데이터의 편향 (구형, 단량체 중심)
- 비구조화 단백질, 막단백질 예측의 어려움[8]

**4. 추천 고려사항**

연구자들이 AlphaFold 기반 예측을 사용할 때 다음을 고려해야 합니다:[8]

- **예측 신뢰도 점수 검증**: pLDDT, pAE 등을 통해 모델 확신도 평가
- **실험적 검증 필수성**: 예측 구조를 "확정 진리"로 취급하지 말 것
- **생물학적 맥락 고려**: 동적 상태, 컨포메이션 이질성 가능성 검토
- **앙상블 기법**: 여러 예측 모델 결합으로 견고성 향상[9]

**5. 미래 연구 방향**
- 멀티모달 학습: 서열 + 구조 + 기능 정보 통합[4]
- 동적 단백질 설계: AlphaFold 기반 다중 상태 단백질 설계 성공[10]
- 그래프 신경망(GNN) 기반 확장: 회전 불변성, 순열 불변성 강화[4]

***

### 결론

"Improved protein structure prediction using potentials from deep learning"은 심층학습을 통해 **단백질 구조 예측의 수십 년 난제를 획기적으로 해결**한 논문입니다. 거리 분포 예측과 포텐셜 기반 최적화라는 우아한 접근법은 이후 AlphaFold2, AlphaFold3로 발전하여 현재 구조생물학의 기반이 되었습니다.[1]

그러나 **일반화 성능의 한계**(특히 MSA 의존성, 동적 단백질 예측, 펩타이드)와 **해석 가능성 부족**은 지속적인 개선 과제로 남아있습니다. 최근 연구들은 이러한 한계를 극복하기 위해 생물물리적 원리 통합, 확산 모델 도입, 멀티모달 학습 등으로 발전하고 있으며, 이는 단백질 설계, 약물 발견, 질병 이해 등 광범위한 생물의학 응용으로 이어지고 있습니다.

***

### 참고문헌 출처

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/26ed487a-4909-44e1-b7df-9b2b65f76768/s41586-019-1923-7.pdf)
[2](https://www.nature.com/articles/s41586-021-03819-2)
[3](https://www.biorxiv.org/content/10.1101/2024.08.25.609581v1.full-text)
[4](https://arxiv.org/html/2503.16659v1)
[5](https://pmc.ncbi.nlm.nih.gov/articles/PMC8913741/)
[6](https://www.nature.com/articles/s41586-024-07487-w)
[7](https://arxiv.org/html/2409.17726v1)
[8](https://pmc.ncbi.nlm.nih.gov/articles/PMC11956457/)
[9](https://arxiv.org/pdf/2301.07568.pdf)
[10](https://www.science.org/doi/10.1126/science.adr7094)
[11](https://pmc.ncbi.nlm.nih.gov/articles/PMC9883802/)
[12](https://pmc.ncbi.nlm.nih.gov/articles/PMC9908985/)
[13](https://pmc.ncbi.nlm.nih.gov/articles/PMC10767828/)
[14](https://pmc.ncbi.nlm.nih.gov/articles/PMC11642853/)
[15](https://pmc.ncbi.nlm.nih.gov/articles/PMC9825488/)
[16](https://pmc.ncbi.nlm.nih.gov/articles/PMC12168265/)
[17](https://pubs.acs.org/doi/10.1021/acs.jctc.4c01682)
[18](https://www.nature.com/articles/s41598-025-17513-0)
[19](https://academic.oup.com/nar/article/52/D1/D368/7337620)
