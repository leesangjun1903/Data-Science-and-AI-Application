# On the Existence of Simpler Machine Learning Models

## **1. 핵심 주장과 주요 기여**

이 논문의 핵심 주장은 **정확하면서도 단순한 머신러닝 모델이 실제로 존재할 수 있으며, 이를 찾기 전에 그 존재 가능성을 증명할 수 있다**는 것입니다.[1]

주요 기여는 다음과 같습니다:[1]

**Rashomon 비율(Rashomon Ratio)의 정의**: Rashomon 집합의 크기를 정량화하는 새로운 학습 문제의 단순성 척도를 제안했습니다. Rashomon 집합은 거의 동등하게 정확한 모델들의 집합이며, Rashomon 비율은 이 집합의 부피를 가설 공간의 부피로 나눈 값입니다.[1]

**일반화 경계 제공**: Rashomon 집합 내 모델들에 대한 일반화 경계를 제공하고, Rashomon 집합의 크기가 일반화 성능이 좋은 단순 모델 존재의 지표가 됨을 증명했습니다.[1]

**Rashomon 집합 크기 추정 방법**: 여러 가지 접근법을 통해 Rashomon 집합의 크기를 추정하는 방법을 제시했습니다.[1]

**실증적 검증**: 큰 Rashomon 집합이 발생할 때 대부분의 머신러닝 방법들이 유사한 성능을 보이며, 단순하면서도 정확한 모델이 존재함을 실험적으로 입증했습니다.[1]

**복잡도 척도와의 차별성**: Rashomon 비율이 VC 차원, 알고리즘 안정성, 기하학적 마진, Rademacher 복잡도 등 기존의 복잡도 척도와 다름을 이론적으로 증명했습니다.[1]

## **2. 연구의 목적과 필요성**

### **연구 목적**

이 연구는 **계산적으로 비용이 많이 드는 단순 모델 탐색을 시도하기 전에, 그러한 모델이 존재할 가능성이 있는지 미리 알 수 있는 방법**을 제공하고자 합니다. 오컴의 면도날(Occam's Razor) 원칙에 따라 데이터를 잘 설명하는 가장 단순한 모델을 사용해야 하지만, 희소성과 같은 단순성 제약을 도입하면 최적화 문제가 일반적으로 NP-hard가 되어 실무자들이 시도를 기피하게 됩니다.[1]

### **연구 필요성**

**고위험 의사결정에서의 해석가능성**: 의료, 형사 재범 예측, 대출 심사 등 고위험 분야에서는 단순하고 해석 가능한 모델이 필수적입니다. 그러나 현대 머신러닝은 복잡한 블랙박스 모델을 선호하는 경향이 있습니다.[1]

**기존 이론의 한계**: 기존의 통계 학습 이론(VC 이론, 알고리즘 안정성 등)은 함수 클래스의 복잡도를 데이터와 무관하게 측정하거나 특정 알고리즘의 속성을 측정할 뿐, 실제로 많은 데이터셋에서 여러 표준 알고리즘이 유사한 성능을 보이는 현상을 직접적으로 설명하지 못합니다.[1]

**실무적 관찰과 이론의 간극**: 실무에서는 많은 데이터셋에서 여러 알고리즘이 비슷한 성능을 보이고, 이 경우 단순한 모델도 비슷하게 잘 작동하는 경우가 많습니다. 이러한 세 가지 관찰(유사한 성능, 좋은 일반화, 단순 모델 존재)을 설명할 수 있는 통합된 이론적 프레임워크가 필요했습니다.[1]

## **3. 연구 주제, 방법, 결과**

### **연구 주제**

논문은 다음 핵심 질문들을 다룹니다:[1]

- 정확하면서도 단순한 모델이 존재함을 명시적으로 찾기 전에 증명하거나 그 가능성을 보일 수 있는가?
- Rashomon 집합이 크면 단순 모델이 포함될 가능성이 높은가?
- 어떤 조건에서 Rashomon 집합이 커지는가?

### **연구 방법**

**이론적 접근**

**Rashomon 집합 정의**: 경험적 위험이 최적 모델에 비해 ε 이내인 모델들의 집합으로 정의했습니다. 수식으로는 $$\text{Rset}(F, \epsilon) = \{f \in F : \hat{L}(f) \leq \hat{L}(f^*) + \epsilon\}$$입니다.[1]

**일반화 정리**: 단순한 함수 클래스 $$F_1$$이 복잡한 클래스 $$F_2$$의 부분집합일 때, $$F_2$$의 true Rashomon 집합이 $$F_1$$의 모델을 포함하면, $$F_1$$에서 학습한 모델의 경험적 성능이 $$F_2$$의 최적 모델의 테스트 성능에 근접함을 보였습니다(Theorem 5).[1]

**근사 이론 활용**: 손실 함수가 K-Lipschitz이고 $$F_1$$이 $$F_2$$의 좋은 커버를 형성하면, 큰 Rashomon 집합이 단순 모델의 존재를 보장함을 증명했습니다(Theorem 7).[1]

**실험적 접근**

**데이터셋**: UCI Machine Learning Repository에서 38개의 분류 데이터셋을 사용했습니다(16개는 범주형 특징, 22개는 실수값 특징).[1]

**알고리즘**: 로지스틱 회귀(LR), CART, 랜덤 포레스트(RF), 그래디언트 부스팅 트리(GBT), RBF 커널 SVM 등 5가지 알고리즘을 사용했습니다.[1]

**Rashomon 비율 추정**: 깊이 7의 의사결정 트리를 사용한 중요도 샘플링으로 Rashomon 집합의 크기를 추정했습니다. 각 폴드당 250,000개의 트리를 샘플링했으며, Rashomon 파라미터 ε은 0.05로 설정했습니다.[1]

### **주요 결과**

**이론적 결과**

- Rashomon 비율이 VC 차원, 알고리즘 안정성, 기하학적 마진, 국소 Rademacher 복잡도와 구별됨을 증명했습니다(Theorems 2-4).[1]
- 선형 최소제곱 회귀의 경우 Rashomon 집합의 부피에 대한 닫힌 형태의 해를 도출했습니다.[1]

**실험적 결과**

큰 Rashomon 비율($$10^{-37}$$ 또는 $$10^{-38}$$ 수준)을 가진 데이터셋에서는 모든 알고리즘이 5% 이내의 유사한 학습 성능을 보였으며, 단순한 모델(LR, CART)도 복잡한 모델(RF, GBT, SVM)과 비슷한 성능을 달성했습니다.[1]

큰 Rashomon 비율을 가진 경우 모든 모델이 잘 일반화했으며(학습-테스트 오차 차이 5% 이내), 테스트 성능이 학습 성능과 일치했습니다.[1]

작은 Rashomon 비율($$10^{-40}$$ 이하)을 가진 데이터셋에서는 알고리즘 간 성능 차이가 크고, 일반화가 일관되지 않았습니다.[1]

**노이즈와의 관계**: 랜덤 분류 노이즈를 추가해도 true Rashomon 집합의 크기는 기대값으로 감소하지 않음을 증명했습니다(Theorem 8). 가우시안 분포에서 특징 노이즈를 증가시키면 Rashomon 집합이 커질 수 있음을 수치적으로 입증했습니다(Conjecture 9).[1]

## **4. 결론 및 후속 연구 방향**

### **연구자들이 제시한 결론과 시사점**

논문은 다음과 같은 주요 결론을 제시합니다:[1]

**큰 Rashomon 집합은 단순한 가설 공간의 모델을 포함할 수 있습니다**: 이는 Section 5의 이론적 결과로 뒷받침됩니다.[1]

**여러 알고리즘의 유사한 성능은 큰 Rashomon 집합과 상관관계가 있습니다**: 38개 데이터셋에 대한 실험으로 검증되었습니다.[1]

**큰 Rashomon 집합은 좋은 일반화 성능을 가진 모델의 존재와 상관관계가 있습니다**: 실험적으로 확인되었습니다.[1]

**Rashomon 비율은 학습 문제의 복잡도 척도입니다**: 겹치는 가우시안 분포에서 생성된 데이터는 큰 Rashomon 집합을 가지는 경향이 있습니다.[1]

**실무적 시사점**: 연구자가 여러 알고리즘을 실행했을 때 모두 유사한 성능을 보이고 잘 일반화하면, 학습 문제가 큰 Rashomon 집합을 가질 가능성이 높습니다. 이 경우 단순 모델을 찾기 위한 계산적으로 비싼 최적화를 시도할 가치가 있습니다. 반대로 알고리즘들이 서로 다른 성능을 보이면, 과적합하지 않으면서 더 나은 성능을 달성하는 복잡한 모델 클래스를 선택할 수 있습니다.[1]

**고위험 의사결정에 대한 함의**: 많은 실제 데이터셋(형사 재범 예측, 대출 채무불이행 등)이 큰 Rashomon 집합을 가질 가능성이 있으므로, 정확도 손실 없이 단순하거나 해석 가능한 모델을 사용할 수 있습니다.[1]

### **추가 후속 연구 방향 제안**

논문의 결과를 바탕으로 다음과 같은 후속 연구 방향을 제안할 수 있습니다:

**Rashomon 비율의 효율적 계산 방법**: 현재 연구는 의사결정 트리와 중요도 샘플링을 사용했지만, 더 일반적이고 효율적인 Rashomon 비율 추정 방법을 개발할 필요가 있습니다. 특히 딥러닝 모델이나 고차원 데이터에 적용 가능한 방법이 요구됩니다.

**능동 학습 및 실험 설계**: Rashomon 집합의 크기를 고려한 능동 학습 전략을 개발하여, 어떤 데이터 포인트를 추가로 라벨링하면 Rashomon 집합을 줄이고 모델 선택의 불확실성을 감소시킬 수 있는지 연구할 수 있습니다.

**공정성 및 편향성 연구**: Rashomon 집합 내에서 공정성 제약을 만족하는 모델의 존재를 연구할 수 있습니다. 큰 Rashomon 집합이 정확도를 유지하면서 공정한 모델을 찾을 가능성을 높일 수 있는지 탐구할 수 있습니다.

**설명 가능한 AI와의 통합**: Rashomon 집합의 개념을 활용하여 모델 설명의 안정성을 평가하고, 여러 동등하게 좋은 모델 간 설명의 일관성을 분석하는 연구가 가능합니다.

**특정 도메인 적용**: 의료, 금융, 형사 사법 등 고위험 분야에서 Rashomon 비율을 실제로 측정하고, 해석 가능한 단순 모델의 존재를 검증하는 도메인별 연구가 필요합니다.

**동적 및 온라인 학습**: 데이터가 시간에 따라 변화하는 환경에서 Rashomon 집합이 어떻게 진화하는지, 그리고 이를 온라인 학습 알고리즘에 어떻게 통합할 수 있는지 연구할 수 있습니다.

**멀티태스크 및 전이 학습**: 여러 관련 태스크에서 공유되는 Rashomon 집합의 구조를 분석하고, 이를 전이 학습에 활용하는 방법을 탐구할 수 있습니다.

**인과 추론과의 연결**: Rashomon 집합 내에서 인과적으로 타당한 모델을 식별하는 방법을 연구하여, 예측뿐만 아니라 인과 관계 파악에도 활용할 수 있습니다.

이 연구는 머신러닝의 해석가능성과 단순성에 대한 중요한 이론적 기반을 제공하며, 실무자들이 복잡한 블랙박스 모델 대신 단순하고 해석 가능한 모델을 선택할 수 있는 과학적 근거를 마련했습니다.[1]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/8043de6a-57bc-4a6f-b4bf-3048d795e18f/1908.01755v4.pdf)
