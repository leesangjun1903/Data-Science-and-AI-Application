
# On the Importance of Initialization and Momentum in Deep Learning

## 1. 핵심 주장과 주요 기여

이 논문은 2013년 ICML에서 발표된 Sutskever 등의 획기적 연구로, **잘 설계된 초기화(Initialization)와 신중하게 조정된 모멘텀(Momentum) 파라미터 스케줄이 깊은 신경망(DNN)과 순환 신경망(RNN)을 훈련하는 데 필수적이라는 것을 증명**했습니다.[1]

논문의 핵심 기여는 다음과 같습니다:[1]

1. **모멘텀의 재평가**: 이전까지 국소 수렴성(local convergence)에서만 연구된 모멘텀이 실제로 깊은 학습의 초기 "과도기 단계(transient phase)"에서 매우 중요한 역할을 한다는 것을 입증
2. **초기화의 중요성**: 이전의 초기화 방식(예: Hinton & Salakhutdinov 2006)이 불충분했으며, 잘 설계된 Sparse Initialization(SI)이 필수적임을 증명
3. **실무적 결과**: 정교하고 복잡한 Hessian-Free(HF) 최적화 방법보다 **단순한 모멘텀 기반 SGD가 비교 가능하거나 우수한 성능**을 달성할 수 있음을 보여줌
4. **RNN 훈련**: 장기 의존성(long-term dependencies) 문제가 있는 RNN도 모멘텀과 적절한 초기화로 성공적으로 훈련 가능함을 입증

## 2. 해결하고자 하는 문제

**주요 문제점들**:[1]

1. **훈련 어려움**: 깊은 신경망과 RNN은 일반적인 SGD로 훈련이 거의 불가능하다고 여겨짐
2. **Vanishing Gradient**: RNN의 역전파에서 그래디언트 소실 문제로 인해 장기 의존성 학습이 어려움
3. **초기화 방식의 부재**: 깊은 네트워크를 위한 체계적인 초기화 기법 부족
4. **모멘텀의 오해**: 모멘텀 방법이 확률적 설정에서 도움이 되지 않는다는 일반적 믿음

## 3. 제안 방법 및 수식

### 3.1 Classical Momentum (CM)

모멘텀 기반 방법의 기본 식:[1]

$$
v_{t+1} = \mu v_t - \varepsilon \nabla f(\theta_t) \quad (1)
$$

$$
\theta_{t+1} = \theta_t + v_{t+1} \quad (2)
$$

여기서:
- $$\varepsilon > 0$$: 학습률
- $$\mu \in $$: 모멘텀 계수[1]
- $$\nabla f(\theta_t)$$: $$\theta_t$$에서의 그래디언트
- $$v_t$$: 속도 벡터

**원리**: 저곡률(low-curvature) 방향의 지속적인 감소가 반복되면서 누적되고, 고곡률(high-curvature) 방향의 진동은 상쇄됩니다.[1]

### 3.2 Nesterov's Accelerated Gradient (NAG)

NAG는 다음과 같이 표현됩니다:[1]

$$
v_{t+1} = \mu v_t - \varepsilon \nabla f(\theta_t + \mu v_t) \quad (3)
$$

$$
\theta_{t+1} = \theta_t + v_{t+1} \quad (4)
$$

**핵심 차이**: CM은 현재 위치 $$\theta_t$$에서 그래디언트를 계산하지만, NAG는 "look-ahead" 위치 $$\theta_t + \mu v_t$$에서 그래디언트를 계산합니다. 이는 **NAG가 더 빠르고 안정적인 속도 조정**을 가능하게 합니다.[1]

### 3.3 이론적 분석: Theorem 2.1

양의 정부호 이차 목적함수에 대한 중요한 정리:[1]

양의 고유값 $$\lambda_i$$를 갖는 이차함수 $$p(y) = \sum_{i=1}^n [p]_i([y]_i)$$에 대해:

- **CM**: 모든 고유방향에서 동일한 모멘텀 $$\mu$$ 사용
- **NAG**: 각 고유방향 $$i$$에서 효과적 모멘텀 $$\mu(1 - \lambda_i \varepsilon)$$ 사용

**의미**: NAG는 고곡률 방향에서 더 낮은 효과적 모멘텀을 사용하여 진동을 방지하고, 더 큰 $$\mu$$ 값을 안전하게 사용할 수 있습니다.[1]

### 3.4 Sparse Initialization (SI)

SI 기법의 구체적 사항:[1]

- 각 신경원 유닛이 이전 레이어의 **임의로 선택된 15개 유닛**과만 연결
- 가중치는 **단위 가우시안(Unit Gaussian) N(0,1)**에서 샘플링
- 편향은 **0으로 초기화**
- 목표: 네트워크 폭에 독립적으로 입력값 크기 제어 및 다양한 활성화 반응 유도

**스케일 조정**: SI 스케일을 2배로 재조정할 때 합리적 성능, 3배 이상에서는 저하 관찰[1]

### 3.5 모멘텀 스케줄

깊은 오토인코더 훈련에 사용된 모멘텀 스케줄:[1]

$$
\mu_t = \min\left(1 - 2^{-1-\log_2(\lfloor t/250 \rfloor + 1)}, \mu_{\text{max}}\right) \quad (5)
$$

여기서 $$\mu_{\text{max}} \in \{0.999, 0.995, 0.99, 0.9, 0\}$$

**동기**: 
- Nesterov(1983)의 강볼록함수용 제안: $$\mu_t = 1 - 3/(t+5)$$
- Nesterov(2003)의 강볼록함수 제안: 상수 $$\mu_t$$ (조건수 의존)
- 이 스케줄은 두 제안을 혼합하여, 초기의 빠른 가속과 후기의 세밀한 수렴 모두 달성[1]

## 4. 모델 구조 및 실험 설정

### 4.1 깊은 오토인코더 실험

세 가지 표준 벤치마크 문제:[1]

| 문제 | 차원 | 데이터 크기 | 아키텍처 |
|------|------|-----------|---------|
| Curves | 784 | 20,000 | 784-400-200-100-50-25-6 |
| MNIST | 784 | 60,000 | 784-1000-500-250-30 |
| Faces | 625 | 103,500 | 625-2000-1000-500-30 |

- 네트워크 깊이: 7-11 레이어
- 활성함수: 표준 로지스틱 시그모이드
- 훈련 업데이트: 750,000회 (미니배치 크기 200)
- 정규화: 없음

### 4.2 RNN 실험 설정

**Echo-State Network (ESN) 기반 초기화**:[1]

| 연결 유형 | 희소성 | 스케일 |
|----------|-------|-------|
| Input-to-Hidden (add) | Dense | 0.001·N(0,1) |
| Input-to-Hidden (mem) | Dense | 0.1·N(0,1) |
| Hidden-to-Hidden | 15 fan-in | 스펙트럼 반경 1.1 |
| Hidden-to-Output | Dense | 0.1·N(0,1) |
| Hidden Bias | Dense | 0 |
| Output Bias | Dense | 출력 평균 |

**중요 특성**:
- 숨겨진 상태의 **스펙트럼 반경을 1.1**로 설정하여 그래디언트 폭발/소실 완화[1]
- 입력-숨겨진 가중치의 신중한 스케일링으로 정보 보존 최적화
- 입력/출력 중심화(Centering) 필수적

## 5. 성능 향상 및 주요 결과

### 5.1 깊은 오토인코더 결과

Table 1: 훈련 이차 오차 비교[1]

| 작업 | 0(SGD) | 0.9N | 0.99N | 0.995N | 0.999N | SGDC | HF† | HF∗ |
|-----|--------|------|-------|--------|--------|------|-----|-----|
| Curves | 0.48 | 0.16 | 0.096 | 0.091 | **0.074** | 0.15 | 0.058 | 0.11 |
| MNIST | 2.1 | 1.0 | 0.73 | 0.75 | 0.80 | 0.9 | 0.69 | 1.40 |
| Faces | 36.4 | 14.2 | 8.5 | 7.8 | **7.7** | NA | 7.5 | 12.0 |

**결과 해석**:
- NAG (N 표시)가 CM (M 표시)보다 대체로 우수한 성능 달성, 특히 높은 $$\mu_{\text{max}}$$ 값에서[1]
- **최고 성능의 NAG는 Martens(2010)의 HF 결과를 초과** (MNIST 제외)
- 순수 SGD($$\mu_{\text{max}} = 0$$)는 심각하게 저하된 성능[1]

### 5.2 저모멘텀 미세조정의 효과

Table 2: 최적화 후기 단계에서 모멘텀 감소의 효과[1]

| 문제 | Before | After |
|-----|--------|-------|
| Curves | 0.096 | 0.074 |
| MNIST | 1.20 | 0.73 |
| Faces | 10.83 | 7.7 |

마지막 1,000 업데이트에서 $$\mu$$를 0.9로 감소시켜 세밀한 수렴 달성[1]

### 5.3 RNN 장기 의존성 결과

Table 5: 인공 RNN 문제들의 제로-원 손실[1]

| 문제 | 0 | 0.9N | 0.98N | 0.995N | 0.9M | 0.98M | 0.995M |
|-----|---|------|-------|--------|------|-------|--------|
| add (T=80) | 0.82 | 0.39 | 0.02 | 0.21 | 0.00025 | 0.43 | 0.62 |
| mul (T=80) | 0.84 | 0.48 | 0.36 | 0.22 | 0.0013 | 0.029 | **0.025** |
| mem-5 (T=200) | 2.5 | 1.27 | 1.02 | 0.96 | 0.63 | 1.12 | 1.09 |
| mem-20 (T=80) | 8.0 | 5.37 | 2.77 | 0.0144 | 0.00005 | 1.75 | 0.0017 |

**주요 발견**:
- NAG가 높은 $$\mu_0$$ 값에서 **지속적으로 우수한 성능**[1]
- 모멘텀 없음($$\mu_0=0$$)일 때는 거의 모든 문제에서 높은 오류
- Martens & Sutskever(2011)의 HF 결과에는 미치지 못하지만, **훨씬 간단한 방법**[1]

## 6. 일반화 성능 향상

### 6.1 과도기 단계(Transient Phase) vs 최적화-추정(Optimization-Estimation) 단계

논문의 핵심 통찰력:[1]

- **과도기 단계**: 초기 훈련 단계로, 목적함수 감소 방향이 여러 연속 그래디언트 추정에서 일관되게 나타남. 모멘텀이 이러한 지속적인 방향을 증폭시켜 **빠른 수렴 달성**
- **최적화-추정 단계**: 최종 국소 수렴 단계로, 확률적 그래디언트 노이즈가 지배적. 이 단계에서 모멘텀의 이론적 장점이 감소

수렴 속도 비교:[1]

- **SGD**: $$O(L/T + \sigma/\sqrt{T})$$ (L은 Lipschitz 상수, σ는 노이즈 분산)
- **가속 그래디언트 (Lan 2010)**: $$O(L/T^2 + \sigma/\sqrt{T})$$

결론: 초기 단계에서 $$L/T$$가 지배적일 때 모멘텀이 우수하며, 최종 단계에서 $$\sigma/\sqrt{T}$$가 지배적일 때는 두 방법이 동등[1]

### 6.2 낮은 모멘텀으로의 전환 전략

논문의 제안:[1]

1. **초기 훈련**: 높은 $$\mu$$ 값(0.99-0.999) 사용하여 저곡률 방향에서 빠른 진행
2. **후기 훈련**: $$\mu$$를 0.9로 감소시켜 고곡률 방향에서 세밀한 수렴 달성
3. **장점**: 보다 정확한 국소 최소값에 도달하여 일반화 성능 개선

**이론적 배경**: Darken & Moody(1993)의 "과도기"와 "최적화-추정" 단계 구분에 기초[1]

### 6.3 손실 지형과 일반화

논문은 직접 일반화 성능을 측정하지 않았지만, 다음을 제시:[1]

- **테스트 오류는 훈련 오류와 높은 상관성**: 오버트레이닝보다는 언더트레이닝 문제가 주요 관심사
- **이유**: 깊은 네트워크에서는 과도기 단계 최적화가 전체 훈련 시간의 대부분을 차지하기 때문

## 7. 한계점(Limitations)

논문의 주요 한계:[1]

1. **테스트 오류 미포함**: "이 논문의 초점이 최적화이기 때문에, 훈련 오류만 보고" - 정규화 및 오버피팅 효과 불명확[1]
2. **초기화 민감도**: SI 스케일이 작업별로 다를 필요성 (예: 0.001 vs 0.1). Sparse Initialization의 일반성 제한
3. **RNN에서 제약**: 
   - HF 방법(Martens & Sutskever 2011)보다 여전히 성능 저하[1]
   - 중심화 필요성 추가 (HF는 불필요)
4. **인공 데이터셋**: 실제 시계열 문제에 대한 일반화 가능성 불명확
5. **하이퍼파라미터 튜닝**: 모멘텀 스케줄이 수동으로 설계되어 자동화 부족

## 8. 모멘텀과 HF의 관계

### 8.1 HF를 모멘텀 방법으로 보기

논문의 혁신적 통찰:[1]

> "Hessian-Free 방법의 "핫-스타트" CG 초기화는 실제로 모멘텀과 유사한 메커니즘"

- CG의 단계별 반복 = 이전 업데이트 정보 재사용 (모멘텀과 유사)
- HF 한 스텝 ≈ NAG (곡률 기반 학습률 사용)
- **결론**: HF는 NAG와 정확한 2차 방법의 하이브리드[1]

### 8.2 개선된 HF 방법

논문은 HF를 "NAG처럼" 동작하도록 수정:[1]

- 라인 서치 제거, 고정 학습률 사용
- 감쇠 상수 점진적 증가
- 작은 미니배치 사용
- 결과: Martens(2010) 초과 성능 달성[1]

## 9. 현대 연구에 미치는 영향

### 9.1 모멘텀 연구의 진화

본 논문 이후 발전상:[2][3][4][5][6][7][8]

1. **적응형 모멘텀**: 
   - 2021년 "Training Deep Neural Networks with Adaptive Momentum": 학습률과 연관된 적응형 헤비볼 모멘텀 제안[2]
   - 2024년 "Adan: Adaptive Nesterov Momentum Algorithm": Nesterov 가속을 새로운 방식으로 재구성[7]

2. **Schedule-Free 최적화**:
   - 2025년 "Connections between Schedule-Free Optimizers, AdEMAMix": 스케줄 없는 최적화 방법 연구[4]

3. **모멘텀의 한계 재검토**:
   - 2024년 ICLR "The Marginal Value of Momentum for Small Learning Rate SGD": 작은 학습률에서 모멘텀의 제한된 효과 입증[6][9]
   - 2025년 "AdaPM: Partial Momentum for LLM Training": 대규모 언어 모델에서 선택적 모멘텀 적용[8]

4. **일반화와 손실 지형**:
   - 2025년 "Improving generalization in DNNs through orthogonality": 모멘텀이 파라미터 벡터 직교성을 감소시키며, 이것이 일반화에 영향을 미친다는 발견[10]

### 9.2 초기화 연구의 발전

본 논문 이후의 진화:[11][12]

1. **Glorot 초기화** (2010년): 본 논문 발표 직후 더 나은 초기화 제안[1]
2. **HE 초기화**: ReLU 네트워크를 위한 특화 초기화
3. **적응형 초기화**: 2024년 "Revisiting the Initial Steps in Adaptive Gradient" - Adam의 초기 단계 초기화 최적화[12]

## 10. 앞으로의 연구 시 고려할 점

### 10.1 현대적 맥락에서의 적용성

1. **Transformer 시대의 적응**:
   - 본 논문의 전통적 모멘텀 관점이 Adam, AdamW 같은 적응형 방법에 비해 제한적[6][7]
   - 하지만 최근 연구들이 선택적 모멘텀 활용으로 메모리 효율성 개선 시도 중[8]

2. **대규모 배치 훈련**:
   - 본 논문(배치 크기 200)과 달리 현대 대규모 훈련(배치 크기 1024-8192)에서 모멘텀 효과 재검토 필요[6]

3. **손실 지형 분석**:
   - 최근 연구는 모멘텀이 더 평탄한 손실 지형으로 수렴하여 일반화 개선[10][6]
   - 일반화 관점의 체계적 분석 필요

### 10.2 추천되는 실험 설계

1. **일반화 성능 측정**:
   - 본 논문이 생략한 테스트 오류 체계적 평가
   - 정규화 기법(L2, 드롭아웃, 배치정규화)과의 상호작용 분석

2. **현대 아키텍처 적용**:
   - CNN, RNN뿐 아니라 Transformer에 대한 모멘텀 효과 연구[10]
   - Vision Transformer, BERT 같은 사전학습 모델의 미세조정 단계에서 모멘텀 역할

3. **이론-실무 격차 해소**:
   - 본 논문의 이차 함수 분석(Theorem 2.1)을 심층 신경망의 비볼록 설정으로 확장
   - 실제 훈련 동역학에서의 모멘텀 효과 메커니즘 재분석

4. **하이퍼파라미터 자동화**:
   - 작업 특성에 따라 최적 $$\mu$$ 스케줄을 자동으로 선택하는 메타-학습 접근
   - 학습률과 모멘텀 간의 상호작용 더욱 정교한 수학적 모델화

5. **에너지 효율성**:
   - 최근 GPU 메모리 제약 상황에서 모멘텀 버퍼 필요성 재평가[8][6]
   - 부분 모멘텀, 저랭크 모멘텀 근사 등 메모리 효율적 변형 연구

### 10.3 현대적 최적화 관점

**기존 관점의 한계**:[6]

- 작은 학습률에서 모멘텀의 실제 이득이 제한적일 수 있음
- 대규모 배치 훈련에서는 모멘텀이 더 유용하나, 작은 배치에서는 한계 존재

**해결 방향**:
- 맥락 의존적(context-dependent) 모멘텀 활용 전략
- 네트워크 계층별 차별화된 모멘텀 적용[8]
- 동적 모멘텀 조정 기법 개발

***

## 결론

Sutskever et al.(2013)의 "On the Importance of Initialization and Momentum in Deep Learning"은 **깊은 신경망 훈련의 가장 기본적인 두 요소—초기화와 모멘텀—을 과학적으로 재평가**한 획기적 논문입니다.[1]

이 논문은 단순한 SGD with Momentum이 복잡한 2차 방법(HF)과 경쟁할 수 있음을 보여주었고, 이는 **현대 딥러닝의 실무적 표준 확립**에 결정적 역할을 했습니다. 하지만 2024년 이후의 연구들은 모멘텀의 역할이 맥락(학습률 크기, 배치 크기, 네트워크 구조)에 따라 크게 달라질 수 있음을 시사하고 있습니다.[10][6][8]

따라서 현대의 연구자들은 본 논문의 근본적인 통찰을 바탕으로 하되, 최신 네트워크 아키텍처, 적응형 최적화 방법, 대규모 훈련 환경의 특성을 반영하여 모멘텀 전략을 재설계할 필요가 있습니영하여 모멘텀 전략을 재설계할 필요가 있습니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/8d6bf6e4-4c09-4ff5-81bd-897c960f15c3/Momentum_Deep.pdf)
[2](https://arxiv.org/pdf/2110.09057.pdf)
[3](https://arxiv.org/abs/2410.07870)
[4](https://arxiv.org/pdf/2502.02431.pdf)
[5](https://arxiv.org/pdf/1907.08610.pdf)
[6](https://arxiv.org/abs/2210.16400v2)
[7](https://arxiv.org/pdf/2208.06677.pdf)
[8](https://arxiv.org/html/2510.09103v1)
[9](https://proceedings.iclr.cc/paper_files/paper/2024/file/3a6935d11910d6f9142b0a1e36fc6753-Paper-Conference.pdf)
[10](https://www.sciencedirect.com/science/article/abs/pii/S0306457325000512)
[11](https://eurasip.org/Proceedings/Eusipco/Eusipco2024/pdfs/0001761.pdf)
[12](https://arxiv.org/html/2412.02153v2)
[13](https://linkinghub.elsevier.com/retrieve/pii/S2001037024002356)
[14](https://ieeexplore.ieee.org/document/10528040/)
[15](https://www.iieta.org/journals/mmep/paper/10.18280/mmep.111008)
[16](https://resjournals.onlinelibrary.wiley.com/doi/10.1111/afe.12667)
[17](https://ijaseit.insightsociety.org/index.php/ijaseit/article/view/20691)
[18](http://medrxiv.org/lookup/doi/10.1101/2024.10.09.24314920)
[19](https://ijarcs.info/index.php/Ijarcs/article/view/7127)
[20](https://dl.acm.org/doi/10.1145/3749369)
[21](https://www.jmq.ro/phuglukr/SFICS_03.03.20242)
[22](https://www.cinc.org/archives/2024/pdf/CinC2024-496.pdf)
[23](http://arxiv.org/pdf/2110.00625.pdf)
[24](http://arxiv.org/pdf/2104.11981.pdf)
[25](https://www.youtube.com/watch?v=7e0nX6WpnDM)
[26](https://openreview.net/forum?id=3JjJezzVkT)
[27](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial4/Optimization_and_Initialization.html)
[28](https://icml.cc/virtual/2025/poster/45760)
[29](https://arxiv.org/html/2510.04988v1)
