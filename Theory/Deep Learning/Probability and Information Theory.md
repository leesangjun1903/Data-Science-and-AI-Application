# Probability and Information Theory

## 3.1 Why Probability?
확률 이론은 원래 사건의 빈도를 분석하기 위해 개발되었습니다. 확률 이론을 포커 게임에서 특정 카드를 그리는 것과 같은 사건을 연구하는 데 어떻게 사용할 수 있는지 쉽게 알 수 있습니다.  
이러한 종류의 사건은 종종 반복 가능합니다. 결과에 확률 p가 있다고 말할 때, 이는 실험(예: 카드 한 장을 그리는 것)을 무한히 반복하면 반복의 비율 p가 그 결과를 초래한다는 것을 의미합니다.  
이러한 종류의 추론은 반복 불가능한 명제에는 즉시 적용되지 않는 것으로 보입니다. 

의사가 환자를 분석하고 독감에 걸릴 확률이 40%라고 말한다면, 이는 매우 다른 무언가를 의미합니다—우리는 환자의 무한히 많은 복제품을 만들 수 없으며, 환자의 다른 복제품이 동일한 증상으로 나타나면서도 기저 조건이 달라질 것이라고 믿을 이유도 없습니다.  
의사가 환자를 진단하는 경우, 우리는 확률을 사용하여 환자가 독감에 걸렸다는 절대 확실성을 나타내고, 1은 절대 확실성을 나타내고 0은 환자가 독감에 걸리지 않았다는 절대 확실성을 나타냅니다.
전자의 확률은 사건 발생률과 직접적으로 관련이 있으며(frequentist probability), 후자의 확률은 질적인 확실성 수준과 관련이 있습니다.(Bayesian probability)

## 3.2 Random Variables
랜덤 변수는 서로 다른 값을 무작위로 가질 수 있는 변수입니다.

## 3.3 Probability Distributions
#### probability distribution

### 3.3.1 Discrete Variables and Probability Mass Functions


#### probability mass function(PMF)
#### joint probability distribution

#### uniform distribution

### 3.3.2 Continuous Variables and Probability Density Functions
#### probability density function (PDF)

## 3.4 Marginal Probability
#### marginal probability distribution
랜덤 변수는 다양한 값을 무작위로 취할 수 있는 변수입니다. 때로는 변수 집합에 대한 확률 분포를 알고 그 중 일부에 대한 확률 분포를 알고 싶어하기도 합니다.  
부분 집합에 대한 확률 분포를 주변 확률 분포라고 합니다.

**sum rule** 에 의하여 부분집합 y 분포의 전체 합을 x 분포의 주변 분포화시키면 x 분포가 될 것입니다. 이는 연속적인 구간으로 확장시켜도 가능합니다.

## 3.5 Conditional Probability
많은 경우, 다른 사건이 발생했을 때 어떤 사건이 발생할 확률에 관심이 있습니다. 이를 조건부 확률이라고 합니다.

행동의 결과를 계산하는 것을 개입 쿼리(**intervention query**) 만들기라고 합니다. 개입 쿼리는 인과 모델링(**causal modeling**)의 영역입니다.

## 3.6 The Chain Rule of Conditional Probabilities
#### chain rule, or product rule
많은 확률 변수에 대한 모든 공동 확률 분포는 단 하나의 변수에 대한 조건부 분포로 분해될 수 있습니다.

## 3.7 Independence and Conditional Independence
확률 분포를 두 가지 요인의 곱으로 표현할 수 있는 경우, 두 개의 확률 변수 x와 y는 독립적입니다. 

x와 y에 대한 조건부 확률 분포가 모든 z 값에 대해 이러한 방식으로 인수분해되는 경우, 임의 변수 z가 주어졌을 때 두 개의 무작위 변수 x, y는 조건부로 독립적(**conditionally independent**)입니다:

## 3.8 Expectation, Variance and Covariance
확률 분포 P(x)에 대한 함수 f(x)의 기대값(**expectation**) 또는 기대값은 x가 P에서 도출될 때 f가 취하는 평균(**average**) 또는 평균값입니다.

#### variance
분산(**variance**)은 확률 분포에서 x의 다른 값을 샘플링할 때 무작위 변수 x의 함수 값이 얼마나 변하는지를 측정하는 척도를 제공합니다.

분산이 낮을 때 f(x) 값은 예상 값 근처에 모여 있습니다. 분산의 제곱근을 표준 편차(**standard deviation**)라고 합니다.

공분산(**covariance**)은 두 값이 서로 얼마나 선형적으로 관련되어 있는지와 이러한 변수들의 규모를 어느 정도 파악할 수 있게 해줍니다:

공분산의 절대값이 높다는 것은 값이 매우 많이 변하고 동시에 각 평균에서 멀리 떨어져 있다는 것을 의미합니다.  
공분산의 부호가 양수이면 두 변수 모두 상대적으로 높은 값을 동시에 취하는 경향이 있습니다.  
공분산의 부호가 음수이면 한 변수가 상대적으로 낮은 값을 취하는 경향이 있고 그 반대의 경우도 마찬가지입니다. 

상관관계(**correlation**)와 같은 다른 측정 방법은 개별 변수의 규모에 영향을 받지 않고 변수가 얼마나 관련되어 있는지만 측정하기 위해 각 변수의 기여도를 정규화합니다.  
공분산과 의존성의 개념은 관련이 있지만 서로 다른 개념입니다. 독립적인 두 변수는 공분산이 0이고 공분산이 0이 아닌 두 변수는 종속적이기 때문에 관련이 있습니다.  
그러나 독립성은 공분산과는 별개의 속성입니다. 두 변수가 공분산이 0이 되려면 변수 간에 선형적인 의존성이 없어야 합니다.  
독립성은 0이 아닌 공분산보다 더 강력한 요구 사항이며, 독립성은 비선형 관계도 배제하기 때문입니다. 두 변수가 종속적이지만 공분산이 0이 되는 것은 가능합니다. 

#### covariance matrix

## 3.9 Common Probability Distributions
### 3.9.1 Bernoulli Distribution
베르누이 분포는 단일 이진 랜덤 변수에 대한 분포입니다.

### 3.9.2 Multinoulli Distribution
다항 분포 또는 범주형 분포(multinoulli, or categorical, distribution)는 k개의 서로 다른 상태를 가진 단일 이산 변수에 대한 분포로, 여기서 k는 유한합니다.

다항 분포(multinoulli distribution)는 다항 분포(**multinomial distribution**)의 특수한 경우입니다. 다항 분포는 {0, . . . . . , n}k의 벡터에 대한 분포로, n개의 샘플이 다항 분포에서 추출될 때 각 k개의 범주가 몇 번 방문되는지를 나타냅니다.  
"multinomial"라는 용어를 사용하여 다항 분포(**multinoulli distribution**)를 지칭하지만, 이는 n = 1인 경우만을 지칭한다는 점을 명확히 하지 않습니다.

베르누이 분포는 특히 강력하기 때문이 아니라 영역이 단순하기 때문에 모든 상태를 열거할 수 있는 이산 변수를 모델링하기 때문에 설명할 수 있습니다.  
연속 변수를 다룰 때는 셀 수 없이 많은 상태가 존재하므로 소수의 매개변수로 설명되는 모든 분포는 분포에 엄격한 제한을 가해야 합니다.

### 3.9.3 Gaussian Distribution
PDF를 평가할 때는 σ(표준편차)을 제곱하고 역산해야 합니다.  
다양한 매개변수 값으로 PDF를 자주 평가해야 할 때, 분포를 매개변수화하는 더 효율적인 방법은 매개변수 β ∈(0, ∞)를 사용하여 분포의 정밀도(**precision**) 또는 역분산을 제어하는 것입니다.

모델링하고자 하는 많은 분포가 실제로 정규 분포에 가깝습니다.  
중심 극한 정리(**central limit theorem**)는 많은 독립적인 무작위 변수의 합이 대략 정규 분포에 가깝다는 것을 보여줍니다.  
즉, 실제로는 시스템을 보다 구조화된 동작을 가진 부분으로 분해할 수 있더라도 많은 복잡한 시스템을 정규 분포 노이즈로 성공적으로 모델링할 수 있습니다. 

동일한 분산을 가진 모든 가능한 확률 분포 중 정규 분포는 실수에 대한 불확실성의 최대량을 인코딩합니다. 따라서 정규 분포는 모델에 최소한의 사전 지식을 삽입하는 분포라고 생각할 수 있습니다. 

정규 분포는 $R^n$ 으로 일반화되며, 이 경우 다변량 정규 분포(**multivariate normal distribution**)로 알려져 있습니다.

단변량 경우와 마찬가지로, 매개변수의 여러 다른 값에 대해 PDF를 여러 번 평가하고자 할 때, 공분산은 분포를 매개변수화하는 계산적으로 효율적인 방법이 아닙니다.  
왜냐하면 PDF를 평가하기 위해 σ을 역변환해야 하기 때문입니다. 대신 정밀 행렬(**precision matrix**) β를 사용할 수 있습니다.

공분산 행렬을 대각선 행렬(diagonal matrix)로 고정하는 경우가 많습니다. 더 간단한 버전은 공분산 행렬이 스칼라 곱하기 항등 행렬인 등방성(**isotropic**) 가우시안 분포입니다.

### 3.9.4 Exponential and Laplace Distributions
딥러닝의 맥락에서 우리는 종종 x = 0의 날카로운 점을 가진 확률 분포를 원합니다. 이를 달성하기 위해 지수 분포(**exponential distribution**)를 사용할 수 있습니다.

임의의 점 µ에 확률 질량의 급격한 피크를 배치할 수 있게 해주는 밀접하게 관련된 확률 분포는 라플라스 분포(**Laplace distribution**)입니다.

### 3.9.5 The Dirac Distribution and Empirical Distribution
경우에 따라 확률 분포의 모든 질량이 단일 지점을 중심으로 클러스터링되도록 지정하고자 합니다. 이는 디랙 델타 함수(**Dirac delta function**)를 사용하여 PDF를 정의함으로써 달성할 수 있습니다.

디랙 델타 함수는 0을 제외한 모든 곳에서 0의 값을 가지면서도 1에 적분하도록 정의됩니다.  
디랙 델타 함수는 각 값 x를 실수 값의 출력과 연관시키는 일반적인 함수가 아니라, 적분할 때 그 성질에 따라 정의되는 일반화된 함수(**generalized function**)라는 다른 종류의 수학적 객체입니다.  
디랙 델타 함수는 0을 제외한 모든 점에 점점 더 적은 질량을 부여하는 일련의 함수의 극한점이라고 생각할 수 있습니다.

디랙델타 분포의 일반적인 용도는 경험적 분포(**empirical distribution**)의 구성 요소입니다.

디랙 델타 분포는 연속 변수에 대한 경험적 분포를 정의하는 데만 필요합니다.  
이산 변수의 경우 상황이 더 간단합니다. 경험적 분포는 "multinoulli distribution"로 개념화될 수 있으며, 각 입력 값과 관련된 확률은 단순히 훈련 집합에서 해당 값의 경험적 빈도(**empirical frequency**)와 같습니다.  
우리는 훈련 예제 데이터셋에서 형성된 경험적 분포를 이 데이터셋에서 모델을 훈련할 때 샘플링하는 분포를 명시하는 것으로 볼 수 있습니다.  
경험적 분포에 대한 또 다른 중요한 관점은 훈련 데이터의 우도(likelihood)를 최대화하는 것이 확률 밀도라는 점입니다.

### 3.9.6 Mixtures of Distributions
다른 단순한 확률 분포를 결합하여 확률 분포를 정의하는 것도 일반적입니다. 분포를 결합하는 일반적인 방법 중 하나는 혼합 분포를 구성하는 것입니다. 혼합 분포는 여러 구성 요소 분포로 구성됩니다.

잠재 변수는 직접 관찰할 수 없는 무작위 변수입니다.  
혼합 모델의 구성 요소 항등식 변수 c가 예를 제공합니다. 잠재 변수(**latent variable**)는 합동 분포를 통해 x와 관련될 수 있으며, 이 경우 P(x,c) = P(x |c)P(c)입니다.  
잠재 변수에 대한 분포 P(c)와 잠재 변수를 가시 변수와 연관시키는 분포 P(x |c)는 잠재 변수를 참조하지 않고도 분포 P(x)의 모양을 결정합니다.

매우 강력하고 일반적인 유형의 혼합 모델은 구성 요소 p(x |c = i)가 가우시안인 가우시안 혼합 모델(**Gaussian mixture model**)입니다.  
각 구성 요소는 별도로 매개변수화된 평균 µ(i)와 공분산 σ(i)를 갖습니다. 일부 혼합물은 더 많은 제약 조건을 가질 수 있습니다. 

평균과 공분산 외에도 가우시안 혼합물의 매개변수는 각 구성 요소 i에 주어진 사전 확률(**prior probability**) αi = P(c = i)을 지정합니다.  
"사전"이라는 단어는 x를 관찰하기 전에 모델의 c에 대한 믿음을 표현한다는 것을 나타냅니다. 이에 비해 P(c |x)는 사후 확률(**posterior probability**)로, x를 관찰한 후에 계산되기 때문입니다.  
가우시안 혼합물 모델은 충분한 구성 요소를 가진 가우시안 혼합물 모델에 의해 임의의 특정 0이 아닌 오차로 매끄러운 밀도를 근사할 수 있다는 점에서 보편적인 밀도 근사치(**universal approximator**)입니다.

<img width="833" alt="스크린샷 2025-04-22 오후 2 09 49" src="https://github.com/user-attachments/assets/c7bac68e-0f1b-4be6-bbe4-8c09d28aacb7" />

## 3.10 Useful Properties of Common Functions
#### logistic sigmoid
로지스틱 시그모이드는 베르누이 분포의 φ 매개변수를 생성하는 데 일반적으로 사용됩니다. 왜냐하면 그 범위는 (0,1)이며, 이는 φ 매개변수의 유효한 값 범위 내에 있기 때문입니다.

#### softplus function
소프트플러스 함수는 범위가 (0, ∞)이기 때문에 정규 분포의 β 또는 σ 매개변수를 생성하는 데 유용할 수 있습니다.

소프트플러스 함수는 양의 부분 함수인 $x^+ = max(0,x)$의 평활화된 버전으로 의도됩니다.

## 3.11 Bayes’ Rule
우리는 종종 P(y |x)를 알고 P(x |y)를 알아야 하는 상황에 처하게 됩니다. 다행히도 P(x)도 알고 있다면 베이즈 법칙을 사용하여 원하는 양을 계산할 수 있습니다.

## 3.12 Technical Details of Continuous Variables
연속 확률 변수와 확률 밀도 함수에 대한 적절한 형식적 이해를 위해서는 측도 이론이라는 수학의 한 분야에서 확률 이론을 개발해야 합니다.  
측도 이론(**measure theory**)은 이 교과서의 범위를 벗어나지만, 측도 이론이 해결하는 데 사용되는 몇 가지 문제를 간략하게 설명할 수 있습니다.  
3.3.2절에서 우리는 연속 벡터 값 x가 어떤 집합 S에 속할 확률이 집합 S에 대한 p(x)의 적분으로 주어진다는 것을 보았습니다.  
집합 S의 일부 선택은 역설을 일으킬 수 있습니다. 예를 들어, p(x ∈ S1) + p(x ∈ S2) >1이지만 S1 ∩ S2 = ∅이 되도록 두 집합 S1과 S2를 구성할 수 있습니다.  
이러한 집합은 일반적으로 실수의 무한 정밀도를 매우 많이 활용하여 구성되며, 예를 들어 유리수 집합을 변환하여 정의된 프랙탈 모양의 집합이나 집합을 만드는 것입니다.

측도 이론은 점 집합이 무시할 수 있을 정도로 작다는 것을 엄격하게 설명하는 방법을 제공합니다. 이러한 집합은 측도 0(**measure zero**)을 갖는다고 합니다.  
측도 0의 집합을 제외한 모든 공간에서 거의 모든 곳(almost everywhere)에 적용되는 속성입니다.

#### Jacobian matrix

## 3.13 Information Theory
정보 이론은 신호에 얼마나 많은 정보가 존재하는지 정량화하는 것을 중심으로 하는 응용 수학의 한 분야입니다.  
정보 이론은 다양한 인코딩 방식을 사용하여 최적의 코드를 설계하고 특정 확률 분포에서 샘플링된 메시지의 예상 길이를 계산하는 방법을 알려줍니다.  

가능성이 높은 이벤트는 정보 함량이 낮아야 하며, 극단적인 경우 발생이 보장되는 이벤트는 정보 함량이 전혀 없어야 합니다.  
가능성이 낮은 이벤트는 정보 함량이 높아야 합니다.  
독립적인 이벤트는 추가 정보가 있어야 합니다. 예를 들어, 던져진 동전이 앞면으로 두 번 나왔다는 사실을 알게 되면 앞면으로 한 번 나왔다는 사실을 알게 되는 것보다 두 배 더 많은 정보를 전달해야 합니다.

#### self-information

밑이 e인 경우 I(x)의 정의는 nat 단위로 작성됩니다. 하나의 nat은 확률 $$\frac{1}{e}$$의 이벤트를 관찰하여 얻은 정보의 양입니다.  
다른 텍스트에서는 밑이 2인 e 로그와 비트 또는 샤논(**bits or shannons**)이라고 불리는 단위를 사용합니다.  

자기 정보는 단일 결과만을 다룹니다. 섀넌 엔트로피(**Shannon entropy**)를 사용하여 전체 확률 분포에서 불확실성의 양을 정량화할 수 있습니다.

즉, 분포의 섀넌 엔트로피는 해당 분포에서 추출된 이벤트에서 예상되는 정보의 양입니다.  
이는 분포 P에서 추출한 기호를 인코딩하는 데 필요한 비트 수(로그가 밑수 2인 경우, 그렇지 않은 경우 단위가 서로 다른 경우)에 대한 하한을 제공합니다.  
거의 결정론적인 분포(결과가 거의 확실한 경우)는 엔트로피가 낮고, 균일에 가까운 분포는 엔트로피가 높습니다. 시연을 위해 그림 3.5를 참조하세요. x가 연속적일 때 섀넌 엔트로피는 미분 엔트로피로 알려져 있습니다.

<img width="833" alt="스크린샷 2025-04-22 오후 2 28 40" src="https://github.com/user-attachments/assets/eb83ac0a-bede-4fa9-8a84-f93124e39a34" />

동일한 확률 변수 x에 대해 두 개의 개별 확률 분포 P(x)와 Q(x)가 있는 경우, Kullback-Leibler (KL) 발산(**Kullback-Leibler (KL) divergence**)을 사용하여 이 두 분포가 얼마나 다른지 측정할 수 있습니다.

KL 발산은 많은 유용한 특성을 가지고 있으며, 특히 음수가 아닙니다. KL 발산은 이산 변수의 경우 P와 Q가 동일한 분포이거나 연속 변수의 경우 "거의 모든 곳"일 때만 0입니다.  
KL 발산은 음수가 아니며 두 분포 간의 차이를 측정하기 때문에 이러한 분포 간의 거리를 측정하는 것으로 개념화되는 경우가 많습니다. 

<img width="833" alt="스크린샷 2025-04-22 오후 2 30 16" src="https://github.com/user-attachments/assets/c6cca3e8-ed9b-4640-9939-57706bb5bedd" />

KL 발산과 밀접하게 관련된 양은 **cross-entropy** H(P,Q) = H(P) + DKL(P ∥Q)로, KL 발산과 유사하지만 왼쪽에 있는 항이 없습니다.

Q에 대한 교차 엔트로피를 최소화하는 것은 생략된 항에 Q가 참여하지 않기 때문에 KL 발산을 최소화하는 것과 같습니다.

## 3.14 Structured Probabilistic Models
그래프를 사용하여 이러한 종류의 인수분해를 설명할 수 있습니다.  
여기서 우리는 그래프 이론의 의미에서 "그래프"라는 단어를 사용합니다: 간선으로 서로 연결될 수 있는 정점 집합입니다.  
확률 분포의 인수분해를 그래프로 표현할 때 이를 구조화 확률 모델 또는 그래픽 모델(**structured probabilistic model, or graphical model**)이라고 부릅니다.

구조화된 확률 모델에는 두 가지 주요 유형이 있습니다: 유향 확률 모델과 무향 확률 모델(directed and undirected)입니다.  
두 종류의 그래픽 모델 모두 그래프의 각 노드가 랜덤 변수에 해당하는 그래프 G를 사용하며, 두 랜덤 변수를 연결하는 엣지는 확률 분포가 두 랜덤 변수 간의 직접적인 상호작용을 나타낼 수 있음을 의미합니다.  

유향 모델(**directed**)은 유향 엣지가 있는 그래프를 사용하며, 위의 예와 같이 조건부 확률 분포로의 인수분해를 나타냅니다.

<img width="833" alt="스크린샷 2025-04-22 오후 2 35 23" src="https://github.com/user-attachments/assets/5b63ea64-ab5b-46f4-b91d-d97428c19601" />

무방향 모델은 무방향 간선을 가진 그래프를 사용하며, 이는 함수 집합으로의 인수분해를 나타냅니다. 유방향 경우와 달리 이러한 함수는 일반적으로 어떤 종류의 확률 분포도 아닙니다.

<img width="833" alt="스크린샷 2025-04-22 오후 2 38 12" src="https://github.com/user-attachments/assets/a15b6efe-f3e6-4530-98f0-e61c82310cf9" />

G에서 서로 연결된 모든 노드 집합을 클리크라고 합니다.

무작위 변수의 구성 확률은 이러한 모든 요인의 곱에 비례하며, 더 큰 요인 값을 초래하는 할당이 더 가능성이 높습니다.  
물론 이 곱이 1로 합이 된다는 보장은 없습니다. 따라서 정규화된 확률 분포를 얻기 위해 φ 함수의 곱의 모든 상태에 대한 합 또는 적분으로 정의된 정규화 상수 Z로 나눕니다.




