# Tree SHAP : Consistent Individualized Feature Attribution for Tree Ensembles

**핵심 주장 및 기여**  
이 논문은 기존 트리 앙상블(Gradient Boosting, Random Forest 등)의 피처 중요도 산출 방식이 **일관성(inconsistency)** 문제로 인해 모델 변경 시 오히려 중요도가 감소할 수 있음을 지적한다. 이를 해결하기 위해 게임 이론 기반의 SHAP(SHapley Additive exPlanation) 값을 트리 모델에 **정확하고 빠르게** 적용하는 Tree SHAP 알고리즘을 제안하며, SHAP 상호작용 값(SHAP interaction values)까지 확장하여 다음을 달성한다:  
- **일관성 보장**: 피처 영향력 증가 시 중요도 감소 불가  
- **국소 정확성**: 개별 예측을 정확히 분해  
- **지수→다항 시간 축소**: 계산 복잡도를 $$O(TL2^M)$$에서 $$O(TLD^2)$$로 개선  

이로써 SHAP 기반 개별 설명을 대규모 트리 앙상블에 실용적으로 적용 가능케 하고, 새로운 시각화(요약 플롯·의존성 플롯) 및 감독 클러스터링 등 응용을 제시한다.[1]

## 1. 해결하고자 하는 문제  
트리 앙상블의 전통적 피처 중요도(Gain, Split Count, Permutation, Saabas)는 모델 구조 변경이나 피처 영향도 증가에도 불구하고 중요도가 반대로 감소할 수 있는 *비일관성* 문제를 안고 있다. 이는 모델 디버깅과 피처 비교에 심각한 오류를 초래한다.[1]

## 2. 제안 방법  
### 2.1 SHAP 값의 정의 및 성질  
SHAP 값은 모델 출력 $$f(x)$$를 각 피처 기여도의 합으로 분해하는 **Additive Feature Attribution** 방식으로, 모든 피처 순열에 걸쳐 조건부 기대값 차이를 평균한 고전적인 Shapley 값으로 정의된다:  

$$
\phi_i = \sum_{S \subseteq N \setminus \{i\}} \frac{|S|!\,(M-|S|-1)!}{M!}\bigl[f_{x}(S\cup\{i\}) - f_{x}(S)\bigr]
$$  

여기서 $$\phi_i$$는 피처 $$i$$의 기여도이며, 세 가지 조건—국소 정확성(local accuracy), 결측성(missingness), 일관성(consistency)—을 만족하는 유일한 해임이 증명되었다.[1]

### 2.2 Tree SHAP: 다항 시간 알고리즘  
- **기존 방식**: 모든 부분집합 $$2^M$$에 대해 조건부 기대값을 계산하여 지수적 시간 소요  
- **Tree SHAP**: 깊이 우선 순회를 통해 경로별 부분집합 크기를 추적하고, EXTEND/UNWIND 연산으로 피처별 가중치를 유지하며 재귀적으로 계산  
- **시간 복잡도**: $$O(TLD^2)$$, 메모리 $$O(D^2M)$$로 축소 (균형 트리 기준 $$D\approx\log L$$)[1]

### 2.3 SHAP 상호작용 값  
두 피처 간 상호작용을 측정하는 **Shapley interaction index**를 이용해 상호작용 기여도 $$\phi_{i,j}$$를 정의하고 이를 SHAP 값과 분리:  

$$
\phi_{i,j} = \sum_{S \subseteq N \setminus \{i,j\}} \frac{|S|!\,(M-|S|-2)!}{2\,(M!)} \Delta_{i,j}(S)
$$  

$$\Delta_{i,j}(S)$$는 $$i,j$$ 동시 존재 시 기대값 차이로, 메인 효과 $$\phi_{i,i}$$는 $$\phi_i - \sum_{j\neq i}\phi_{i,j}$$로 계산한다.[1]

## 3. 모델 구조 및 실험 결과  
- **Tree SHAP 구현**: XGBoost, LightGBM에 통합  
- **실험**  
  - 사용자 직관 일치도: Mechanical Turk 참여자 34명 대상 모델 A 실험에서 SHAP 값이 직관적으로 가장 자연스러운 기여 분배를 보임.[1]
  - 계산 속도: 1,000그루 깊이10 트리, 100피처 모델 설명을 0.08초 내 완료.[1]
  - 감독 클러스터링: SHAP 기반 클러스터링이 Saabas 대비 군집 내 모델 출력 일관성(R²) 높음.[1]
  - 영향 피처 식별: 트위터 감성 분석에서 SHAP이 최우선 부정 단어 탐지 정확도 최고.[1]

## 4. 성능 향상 및 한계  
**성능 향상**  
- **일관성 보장**으로 피처 비교 신뢰도 극대화  
- **지수→다항 시간** 계산으로 대규모 앙상블 설명 가능  
- 상호작용, 요약·의존성 플롯 등 **새로운 시각화·응용** 제공  

**한계**  
- **메모리 사용**: 깊이 및 피처 수 증가 시 $$O(D^2M)$$ 메모리 필요  
- **다차원 상호작용**: 두 피처 이상의 고차 상호작용 계산 복잡도 급증  
- **특정 모델 적용**: 트리 이외 모델에는 별도 최적화 필요[1]

## 5. 일반화 성능 향상 가능성  
Tree SHAP 기반 설명 기법은 모델 과적합의 원인인 불필요한 피처 의존도를 식별하고, 상호작용 취약 지점을 드러내며, 개별 샘플 수준에서 오탐지 사례를 찾아낼 수 있으므로 **일반화 성능을 강화**할 수 있다. 특히 감독 클러스터링으로 주요 부류별 설명 차이 파악, SHAP 의존성 플롯으로 상호작용별 과적합 경향 관찰이 가능하다.

## 6. 향후 연구 영향 및 고려 사항  
앞으로 연구에서는 다음을 고려해야 한다:  
- **확장성**: 메모리 최적화 및 다차원 상호작용 효율적 계산  
- **타 모델 적용**: 신경망·그래프 모델에 대한 SHAP 가속 알고리즘 개발  
- **자동화된 진단**: SHAP 설명 기반 피처 셀렉션 및 과적합 감시 시스템 설계  
- **윤리적 해석**: 의료·금융 분야 적용 시 일관성 보장이 설명 책임성 강화에 미치는 영향 검토  

이 논문은 트리 기반 모델 해석의 이론적·실용적 토대를 확립하여 후속 연구와 응용 개발에 핵심 가이드라인을 제공한다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/6e4e1455-f0a6-40bb-b27f-973e8aa8a762/1802.03888v3.pdf)
