# Deep Learning based Recommender System: A Survey and New Perspectives

## 1. 논문의 핵심 주장과 주요 기여

이 논문은 **딥러닝 기반 추천 시스템**의 포괄적인 조사 및 분류 체계를 제공합니다. 저자들의 핵심 주장은 다음과 같습니다:[1]

**핵심 주장:**
- 딥러닝은 기존의 선형 기반 추천 모델(행렬 분해, 팩터라이제이션 머신 등)의 한계를 극복하고, 사용자-아이템 간의 복잡한 비선형 관계를 효과적으로 포착할 수 있습니다.
- 딥러닝의 **특징 표현 학습(Representation Learning)** 능력을 통해 텍스트, 이미지, 오디오, 비디오 등 다양한 모달리티의 데이터를 통합하여 처리할 수 있습니다.
- 시간적 역동성과 순차 패턴을 모델링할 수 있어, 세션 기반 추천, 시계열 기반 추천 등의 새로운 응용을 가능하게 합니다.

**주요 기여:**
1. **체계적 분류 체계**: 딥러닝 기반 추천 모델을 신경망 구성 요소(MLP, Autoencoder, CNN, RNN, RBM, NADE, Attention, GAN, DRL) 기준으로 분류하고, 하이브리드 모델 범주를 추가하여 100개 이상의 논문을 조직화했습니다.[1]

2. **포괄적 상태 분석**: 각 구조별 대표적인 모델들(NCF, DeepFM, AutoRec, CDAE, GRU4Rec, IRGAN 등)의 동작 원리, 수식, 성능 특징을 상세히 설명합니다.

3. **실무적 시사점**: 산업 사례(Netflix 80%, YouTube 60% 추천 데이터 기반 운영), 확장성 분석, 평가 방법론의 문제점을 지적합니다.

***

## 2. 논문이 해결하고자 하는 문제와 제안 방법

### 2.1 주요 문제점

**해결 대상 문제:**[1]
1. **정보 과부하 문제**: 웹상의 폭발적 정보 증가에 따른 개인화 필요성
2. **추천 시스템의 한계**: 기존 협업 필터링과 행렬 분해의 선형성 제약
3. **다중 모달 데이터 처리**: 텍스트, 이미지, 비디오 등 이질적 정보의 통합 어려움
4. **시간적 역동성 포착 부족**: 사용자 선호도 변화와 세션 기반 행동 모델링의 한계

### 2.2 제안 방법의 수학적 기초

#### **기본 설정:**[1]
- M명의 사용자, N개의 아이템
- 상호작용 행렬: $$R \in \mathbb{R}^{M \times N}$$, 예측 행렬: $$\hat{R}$$
- 사용자 u의 아이템 i에 대한 선호도: $$r_{ui}$$, 예측값: $$\hat{r}_{ui}$$
- 사용자 잠재 요인: $$U \in \mathbb{R}^{M \times k}$$, 아이템 잠재 요인: $$V \in \mathbb{R}^{N \times k}$$

#### **주요 모델별 수식:**

**1) Neural Collaborative Filtering (NCF):**[1]

$$
\hat{r}_{ui} = f(U^T \cdot s^{\text{user}}_u, V^T \cdot s^{\text{item}}_i | U, V, \theta)
$$

여기서 $$f(\cdot)$$는 다층 퍼셉트론, $$\theta$$는 네트워크 파라미터입니다.

손실함수 (암묵적 피드백):[1]

$$
L = -\sum_{(u,i) \in O \cup O^-} r_{ui} \log \hat{r}_{ui} + (1-r_{ui}) \log(1-\hat{r}_{ui})
$$

**2) Deep Factorization Machine (DeepFM):**[1]

$$
\hat{r}_{ui} = \sigma(y_{FM}(x) + y_{MLP}(x))
$$

- $$y_{FM}(x)$$: 팩터라이제이션 머신의 저차 특징 상호작용
- $$y_{MLP}(x)$$: MLP의 고차 특징 상호작용
- $$\sigma(\cdot)$$: 시그모이드 활성화 함수

**3) Wide & Deep Learning:**[1]

$$
P(\hat{r}_{ui} = 1|x) = \sigma(W^T_{\text{wide}}\{x, \phi(x)\} + W^T_{\text{deep}}a^{(l_f)} + \text{bias})
$$

- Wide 부분: $$y = W^T_{\text{wide}}\{x, \phi(x)\} + b$$ (일반화된 선형 모델)
- Deep 부분: $$\alpha^{(l+1)} = f(W^{(l)}_{\text{deep}}\alpha^{(l)} + b^{(l)})$$ (MLP)

**4) AutoRec (Item-based):**[1]

$$
\arg\min_{\theta} \sum_{i=1}^{N} \|r^{(i)} - h(r^{(i)};\theta)\|^2_O + \lambda \cdot \text{reg}
$$

여기서 재구성 함수:

$$
h(r^{(i)};\theta) = f(W \cdot g(V \cdot r^{(i)} + \mu) + b)
$$

- $$\|\cdot\|^2_O$$: 관측된 평점만 고려
- $$f(\cdot), g(\cdot)$$: 활성화 함수

**5) Collaborative Denoising Auto-Encoder (CDAE):**[1]

$$
\arg\min_{W_1, W_2, V, b_1, b_2} \frac{1}{M}\sum_{u=1}^{M} \mathbb{E}_{p(\tilde{r}^{(u)}_{\text{pref}}|r^{(u)}_{\text{pref}})} [\ell(\tilde{r}^{(u)}_{\text{pref}}, h(\tilde{r}^{(u)}_{\text{pref}}))] + \lambda \cdot \text{reg}
$$

재구성:

$$
h(\tilde{r}^{(u)}_{\text{pref}}) = f(W_2 \cdot g(W_1 \cdot \tilde{r}^{(u)}_{\text{pref}} + V_u + b_1) + b_2)
$$

**6) GRU4Rec (세션 기반 추천):**[1]
순위 손실 함수:

$$
L_s = \frac{1}{S}\sum_{j=1}^{S} [\sigma(\hat{r}_{sj} - \hat{r}_{si}) + \sigma(\hat{r}^2_{sj})]
$$

- $$S$$: 샘플 크기
- $$\hat{r}\_{si}, \hat{r}_{sj}$$: 음수/양수 아이템 점수

**7) Deep Semantic Similarity based Personalized Recommendation (DSPR):**[1]

```math
L = -\sum_{(u,i^*)} \left[\log(e^{\text{sim}(u,i^*)}) - \log\left(\sum_{(u,i^-) \in D^-} e^{\text{sim}(u,i^-)}\right)\right]
```

**8) GAN 기반 추천 (IRGAN):**[1]

```math
J_{G^*, D^*} = \min_{\theta} \max_{\phi} \sum_{n=1}^{N} \left(\mathbb{E}_{d \sim p_{\text{true}}(d|q_n,r)} [\log D(d|q_n)] + \mathbb{E}_{d \sim p_{\theta}(d|q_n,r)} [\log(1-D(d|q_n))]\right)
```

### 2.3 모델 구조의 특징

**각 아키텍처별 설계 원리:**[1]

| 모델 유형 | 주요 강점 | 설계 목적 |
|---------|---------|---------|
| **MLP 기반** | 비선형 변환, 메모리화 | 사용자-아이템 상호작용의 비선형 포착 |
| **Autoencoder** | 특징 표현 학습, 재구성 | 콘텐츠 정보와 협업 신호 통합 |
| **CNN** | 다중 모달 처리, 지역/전역 특징 | 이미지, 텍스트 등 구조화된 데이터 처리 |
| **RNN/LSTM** | 순차 모델링, 시간적 역동성 | 세션 기반, 시계열 추천 |
| **Attention** | 선택적 초점, 해석성 | 중요 정보 필터링, 설명 가능성 제공 |
| **GAN** | 생성 및 판별 학습 | 음수 샘플 생성, 적대적 학습 |

---

## 3. 성능 향상 메커니즘

### 3.1 비선형 표현 능력

기존 행렬 분해는 선형 모델:

$$
\text{MF: } \hat{r}_{ui} = U_u^T V_i \quad \text{(선형 결합)}
$$

**딥러닝의 개선:**

$$
\text{DNN: } \hat{r}_{ui} = f_L(\cdots f_2(f_1(U_u \oplus V_i)) \cdots) \quad \text{(다중 비선형 변환)}
$$

신경망 근사 이론에 의해, 충분한 은닉층과 뉴런으로 임의의 연속함수를 원하는 정확도로 근사 가능합니다.[1]

### 3.2 특징 표현 학습의 우월성

**자동 특징 공학:**[1]
- 기존 방식: 수동 특징 추출 → 비용 높음, 도메인 지식 필요
- 딥러닝: 원본 데이터 → 계층적 표현 학습 → 자동화

**다중 모달 통합:**
- CNN으로 이미지 처리: 시각적 특징 추출
- RNN으로 텍스트 처리: 의미론적 정보 추출
- 통합 임베딩 공간에서 최종 추천

### 3.3 정규화 및 일반화 기법

**Dropout과 Batch Normalization:**[1]
- **Dropout**: 과적합 방지, 앙상블 효과
- **Batch Normalization**: 내부 공변량 이동 완화, 학습 안정화

**손실함수 설계:**
- 명시적 피드백: 제곱 손실 $$\|r - \hat{r}\|^2$$
- 암묵적 피드백: 교차 엔트로피 $$-r \log \hat{r} - (1-r) \log(1-\hat{r})$$
- 순위 손실: Bayesian Personalized Ranking (BPR) 변형

**부정 샘플링:**

$$
L = -\sum_{(u,i^+)} \log \sigma(s(u,i^+)) - \sum_{(u,i^-)} \log \sigma(-s(u,i^-))
$$

***

## 4. 모델의 일반화 성능 향상 관련 내용

### 4.1 일반화 성능의 개념적 기초

논문에서 **일반화 성능(Generalization)**은 다음과 같은 맥락에서 논의됩니다:[1]

**Wide & Deep Learning의 설계 철학:**

$$
\text{총 성능} = \text{메모리화(Memorization)} + \text{일반화(Generalization)}
$$

- **Wide 부분** (메모리화): 직접 특징 조합을 통해 훈련 데이터의 구체적 패턴 포착
- **Deep 부분** (일반화): 다층 비선형 변환을 통해 추상적, 일반화된 표현 학습

### 4.2 표현 학습을 통한 일반화

**Collaborative Deep Learning (CDL)의 예시:**[1]

CDL은 두 가지 성분을 결합합니다:
1. **인식 성분(Perception)**: 스택된 노이징 제거 오토인코더 (SDAE)
2. **작업 특화 성분(Task-specific)**: 확률적 행렬 분해 (PMF)

생성 과정:

$$
\begin{aligned}
V_i &= \epsilon_i + X^T_{L_2, i*} \quad \text{(아이템 잠재 벡터)} \\
U_u &\sim \mathcal{N}(0, \lambda^{-1}_u I_D) \quad \text{(사용자 잠재 벡터)} \\
r_{ui} &\sim \mathcal{N}(U_u^T V_i, C^{-1}_{ui}) \quad \text{(평점 생성)}
\end{aligned}
$$

**일반화 메커니즘**: 아이템 특징(텍스트, 이미지)에서 학습한 표현이 **보이지 않은 사용자-아이템 쌍**에 대해서도 좋은 예측을 제공합니다.

### 4.3 순차 모델링을 통한 시간적 일반화

**RNN 기반 모델의 장점:**[1]

**Recurrent Recommender Network (RRN):**

$$
\hat{r}_{ui|t} = f(u^t_u, v^t_i, u_u, v_i)
$$

- $$u^t_u, v^t_i$$: LSTM으로 학습한 동적 상태 (시간에 따른 변화)
- $$u_u, v_i$$: 표준 MF로 학습한 정상 잠재 속성 (고정 특성)

**일반화 특성**:
- 새로운 시간대 데이터에 대한 예측 (외삽, Extrapolation)
- 계절성과 장기 추세 동시 포착
- 사용자 선호도 변화의 **점진적 변화 패턴**을 학습하여 미래 데이터에 적용

### 4.4 세션 기반 추천의 일반화

**GRU4Rec의 일반화 기제:**[1]

기존 협업 필터링의 한계:
- 로그인하지 않은 사용자 → 사용자 ID 없음 → 협업 신호 없음 → 극심한 희소성

**GRU4Rec의 해결**:
```
세션 내 행동 순서 → GRU → 차기 아이템 확률
P(i_{t+1} | i_1, ..., i_t)
```

**일반화 우월성**:
- 사용자 ID에 의존하지 않음 → 새 사용자에게 즉시 적용 가능
- 세션 내 아이템 간 **순차 패턴**을 학습 → 유사한 행동 패턴의 다른 세션으로 일반화
- 손실함수의 개선 (TOP1-max, BPR-max)으로 그래디언트 소실 문제 극복

### 4.5 Attention 메커니즘의 일반화 기여

**Attention의 역할:**[1]

표준 Attention:

$$
\alpha_i = \frac{\exp(q \cdot k_i)}{\sum_j \exp(q \cdot k_j)}
$$

**일반화 개선**:
- **선택적 초점**: 훈련 데이터의 노이즈 무시, 본질적 패턴만 학습
- **해석성 제공**: Attention 가중치로 중요 특징 파악 → 모델 신뢰도 향상
- **이전 학습(Transfer)**: Attention 패턴이 도메인을 초월하여 전이 가능

### 4.6 다중 작업 학습(Multi-Task Learning)의 일반화

**Multi-Task의 원리:**[1]

보조 작업(예: 아이템 메타데이터 예측)을 추가하면:

$$
L_{\text{total}} = L_{\text{주작업}} + \lambda L_{\text{보조작업}}
$$

**일반화 이점**:
1. **암묵적 데이터 증강**: 제한된 훈련 데이터를 보조 작업으로 보강
2. **공유 표현 정규화**: 두 작업이 강요하는 제약이 과적합 방지
3. **특징 공간 탐색 강화**: 단일 작업보다 더 풍부한 표현 학습

### 4.7 일반화 한계와 문제점

논문은 다음과 같은 **현존 한계**를 지적합니다:[1]

| 한계 | 원인 | 영향 |
|-----|-----|------|
| **콜드 스타트** | 새 사용자/아이템에 대한 데이터 부족 | 일반화 성능 급격히 저하 |
| **희소성** | 대부분 상호작용 미관측 | 효과적 특징 학습 방해 |
| **분포 이동** | 시간에 따른 사용자 선호도 변화 | 고정된 모델의 예측력 감소 |
| **해석성 부족** | 블랙박스 특성 | 신뢰성 감소, 문제 진단 어려움 |

***

## 5. 모델 평가 및 성능 메트릭

**주요 평가 방법:**[1]
- **평점 예측**: MAE, RMSE
- **순위 예측**: nDCG, Recall@K, Hit Rate
- **효율성**: 학습/추론 시간, 메모리 사용량

**논문의 평가 방법론 비판:**[1]

저자들은 "필드가 더 나은, 통일된 평가 기준이 필요하다"고 강조합니다:
1. 테스트 셋 분할 방식의 **임의성** 문제
2. 데이터셋 선택의 **일관성 부족**
3. 기준 모델(Baseline) 구성의 **자의성**

예시: NCF는 원론문에서 높은 성능이지만, 다른 논문에서는 낮은 순위로 평가됨.

---

## 6. 논문의 한계

### 6.1 구조적 한계

**인식론적 한계:**[1]
- **해석성 부족**: 신경망 은닉층의 활성화가 의미적으로 해석 불가능
- **과적합 위험**: 깊은 네트워크의 매개변수 수로 인한 과적합 경향
- **계산 비용**: GPU 의존성, 대규모 데이터 필요

**실무 한계:**[1]
- **하이퍼파라미터 튜닝 복잡성**: 모델별로 다양한 조정 필요
- **재현성 문제**: 동일한 결과 재현 어려움
- **배포 난제**: 실시간 추천에 필요한 추론 속도 확보 어려움

### 6.2 논문의 미해결 문제

논문에서 향후 연구로 제시하는 **오픈 이슈:**[1]

1. **확장성 (Scalability)**
   - 비정상(Non-stationary) 데이터 처리
   - 고차원 텐서 연산의 효율화
   - 지식 증류(Knowledge Distillation)를 통한 모델 압축

2. **교차 도메인 추천 (Cross-Domain)**
   - 도메인 간 사용자 행동 차이의 모델링
   - 도메인 이동(Domain Shift) 해결
   - 일반화 가능한 전이 학습

3. **평가 표준화**
   - 벤치마크 데이터셋 부족 (ImageNet, MNIST 같은)
   - 블라인드 테스트 셋 필요
   - 시간 기반 분할의 타당성 검증

4. **추론 및 이유 제시 (Reasoning & Explainability)**
   - 다단계 추론 구조 개발
   - 메타 경로(Meta-path) 기반 추론
   - 사용자가 이해 가능한 추천 이유 제시

***

## 7. 일반화 성능 향상의 종합 분석

### 7.1 일반화 성능이 중요한 이유

**추천 시스템의 특수성:**[1]
- **배포 환경의 다양성**: MovieLens(온라인) vs 상용 플랫폼(대규모, 실시간)
- **사용자 행동의 변동성**: 계절성, 트렌드, 일시적 관심의 변화
- **새로운 아이템/사용자의 지속적 유입**: 보이지 않은 데이터에 대한 적응 필요

### 7.2 일반화 성능 향상의 메커니즘 요약

| 기법 | 메커니즘 | 적용 모델 |
|-----|--------|---------|
| **표현 학습** | 추상적 특징으로 데이터 압축 | CNN, Autoencoder, CDL |
| **순차 모델링** | 시간적 패턴 → 미래 예측 | RNN, LSTM, GRU4Rec |
| **정규화** | 과적합 방지 | Dropout, Batch Norm, L2 정규화 |
| **부정 샘플링** | 효율적 학습 신호 생성 | CDAE, BPR, GRU4Rec |
| **다중 작업 학습** | 암묵적 데이터 증강 | NRT, Multi-task DNN |
| **Attention** | 노이즈 필터링, 해석성 | Attention-based CF, Sequential models |

### 7.3 일반화 성능 개선의 실제 사례

**YouTube 동영상 추천 시스템:**[1]
- 두 단계 구조: 후보 생성(MLP) → 순위 매김(MLP + 특징 교차)
- 특징 공학과 대규모 데이터의 결합으로 실시간 처리와 높은 정확도 달성
- 배포 이후 실제 사용자 만족도 증가 검증

**Yahoo 뉴스 추천:**[1]
- RNN 기반 모델로 사용자의 시간적 선호도 변화 포착
- 일일 천만 이상 활성 사용자 대상 온라인 성공
- 기존 모델 대비 클릭률(CTR) 향상

---

## 8. 향후 연구 시 고려할 점

### 8.1 단기 연구 방향 (1-2년)

1. **강화학습의 활용**
   - 정적 추천 → 동적, 상호작용적 추천으로 전환
   - 사용자 장기 만족도를 고려한 순차 의사결정

2. **설명 가능성 강화**
   - Attention 메커니즘 확대
   - 증거 기반 추천(Evidence-based Recommendation)
   - 사용자 피드백 루프 통합

3. **효율성 개선**
   - 지식 증류를 통한 모델 압축
   - 모바일 장치 대응 경량 모델

### 8.2 중기 연구 방향 (2-5년)

1. **다중 도메인 학습**
   - 도메인 간 지식 전이의 이론화
   - 도메인 불변 특징 학습
   - 보정(Calibration) 기법 개발

2. **추론 아키텍처**
   - 지식 그래프와 결합한 추론
   - 인과 관계(Causal) 기반 모델링
   - 메타 학습(Meta-learning)을 통한 빠른 적응

3. **평가 표준화**
   - 대규모 공개 벤치마크 개발
   - 시간 기반 검증 프로토콜 표준화
   - 공정한 비교를 위한 공통 구현 프레임워크

### 8.3 기술적 고려사항

**모델 선택 기준:**[1]

```
상황 → 최적 모델
─────────────────────────────────
사용자 프로필 풍부 → MLP, DeepFM
이미지 데이터 있음 → CNN, CKE
시계열 데이터 → RNN, GRU4Rec
실시간/세션 기반 → GRU4Rec, STAMP
다중 모달 데이터 → Hybrid (CNN+RNN+Attention)
해석성 중요 → Attention-based, LIME 적용
```

**성능-비용 트레이드오프:**[1]
- 산업 시스템: 간단한 모델(Wide & Deep)의 빠른 학습, 배포 용이성
- 학술 연구: 복잡한 모델의 SOTA 성능 추구
- 중도: 하이브리드 모델로 성능과 효율성 균형

***

## 9. 논문의 학문적 기여와 영향

### 9.1 분야에 미친 영향

이 논문은 **최초의 체계적 딥러닝 추천 시스템 조사**로서:[1]

- **산업 채택 촉진**: 주요 기업들의 딥러닝 추천 시스템 도입 가속화
- **연구 표준화**: 논문 분류 체계가 이후 연구의 참조 틀 제공
- **새로운 연구 영역 개척**: Attention 기반 추천, DRL 추천의 활성화

### 9.2 한계 및 개선 필요성

**논문이 제기하는 비판적 질문:**[1]

> "왜 추천 시스템 분야에는 ImageNet이나 MNIST 같은 표준 벤치마크가 없는가?"

이는 다음을 야기합니다:
- 모델 비교의 신뢰성 문제
- 발전 속도 평가의 어려움
- 재현성 위기

***

## 결론

이 논문은 **딥러닝 기반 추천 시스템의 포괄적 지도**를 제공하며, 특히 **일반화 성능 향상**을 위한 다양한 기법들을 체계화합니다. 표현 학습, 순차 모델링, 정규화, 다중 작업 학습 등의 조합을 통해 기존 선형 모델의 한계를 극복하는 방법을 제시합니다.

그러나 **해석성 부족, 콜드 스타트 문제, 평가 표준화 부족** 등의 미해결 과제가 남아 있으며, 이는 향후 연구의 핵심 과제입니다. 특히 강화학습, 교차 도메인 학습, 설명 가능한 AI와의 결합이 차세대 추천 시스템의 발전 방향이 될 것으로 예상됩니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/5eefbfbf-d7d6-42d8-b313-41b2995a9e22/1707.07435v7.pdf)
