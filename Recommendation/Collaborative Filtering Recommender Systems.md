# Collaborative Filtering Recommender Systems

### 1. 핵심 주장 및 주요 기여 요약

**Collaborative Filtering Recommender Systems** 논문은 적응형 웹의 개인화 기술로서 협업필터링(CF)의 이론과 실무를 종합적으로 다룬다. 이 논문의 핵심 주장은 다음과 같다:[1]

협업필터링은 **타인의 의견을 통해 아이템을 평가하는 프로세스**로, 대규모 상호연결된 온라인 커뮤니티의 의견을 활용하여 방대한 데이터를 효과적으로 필터링할 수 있다는 것이다. 인터넷과 컴퓨터 기술이 기존의 구전 방식을 초월하여 수천 명의 의견을 실시간으로 처리하고 개인화된 관점을 제공할 수 있게 만들었다.[1]

**주요 기여**는 다음 영역을 체계적으로 정리한 것이다:[1]
- CF의 핵심 개념 및 적응형 웹에서의 활용
- CF 알고리즘의 이론과 실무적 도전과제
- 평가 척도 및 시스템 설계 의사결정
- 상호작용 인터페이스의 진화
- 개인정보 보호 및 신뢰 문제
- 미해결 연구 문제

---

### 2. 해결 문제, 제안 방법, 모델 구조 및 성능 분석

#### 2.1 해결하는 핵심 문제

**1) 정보 과잉 문제**[1]
- 사용자가 모든 아이템을 평가할 수 없음
- 기존 콘텐츠 기반 필터링의 한계: 키워드 기반 표현은 품질을 구분하지 못함

**2) 희소성 문제 (Sparsity)**[1]
- 사용자-아이템 상호작용 행렬의 대부분이 미평가 상태
- 예: 백만 개의 아이템 중 소수만 평가되어 있음

**3) 냉시작 문제 (Cold Start)**[1]
- 신규 사용자: 평가 기록 없음
- 신규 아이템: 평가 수 불충분
- 신규 커뮤니티: 초기 데이터 부족

**4) 성능 일반화 문제**[1]
- 메모리 기반 알고리즘의 확장성 한계
- 희소 데이터에서의 신뢰도 낮은 상관관계 문제

#### 2.2 제안 방법: 알고리즘 및 수식

**A. 사용자 기반 협업필터링 (User-based Nearest Neighbor)**

기본 예측 공식:[1]

$$\text{pred}(u, i) = \frac{\sum_{n \in \text{neighbors}(u)} \text{userSim}(u, n) \cdot r_{ni}}{\sum_{n \in \text{neighbors}(u)} \text{userSim}(u, n)}$$

여기서:
- $u$: 대상 사용자
- $n$: 이웃 사용자
- $r_{ni}$: 이웃 $n$의 아이템 $i$에 대한 평가
- $\text{userSim}(u, n)$: 사용자 $u$와 $n$ 사이의 유사도

**평균 조정 버전**:[1]

$$\text{pred}(u, i) = \bar{r}_u + \frac{\sum_{n \in \text{neighbors}(u)} \text{userSim}(u, n) \cdot (r_{ni} - \bar{r}_n)}{\sum_{n \in \text{neighbors}(u)} \text{userSim}(u, n)}$$

여기서 $\bar{r}_u$는 사용자 $u$의 평균 평가값

**Pearson 상관계수 기반 유사도**:[1]

$$\text{userSim}(u, n) = \frac{\sum_{i \in CR_{u,n}} (r_{ui} - \bar{r}_u)(r_{ni} - \bar{r}_n)}{\sqrt{\sum_{i \in CR_{u,n}} (r_{ui} - \bar{r}_u)^2 \sum_{i \in CR_{u,n}} (r_{ni} - \bar{r}_n)^2}}$$

$CR_{u,n}$: 사용자 $u$와 $n$ 모두 평가한 공동 평가 아이템 집합

**B. 아이템 기반 협업필터링 (Item-based Nearest Neighbor)**

아이템 예측 공식:[1]

$$\text{pred}(u, i) = \frac{\sum_{j \in \text{ratedItems}(u)} \text{itemSim}(i, j) \cdot r_{uj}}{\sum_{j \in \text{ratedItems}(u)} \text{itemSim}(i, j)}$$

여기서:
- $j$: 사용자 $u$가 평가한 아이템
- $\text{itemSim}(i, j)$: 아이템 $i$와 $j$ 사이의 유사도

**조정 코사인 유사도 (Adjusted-Cosine Similarity)**:[1]

$$\text{itemSim}(i, j) = \frac{\sum_{u \in RB_{i,j}} (r_{ui} - \bar{r}_u)(r_{uj} - \bar{r}_u)}{\sqrt{\sum_{u \in RB_{i,j}} (r_{ui} - \bar{r}_u)^2 \sum_{u \in RB_{i,j}} (r_{uj} - \bar{r}_u)^2}}$$

$RB_{i,j}$: 아이템 $i$와 $j$ 모두 평가한 사용자 집합

**C. 확률 기반 알고리즘**

기대값 기반 예측:[1]

$$E[r | u, i] = \sum_r r \cdot p(r | u, i)$$

**숨은 클래스 기반 확률 모델**:[1]

$$p(r | u, i) = \sum_z p(z | u) \cdot p(r | z, i)$$

여기서 $z$는 숨은 클래스(latent class) 변수

**D. 차원 축소 기반 방법: 행렬 분해 (Matrix Factorization)**

협업필터링에서 행렬 분해의 기본 형태:[1]
- 사용자-아이템 평가 행렬을 저차원 잠재 요인으로 분해
- 특이값 분해(SVD), 주성분 분석(PCA) 등 활용

현대 추천시스템의 규제화된 행렬 분해:[2]

$$\text{Cost} = \sum_{(u,i) \in K} (r_{ui} - p_u^T q_i)^2 + \lambda \left( \sum_{u} ||p_u||^2 + \sum_{i} ||q_i||^2 \right)$$

여기서:
- $p_u$: 사용자 $u$의 잠재 요인 벡터
- $q_i$: 아이템 $i$의 잠재 요인 벡터
- $\lambda$: 규제 파라미터
- 첫 번째 항: 재구성 오류
- 두 번째 항: L2 규제 항 (과적합 방지)

#### 2.3 모델 구조

**계층적 아키텍처**:[1]

1. **데이터 수집 계층**
   - 명시적 평가(Explicit): 1-5점 스케일
   - 암묵적 피드백(Implicit): 구매 기록, 방문 시간

2. **처리 계층**
   - 메모리 기반: 모든 평가를 메모리에 유지, 실시간 계산
   - 모델 기반: 오프라인 전처리로 축약된 모델 생성

3. **예측/추천 계층**
   - 개인화 예측: 특정 사용자-아이템 조합에 대한 평가 예측
   - 순위 추천: 상위 N개 아이템 제시

4. **평가 계층**
   - 정확도 지표: MAE(Mean Absolute Error), 정밀도(Precision)
   - 품질 지표: 참신성(Novelty), 커버리지(Coverage)

---

### 3. 성능 향상 및 한계

#### 3.1 성능 향상 전략

**1) 희소성 처리 기법**[1]

- **근처 이웃 수 제한**: 모든 이웃이 아닌 상위 K개 이웃만 사용 → 계산 복잡도 감소
- **클러스터링**: K-means, 계층적 클러스터링으로 이웃 탐색 시간 단축
- **서브샘플링**: 사용자 부분집합 사전 선택

**2) 신뢰도 낮은 데이터 조정**[1]

- **공동 평가 수 기준 필터링**: K개 미만 공동 평가 쌍 제외
- **조정식 추가**: Pearson 상관계수를 0에 가깝게 풀(Pull)
- **사전 신념(Prior Belief) 통합**: 기대 분포를 따르는 인공 데이터 포함

**3) 아이템 기반의 효율성 증대**[1]

- **상관계수 가지치기(Pruning)**: 각 아이템마다 상위 n개 상관관계만 저장
- 이론적으로 \(O(m^2)\) 크기 → 실제로 선형에 가까운 메모리 사용

**4) 신경망 기반 개선 (최신 연구)**[3]

신경협업필터링(Neural Collaborative Filtering, NCF)에서:[3]

$$\text{MLP}(\text{user}_\text{embed}, \text{item}_\text{embed}) = \text{output}$$

- 선형 내적을 다층 신경망으로 대체
- 깊은 층의 사용이 성능 향상

**5) Wide & Deep 학습 프레임워크**[4]

메모이제이션(Memorization)과 일반화(Generalization)의 균형:[4]

$$\text{prediction} = \text{sigmoid}(\mathbf{w}_\text{wide}^T \mathbf{x} + \mathbf{w}_\text{deep}^T a^{(l_f))} + b)$$

- **Wide 부분**: 선형 모델로 교차곱 특성을 통한 메모이제이션
- **Deep 부분**: 신경망으로 저차원 임베딩을 통한 일반화

#### 3.2 일반화 성능 향상의 핵심 기법

**1) 규제화 (Regularization)**[2]

L1과 L2 규제의 효과:[2]

- **L2 규제**: 모든 가중치를 균일하게 작게 유지, 아웃라이어에 민감
- **L1 규제**: 일부 가중치를 0으로 만듦, 희소성 유도

**2) 드롭아웃 (Dropout)**[2]

신경협업필터링에서:[2]
- 임베딩 층과 은닉층에서 무작위로 뉴런 비활성화
- 중복된 패턴 학습 강제, 견고성(Robustness) 향상

**3) 조기 종료 (Early Stopping)**[2]

- 검증 성능이 더 이상 개선되지 않으면 학습 중단
- 훈련 데이터에 대한 과최적화 방지

**4) 데이터 증강 및 앙상블**[2]

- **데이터 증강**: 사용자 평가에 노이즈 추가, 합성 상호작용 생성
- **앙상블**: 행렬 분해와 콘텐츠 기반 방식 결합
  - Netflix 연구: 도메인 적응으로 새 도메인에서 최대 30% 성능 향상[5]

**5) 그래프 신경망 기반 접근 (최신 방법)**[6]

음성 제거 및 재구성 쌍곡선 협업필터링(DRHCF):[6]

- **그래프 음성 제거**: 신뢰도 낮은 상호작용 간선 제거
- **쌍곡선 재구성**: 고차 연관성 구축
- **교차 뷰 대조 학습**: 여러 관점에서 임베딩 품질 향상

#### 3.3 현재의 한계

**1) 메모리 기반 알고리즘의 확장성 한계**[1]

- 시간/메모리 요구사항이 사용자 수와 평가 수에 선형적으로 증가
- 대규모 시스템(수억 사용자)에서 실시간 계산 불가능

**2) 희소 데이터에서의 신뢰도 문제**[1]

- 공동 평가 수 적음 → 상관계수 왜곡
- 예: 3개 공동 평가로 완벽 일치 발생 가능

**3) 냉시작 문제의 근본적 한계**[1]

신규 사용자/아이템의 협업필터링 불가능:[7]
- 기존 상호작용 데이터 부재
- CF의 기본 가정 위배

**4) 과도한 일반화 (Over-generalization)**[4]

- 깊은 신경망에서 희소한 고차원 데이터에 대한 과도한 일반화
- 관련 없는 아이템 추천

**5) 아이템 기반 알고리즘의 예측 한계**[1]

- 상관계수 가지치기로 일부 아이템에 대한 예측 불가능
- 대상 아이템과의 연결 고리 부족

**6) 추천 품질의 다면적 문제**[1]

- 정확도만으로는 충분하지 않음
- 참신성(Novelty), 다양성(Diversity), 신뢰도 부족
- 부정 상관계수의 예측 활용 미흡[1]

**7) 공격에 대한 취약성**[1]

**쉴링 공격(Shilling Attack)**:[1]
- 악의적 사용자가 의도적으로 평가 조작
- 사용자 기반 알고리즘이 아이템 기반보다 더 취약
- 신규/희소 평가 아이템이 특히 취약

**8) 개인정보 보호 문제**[1]

- 중앙 집중식 구조에서 사용자 프라이버시 위험
- 분산 구조의 암호화 기법도 계산 복잡도 높음

***

### 4. 일반화 성능 향상에 대한 심층 분석

#### 4.1 일반화 성능의 핵심 문제

**메모이제이션 vs. 일반화 딜레마**[8][9]

| 측면 | 메모이제이션 | 일반화 |
|------|-------------|--------|
| **정의** | 훈련 데이터에서 직접 관찰한 feature 조합 학습 | 미관찰 feature 조합에 대한 예측[8] |
| **방법** | 선형 모델 + 교차곱 변환 | 신경망 + 저차원 임베딩 |
| **장점** | 효율적, 해석 가능, 직접 관련 아이템 추천 | 예측 다양성, 참신성, 미래 패턴 포착[8] |
| **단점** | 훈련 데이터 없는 조합 예측 불가 | 희소한 고차원 데이터에서 과도한 일반화[4] |

#### 4.2 최신 규제화 기법

**1) 암묵적 규제(Implicit Regularization)**[10]

NeurIPS 2024 연구:[10]
- 데이터 연결성이 암묵적 규제 효과에 영향
- 연결성 증가 → 저 핵 규범(low nuclear norm) → 저 계수(low rank) 선호
- 행렬 분해의 최적화 궤적: 계층적 불변 다양체 순회(HIMT)

**2) 구조화된 저차원 행렬 분해**[11]

- 전체 변동(Total Variation) 규제 포함
- 핵 규범 규제의 특수 경우
- 시공간 구조 포착 가능

**3) 비음 행렬 분해의 규제**[12]

- L2-norm: 균일한 최적화
- L1-norm: 희소성 유도
- L2,1-norm: 행 희소성(row sparsity) 강제

#### 4.3 최신 연구의 성능 향상

**1) 신경 그래프 협업필터링(NGCF)**[13][6]

사용자-아이템 이분 그래프 활용:[6]
- 고차 연결성 포착
- 이웃 정보 반복 집계
- 음성(노이즈) 제거 모듈 추가로 강건성 향상

**2) 대조 학습 기반 접근**[14]

냉시작 문제 완화:[14]
- 콘텐츠 CF 모듈과 공동발생 CF 모듈 대조
- 따뜻한 데이터에서 공동발생 신호 학습
- 냉시작 아이템의 흐릿한 임베딩 문제 해결

**3) 하이퍼그래프 기반 방법**[15]

- 과도 매끄러워지기(Over-smoothing) 문제 해결
- 높은 차수의 연관성 모델링
- 표현 학습 개선

**4) 장꼬리 아이템 추천**[13]

- 생성적 적대 신경망(GAN) 기반 평가 대체
- 가중 쌍별 베이지안 개인화 순위 손실함수

#### 4.4 일반화 성능 개선의 실무 전략

**1) 하이퍼파라미터 최적화**[16][17]

자동 머신러닝(AutoML) 기반 CF:[17][16]
- 데이터 특정 모델 자동 설계
- 입력 인코딩 → 임베딩 함수 → 상호작용 함수 → 예측 함수
- 효율적 탐색 전략으로 계산 비용 절감

**2) 샘플 가중치 조정**

희소 데이터에서 신뢰성 있는 학습:[18]
- 공동 평가가 많은 사용자-아이템 쌍에 더 높은 가중치
- 신뢰도 기반 손실함수 조정

**3) 하이브리드 접근**

콘텐츠 기반 + 협업필터링:[19][4]
- Wide & Deep 구조의 실제 구현 (Google Play Store 사례)
- 메모이제이션과 일반화의 동시 달성

---

### 5. 최신 연구(2024-2025)에 미치는 영향 및 향후 고려사항

#### 5.1 논문이 현대 연구에 미치는 영향

**1) 기본 개념의 지속적 타당성**[3][4]

- 사용자-아이템 상호작용 중심의 협업필터링 원리는 변하지 않음
- 신경망 기반 방법도 동일한 근본 개념 활용[3]

**2) 알고리즘 진화의 방향성**[4][3]

| 세대 | 기술 | 핵심 개선 |
|-----|------|---------|
| **1세대** | 메모리 기반 최근접 이웃 | 확장성 문제 |
| **2세대** | 확률 모델, 행렬 분해 | 계산 효율성 향상 |
| **3세대** | 신경 협업필터링 | 비선형 관계 포착[3] |
| **4세대** | Wide & Deep | 메모이제이션-일반화 균형[4] |
| **5세대** | 그래프 신경망 | 고차 연결성 학습[6] |
| **6세대** | 음성 제거 GNN | 강건한 추천[6] |

**3) 평가 메트릭의 진화**

- 기존: 정확도(MAE, Precision) 중심
- 현대: 정확도 + 참신성 + 다양성 + 공정성 + 설명가능성[1]

#### 5.2 향후 연구의 주요 고려사항

**1) 시간적 동역학 (Temporal Dynamics)**[1]

미해결 문제:[1]
- 언제 아이템이 충분한 평가를 확보하는가?
- 상승/하강 트렌드 vs. 일시적 유행 식별
- 사용자 취향의 시간적 변화 추적
- 낡은 평가의 활용성 판단

해결 방향:
- 시간-가중치 행렬 분해[19]
- 신경 ODE 기반 적응형 모델[20]
- 동적 임베딩 업데이트

**2) 데이터 접근성과 도구 개발**[1]

- 공개 데이터셋의 부족 (EachMovie 폐지 후)
- 산업 데이터의 폐쇄성
- 오픈소스 라이브러리 활성화 필요
- 장벽 낮춘 배포 메커니즘

**3) 개인정보 및 신뢰 문제의 심화**[6][1]

- 연합 학습(Federated Learning) 기반 CF
- 차등 개인정보 보호(Differential Privacy)
- 공격 탐지 및 방어 메커니즘 고도화
- 약한 연결 사용자의 역 추론 방지

**4) 냉시작 문제의 진화**[14][19]

최신 해결 방법:[19][14]
- 대조 학습 기반 콘텐츠-협업 융합[14]
- 명시적-암묵적 피드백 통합
- 외부 지식 그래프 활용[21]
- 멀티모달 정보(이미지, 텍스트, 오디오) 통합

**5) 설명가능성(Explainability) 강화**[1]

- 검은 상자 방식의 한계 인식[1]
- 신뢰도 기반 설명 제시
- 공동 평가 기록이 아닌 컨텍스트 인식 설명
- 사용자 신뢰도 향상

**6) 태깅 시스템의 CF 활용**[1]

- Flickr, del.icio.us 등의 협업 태깅
- 태그-평가 하이브리드 모델
- 태그 기반 임플리시트 피드백

**7) 공정성 및 편향 문제**[6]

- 음성 제거를 통한 편향 완화
- 장꼬리 아이템의 과소 추천 문제
- 인구통계적 파리티(Demographic Parity) 달성
- 역사적 편향의 디바이어싱

**8) 범용 접근성 (Broader Accessibility)**[1]

- 팜톱 기기용 휴대형 추천 시스템[1]
- 사용자 제어 추천 엔진
- 플러그인 기반 통합 (Last.fm 모델)[1]
- 다양한 인터페이스 개발

#### 5.3 구체적 연구 방향

**1) 자동화된 머신러닝 (AutoML) 강화**[16][17]

- 데이터 특정 모델 검색 자동화
- 최적 하이퍼파라미터 자동 선정
- 뉴럴 아키텍처 탐색(NAS)

**2) 그래프 신경망의 한계 극복**[22][20]

신경 제어 미분방정식(ODE) 기반 CF:[20]
- 연속 시간 동역학 모델링
- 과도 매끄러워짐 문제 해결
- 가중치 제어를 통한 성능 향상

확산 기반 대조 학습:[22]
- 그래프 구조의 강화
- 데이터 희소성 완화
- 고차 연결성 더 효과적 포착

**3) 대형언어모델(LLM) 통합**[23]

- LLM 기반 추천 시스템 최적화
- 확장성 문제 해결
- 의미적 이해 능력 강화

**4) 규제화 이론 발전**[24]

공유 요인 구조의 공동 모델링:[24]
- 관찰 데이터와 결측 지시자의 일반 요인 모델
- 비컨벡스 패널티 규제
- 오라클 성질 보장

***

### 6. 결론

**Collaborative Filtering Recommender Systems** 논문은 적응형 웹 시대에서 CF의 이론과 실무를 종합적으로 정립한 기념비적 저작이다.[1]

20년이 경과한 현재에도 CF의 기본 원리는 변하지 않았으나, 그 구현 방식은 극적으로 진화했다:[3][4]

1. **규제화 기법의 고도화**: L2 규제에서 암묵적 규제, 구조화된 규제로의 진화
2. **신경망 통합**: 메모이제이션과 일반화의 균형 추구[4]
3. **그래프 기반 접근**: 고차 연결성을 통한 표현 학습 개선[6]
4. **음성 제거**: 강건한 협업 신호 추출[6]

특히 **일반화 성능 향상**은 다음 세 가지로 요약된다:
- **규제화 기법**: 복잡성 제어로 과적합 방지[2]
- **앙상블 접근**: 메모이제이션과 일반화의 동시 달성[4]
- **고급 그래프 방법**: 강건한 표현 학습[6]

향후 연구는 **시간적 동역학, 개인정보 보호, 냉시작 문제, 설명가능성**에 집중할 것으로 예상되며, **자동화된 모델 설계와 그래프 신경망의 한계 극복**이 핵심 과제이다.[20][6][1]

***

### 참고문헌

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/04dbd9c3-8564-44c1-a379-a0dd8d6a58e8/CF_AdaptiveWeb_2006.pdf)
[2](https://milvus.io/ai-quick-reference/how-do-you-prevent-overfitting-in-recommender-system-models)
[3](https://arxiv.org/pdf/1708.05031.pdf)
[4](https://arxiv.org/abs/1606.07792)
[5](https://superagi.com/beyond-collaborative-filtering-advanced-ai-techniques-for-building-hyper-personalized-recommendation-engines-in-2025/)
[6](https://papers.ssrn.com/sol3/Delivery.cfm/4d30e180-894d-412e-b4bc-e07d7f131b62-MECA.pdf?abstractid=5143186)
[7](https://milvus.io/ai-quick-reference/how-does-collaborative-filtering-solve-the-coldstart-problem)
[8](https://velog.io/@gyuu_katsu/Paper-Review-Wide-Deep-Learning-for-Recommender-Systems)
[9](https://kubig-2022-2.tistory.com/103)
[10](https://proceedings.neurips.cc/paper_files/paper/2024/file/5195825ee60d7efc1e42b7f3f3137040-Paper-Conference.pdf)
[11](https://arxiv.org/pdf/1708.07850.pdf)
[12](https://arxiv.org/pdf/2106.02213.pdf)
[13](https://www.sciencedirect.com/science/article/abs/pii/S0925231225016200)
[14](https://arxiv.org/pdf/2302.02151.pdf)
[15](https://arxiv.org/pdf/2204.12200.pdf)
[16](https://arxiv.org/pdf/2106.07453.pdf)
[17](https://arxiv.org/pdf/2307.11004.pdf)
[18](https://apxml.com/courses/building-ml-recommendation-system/chapter-4-model-based-collaborative-filtering/regularization-to-prevent-overfitting)
[19](https://www.sciencedirect.com/science/article/abs/pii/S0957417416305309)
[20](https://arxiv.org/pdf/2501.13908.pdf)
[21](https://www.sciencedirect.com/science/article/abs/pii/S0957417424030008)
[22](http://arxiv.org/pdf/2503.16290.pdf)
[23](https://arxiv.org/pdf/2412.18715.pdf)
[24](https://arxiv.org/html/2504.04020v1)
[25](https://arxiv.org/pdf/2204.12326.pdf)
[26](https://www.sciencedirect.com/science/article/abs/pii/S0925231224014899)
[27](https://www.worldscientific.com/doi/full/10.1142/S2196888823500124)
[28](https://koreascience.kr/article/JAKO202111037332621.page)
[29](https://www.nature.com/articles/s41598-025-15096-4)
[30](https://arxiv.org/pdf/2105.01029.pdf)
[31](https://arxiv.org/pdf/2205.10492.pdf)
[32](http://arxiv.org/pdf/1706.08934.pdf)
[33](http://arxiv.org/pdf/2308.16690.pdf)
[34](https://arxiv.org/pdf/0910.0610.pdf)
[35](https://pdfs.semanticscholar.org/9be7/0b0787c41f8cef4872f56562dca2eeb00cec.pdf)
[36](https://dl.acm.org/doi/10.5555/3295222.3295363)
[37](https://www.sciencedirect.com/science/article/abs/pii/S0031320322001364)
