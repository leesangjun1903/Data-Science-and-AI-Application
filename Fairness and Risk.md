
# Fairness
- Awesome-Fairness-in-AI : https://github.com/datamllab/awesome-fairness-in-ai

## Ethnic Bias, 민족적 편향
- Ethnic Bias in BERT : Mitigating Language-Dependent Ethnic Bias in BERT

#### 헌법적 AI, 인간 피드백 기반 강화 학습(RLHF) 문제 해결
- Constitutional AI: Harmlessness from AI Feedback

# Risk
## 언어 모델의 취약점과 위험성, 유해성
#### Red Team Model
- Red Teaming Language Models with Language Models

#### 개인정보 유출 위험 완화
- Deduplicating Training Data Mitigates Privacy Risks in Language Models
