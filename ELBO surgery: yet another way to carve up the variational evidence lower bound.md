# ELBO surgery: yet another way to carve up the variational evidence lower bound

## 1. 핵심 주장 (간결 요약)
**“ELBO Surgery”** 논문은 변분 오토인코더(VAE)의 증거 하한치(ELBO)를 새롭게 분해하여, 평균 인코딩 분포(qₐᵥg(z))와 사전 분포(p(z)) 간의 마진널 KL 발산(=marginal KL)이 ELBO 성능에 결정적인 영향을 준다는 점을 밝힌다.  
- ELBO를 재구성·상호정보·사전 KL로 세 분해함으로써, 기존에는 보이지 않던 **마진널 KL** 항(term 3)을 명확히 드러낸다.  
- 이 마진널 KL이 실제 학습에서 크게 작용하며 ELBO를 저해하기 때문에, **보다 유연하거나 멀티모달한 사전분포** 설계가 필요함을 제안한다.

***

## 2. 해결하고자 하는 문제
VAE 학습 시 ELBO가 다음 두 항의 차이로 표현되지만,  
1) 개별 KL(q(zₙ|xₙ) ∥ p(z))의 평균  
2) 재구성비용(negative reconstruction)  
  
이전 연구들은 (1)의 의미를 충분히 해석하지 못했고, 최종적으로 모델 성능이 제한되는 원인을 **사전분포가 인코더의 평균 인코딩 분포를 제대로 반영하지 못함**에서 찾지 못했다.

***

## 3. 제안된 방법  
### 3.1 ELBO의 새로운 분해식  
논문은 ELBO $$L$$를 다음 세 항으로 쪼갠다:  

$$
L = \underbrace{\frac{1}{N}\sum_{n=1}^N \mathbb{E}\_{q(z_n|x_n)}[\log p(x_n|z_n)]}\_{\text{(1) 평균 재구성}} 
-\underbrace{I_q(n,z)}\_{\text{(2) 인덱스-코드 상호정보}} 
-\underbrace{\mathrm{KL}(q(z)\Vertp(z))}_{\text{(3) 마진널 KL}}
$$  

여기서  
- $$q(z)=\frac1N\sum_n q(z|x_n)$$는 **평균 인코딩 분포**  
- $$I_q(n,z)$$는 인덱스 $$n$$과 잠재변수 $$z$$ 간의 **상호정보**  

### 3.2 주요 수식  
1) 기존 평균 KL:  

$$
\frac1N\sum_n \mathrm{KL}(q(z_n|x_n)\Vert p(z_n)) 
= I_q(n,z) + \mathrm{KL}(q(z)\Vert p(z))
$$  

2) 따라서 마진널 KL $$\mathrm{KL}(q(z)\Vert p(z))$$는 **잠재저차원의 과도한 정규화**로 ELBO를 크게 낮춘다.

***

## 4. 모델 구조 및 실험  
- **데이터셋**: 바이너리화된 MNIST (N=60,000)  
- **인코더/디코더**: 은닉층 2개, 각 500유닛, softplus 활성화  
- **잠재차원**: 2D, 10D, 20D로 실험  
- **최적화**: Adam  

| Latent Dim | ELBO      | Avg KL  | Mutual Info | Marginal KL |
|-----------:|----------:|--------:|------------:|------------:|
| 2D         | –129.63   | 7.41    | 7.20        | 0.21        |
| 10D        | –88.95    | 19.17   | 10.82       | 8.35        |
| 20D        | –87.45    | 20.20   | 10.67       | 9.53        |

- **관찰**: 차원이 커질수록 마진널 KL(제3항)의 기여도가 커져 ELBO가 크게 저하됨을 확인.

***

## 5. 성능 향상 및 한계  
- **성능 향상**  
  - 마진널 KL을 최소화할 수 있는 **멀티모달(prior) 분포** 도입 시 ELBO 개선 여지 제시  
  - 인덱스-코드 상호정보 항이 최대로 수렴함을 보임으로써, 인코더·디코더 네트워크보다는 사전분포 설계가 관건임을 강조  

- **한계 및 향후 과제**  
  - 제안된 분해는 진단적 분석에 그치며, 실제 **멀티모달 사전분포 설계·학습 방법**은 제시하지 않음  
  - Monte Carlo 추정을 사용하여 마진널 KL을 계산해야 하므로 **계산 비용**(O(NS))이 매우 큼  
  - 대규모 데이터·고차원 잠재공간에서의 적용성 및 **스케일 문제** 검증 필요  

***

## 6. 결론
ELBO Surgery는 VAE의 ELBO 내에 숨겨진 **마진널 KL** 항을 분명히 드러내어, 변분 바운드 개선을 위해 인코더·디코더뿐 아니라 **사전분포 자체를 개선**해야 함을 이론적·실험적으로 설득력 있게 제시했다. 앞으로 멀티모달·데이터 적응형 사전분포 설계가 VAE 성능 향상의 핵심 과제로 떠오를 전망이다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/b5b57b29-1232-43a7-a510-8c517fa4fb32/HoffmanJohnson2016.pdf
