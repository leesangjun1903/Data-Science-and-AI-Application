# Topological Graph Neural Networks

## 1. 핵심 주장 및 주요 기여
이 논문에서는 **메시지 패싱 GNN이 사이클과 같은 전역 토폴로지 구조를 포착하지 못하는 한계를**, 위슬러–라이먼(WL) 검정보다 더 표현력이 강한 토폴로지 정보를 도입하여 극복할 수 있음을 보인다.  
주요 기여:
- TOGL(Topological Graph Layer)라는 **범용 GNN 레이어** 제안  
- **퍼시스턴스 호몰로지**를 이용한 다중 스케일 토폴로지 표현 학습  
- WL 검정보다 더 높은 이성질체(distinguishability) 이론적 증명  
- 합성 데이터 및 실제 데이터에서 예측 성능 향상  

## 2. 문제 정의 및 제안 방법
### 2.1 해결하고자 하는 문제
- 기존 GNN은 인접 노드 정보만 집계하여 사이클(1차 베티 수 β₁) 등 전역 구조를 구분하지 못함  
- WL과 동등한 표현력만 가지고 있어 특정 비동형 그래프를 구별할 수 없음[1]

### 2.2 TOGL 구조 및 수식
1) **필터레이션 함수**  
   각 노드 표현 $$x(v)\in\mathbb{R}^d$$에 대해 MLP $$\Phi: \mathbb{R}^d\to\mathbb{R}^k$$를 적용하여  

$$
     f_i(v)=\bigl[\Phi(x(v))\bigr]_i,\quad i=1,\dots,k
   $$
   
   으로 각 노드 스칼라 값 생성  

2) **퍼시스턴스 다이어그램 계산**  
   각 $$f_i$$로 정의된 필터레이션에 따라 0·1차 퍼시스턴스 다이어그램 $$\mathrm{ph}(G,f_i)$$ 계산  
3) **토폴로지 임베딩**  
   임베딩 함수 $$\Psi$$를 이용해 각 다이어그램을 $$\mathbb{R}^{n'\times d'}$$로 매핑  
4) **잔차 결합(residual aggregation)**  
   0차 특성(노드 기반)  

$$
     \tilde x(v)=x(v)+\Psi^{(0)}\bigl(D^{(0)}_1,\dots,D^{(0)}_k\bigr)[v]
   $$
   
   1차 특성(그래프 전역): 토폴로지 피처를 풀링하여 최종 분류층에 전달  

### 2.3 이론적 표현력
- **Theorem 1**: 매개변수화된 필터레이션 $$f_\theta$$가 서로 다른 노드 값으로 가정될 때, $$\theta\mapsto \Psi(\mathrm{ph}(G,f_\theta))$$는 미분 가능  
- **Theorem 2**: WL로 판별 가능한 모든 그래프는 TOGL도 구별 가능[1]
- **추가 예시**: 두 개의 삼각분해 그래프(β₁=2)와 하나의 육각형 그래프(β₁=1)를 WL는 구별 못하나 TOGL은 β₁으로 구별[1]

## 3. 모델의 성능 향상 및 한계
### 3.1 성능 향상
- **합성 데이터**: CYCLES, NECKLACES에서 소수 층으로도 100% 정확도  
- **구조 기반 벤치마크**: MNIST-STRUCT 등에서 GCN 대비 최대 +8% 향상  
- **일반 벤치마크**: CIFAR-10, DD, PROTEINS 등 여러 데이터셋에서 소폭 개선  

### 3.2 한계
- **고차원 퍼시스턴스 연산 복잡도**: 2차원 이상은 $$O(m^d)$$로 비실용적  
- **과적합 위험**: 작은 데이터셋(ENZYMES)에서 토폴로지 정보가 오히려 과적합 유발  
- **필터레이션 개수·하이퍼파라미터 민감도**  

## 4. 일반화 성능 향상 관점
- TOGL은 **다중 필터레이션**으로 다양한 스케일의 토폴로지 신호 학습  
- **얕은 레이어**에서도 복잡한 전역 구조를 포착하므로 과도한 레이어 깊이가 필요 없고, **오버스무딩**을 완화  
- **엔드투엔드 미분 가능**하여 다양한 GNN 백본에 쉽게 통합 가능  

## 5. 향후 연구 방향 및 고려 사항
- **정규화 기법**: 작은 데이터셋 과적합 방지 위한 드롭아웃·가중치 감쇠  
- **고차원 필터레이션**: 확장 퍼시스턴스, 다변수 필터레이션 연구  
- **응용 도메인**: 화합물 구조, 토폴로지 중요성 높은 분자·지리 공간 그래프  
- **효율화**: 근사 알고리즘이나 희소 필터레이션으로 계산량 절감  

---  
**TOGL**은 GNN의 전역 구조 인식 능력을 크게 확장시켜, 향후 그래프 표현 학습 분야에서 **토폴로지 강화 신경망** 연구를 촉진할 것으로 기대된다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/c936a53d-c9ad-4f31-bbf5-fca8ee10e9ed/2102.07835v4.pdf
