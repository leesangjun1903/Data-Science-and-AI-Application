# A Baseline for Few-Shot Image Classification | Few-Shot Learning
https://github.com/amazon-science/few-shot-baseline

## 1. 핵심 주장과 주요 기여 (간결 요약)
이 논문은 **표준 크로스엔트로피로 사전학습(pre-training)**한 딥넷을 **전이학습(transductive fine-tuning)**만으로 미세조정했을 때, 기존 복잡한 메타러닝·메트릭 기반 방법을 능가하는 **간단하면서도 강력한 베이스라인**임을 밝힌다.  

<details>
<summary>Transductive fine-tuning</summary>
Transductive fine-tuning은 기존의 사전학습된 모델을 새로운 데이터에 맞게 조정하는 fine-tuning 방식 중 하나로, 주로 새로운 데이터(특히 라벨이 없는 테스트 데이터)의 구조나 분포 정보를 함께 활용하여 모델 성능을 개선하는 방법입니다. 일반적인 inductive 학습과 달리, test 데이터 자체를 활용한다는 점에서 transductive 학습 범주에 속합니다.

Test 데이터(쿼리셋)를 고려한 조정: 테스트 시점에서 주어진 unlabeled 데이터를 모델 학습에 함께 사용해 예측 정확도를 높입니다.

상호정보량(Maximization)을 활용: 예를 들어, Few-Shot Learning 분야에서 query feature와 예측 레이블 간의 상호정보량을 최대화하는 방식으로 테스트 집합에 특화된 fine-tuning을 시도합니다.

비지도적 정보 활용: 테스트 데이터의 분포나 레이블 없는 특징을 추론해 모델이 더 잘 일반화하도록 돕습니다.

</details>

주요 기여:
- **트랜스덕티브 미세조정(transductive fine-tuning)** 기법 제안  
- 표준 벤치마크( Mini-ImageNet, Tiered-ImageNet, CIFAR-FS, FC-100 ) 및 대규모 ImageNet-21k에서 **최신 기법 대비 2–7% 절대 성능 향상**  
- 에피소드 난이도를 정량화하는 **“하드니스(hardness)” 메트릭** 제안  

## 2. 문제 정의, 제안 기법, 모델 구조, 성능 및 한계

### 2.1 해결하고자 하는 문제
- **Few-Shot Learning**: 각 클래스당 몇 개의 레이블된 예시만 있는 상황에서 새로운 클래스 분류  
- 기존 메타러닝·메트릭 기반 방법들은  
  1. 하이퍼파라미터·모델 구조가 와이즈(way)/샷(shots)에 따라 달리 조정됨  
  2. 벤치마크 과적합 가능성  
  3. 에피소드별 성능 분산이 매우 큼  

### 2.2 제안 기법: 트랜스덕티브 미세조정
1) **사전학습**  
   - Dm=메타훈련 데이터셋 위에서 표준 크로스엔트로피+라벨 스무딩+믹스업으로 학습  
   - 백본(backbone): WRN-28-10  

2) **서포트 기반 초기화**  
   - 새로운 클래스 Ct의 서포트 샘플(Ds) 특징 z(x;θ)를 ℓ2 정규화 후 각 클래스별 평균을 가중치 wk로 설정  
   - bk=0  
   - 이 과정을 “weight imprinting”이라 부름  

3) **트랜스덕티브 미세조정**  
   - 쿼리 샘플(Dq)의 예측 분포 pΘ(·|x)에 대한 **Shannon 엔트로피**를 최소화하는 반지도 학습 손실 추가  
   - 최종 손실 함수:  

$$  
       Θ^* = \arg\min_Θ \Bigl[\frac1{N_s}\sum_{(x,y)\in D_s} -\log p_Θ(y|x)+\frac1{N_q}\sum_{x\in D_q} H(p_Θ(·|x))\Bigr]  
     $$  

4) **미세조정 프로세스**  
   - 에폭당 서포트용 크로스엔트로피와 쿼리용 엔트로피 손실을 번갈아 업데이트  
   - 고정 학습률, 25 에폭  

### 2.3 모델 구조
- **백본**: Wide ResNet-28-10  
- **추가 분류기**: 백본의 마지막 로짓층 뒤에 ReLU, ℓ2 정규화, FC 레이어(bias 0)  
- 미세조정 단계에서 백본+분류기 전체 파라미터 동결 해제  

### 2.4 성능 향상
- **Mini-ImageNet 1-shot 5-way**: 56.2%→68.1% (train+val)  
- **Tiered-ImageNet 1-shot 5-way**: 67.3%→72.9%  
- **CIFAR-FS 1-shot 5-way**: 72.1%→78.4%  
- **FC-100 1-shot 5-way**: 45.1%→50.4%  
- **ImageNet-21k** 첫 대규모 few-shot 실험에서 1-shot 5-way 87.2%→89.0%  
- 모든 벤치마크에서 기존 메타러닝·메트릭 기반 최첨단 대비 절대 2–7% 상승  

### 2.5 한계
- **추론 시 속도 저하**: 파라미터 업데이트 필요 → non-transductive 대비 수십 배 느림  
- **쿼리 의존성**: 실시간 스트리밍 환경에서 쿼리가 모두 모여야 학습 가능  
- 엔트로피 항 가중치·온도 하이퍼파라미터 조정 시 성능 민감  

## 3. 모델의 일반화 성능 향상 관점
- **대규모 클래스 수 사전학습** 시 embedding 표준화 → 희소 클래스 일반화↑  
- 쿼리 엔트로피 최소화로 **미지 클래스 간 경계 확실성** 강화  
- **하드니스 메트릭**(에피소드 난이도)로 다양한 에피소드에 대해 균일한 성능 예측 및 튜닝  
- 실험 결과, 훈련·검증 데이터 추가(meta-training set 확대) 시 few-shot 성능 일관되게 상승  

## 4. 향후 연구 영향 및 고려 사항
- **재평가**: 복잡한 메타러닝보다 간단한 전이학습이 우수함을 보여줘, 기존 few-shot 논문 벤치마크 재검증 필요  
- **하이퍼파라미터 일원화**: 모든 프로토콜에 공통된 설정으로 효율적이고 일반화된 모델 설계  
- **실시간 적용**: 빠른 추론을 위한 경량화 백본, 쿼리별 점진적 업데이트 기법 연구  
- **하드니스 기반 튜닝**: 에피소드 난이도에 따라 적응적 학습률·정규화 조절  
- **엔트로피 항 임계값**: 과도한 쿼리 편향을 막기 위한 동적 가중치 스케줄링  

이 논문은 few-shot 학습의 평가 기준과 방법론을 단순화하고, 진정한 성능 향상을 위해 **벤치마크 재검토와 체계적 평가**가 필수임을 강조한다. 앞으로는 **전이학습 강화, 실시간 추론 최적화, 에피소드 난이도 적응적 학습**이 연구의 핵심 고려 사항이 될 것이다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/7e8a7364-8d38-40a7-93f4-ba2f1993c4af/1909.02729v5.pdf
