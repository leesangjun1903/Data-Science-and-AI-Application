# A Tutorial on Bayesian Optimization

### 1. 논문의 핵심 주장과 주요 기여

"A Tutorial on Bayesian Optimization"은 **비용이 많이 드는 블랙박스 함수의 효율적인 최적화**에 대한 종합적인 가이드입니다. 논문의 핵심 주장은 다음과 같습니다:[1]

**주요 주장**: 베이지안 최적화는 일반적인 기울기 기반 방법을 적용할 수 없는 고비용 함수 최적화 문제를 해결하기 위한 강력한 접근 방식입니다. 베이지안 최적화는 **서로게이트 모델(대리 모델)을 구축하고 불확실성을 정량화하여 다음 평가 지점을 지능적으로 선택**합니다.[1]

**주요 기여**:

1. **Gaussian Process 회귀를 통한 베이지안 통계적 추론**: 목적함수의 사후확률분포를 구축하여 불확실성을 명시적으로 모델링합니다.[1]

2. **획득함수(Acquisition Function) 분류 및 비교**: Expected Improvement(EI), Knowledge Gradient(KG), Entropy Search(ES), Predictive Entropy Search(PES)의 네 가지 주요 획득함수를 제시합니다.[1]

3. **노이즈가 있는 경우에 대한 Expected Improvement의 일반화**: 이전의 ad-hoc 수정과 달리, **결정이론적 논증에 기반한 형식적인 일반화**를 제공합니다.[1]

4. **확장 문제(Exotic Problem) 처리**: 병렬 평가, 다중 충실도, 제약조건, 다중 정보원, 파생정보 포함 등 다양한 현실적 시나리오를 다룹니다.[1]

***

### 2. 문제 정의, 제안 방법, 모델 구조

#### 2.1 해결하고자 하는 문제

논문이 다루는 최적화 문제는 다음과 같이 정의됩니다:[1]

$$ \max_{x \in A} f(x) $$

**문제의 특성**:
- **고비용 평가**: 각 함수 평가에 수 시간이 소요되며, 전체 평가 횟수가 수백 회로 제한됩니다.[1]
- **도함수 정보 부재**: 기울기나 헤시안 없이 오직 함수값만 관찰 가능합니다(도함수 자유 최적화).[1]
- **블랙박스 특성**: 함수의 특별한 구조(오목성, 선형성 등)를 활용할 수 없습니다.[1]
- **낮은 차원성**: 일반적으로 $$d \leq 20$$차원 연속 영역에서 작동합니다.[1]
- **전역 최적점 찾기**: 국소 최적이 아닌 전역 최적을 목표합니다.[1]

#### 2.2 제안하는 방법 - 기본 알고리즘

베이지안 최적화의 기본 구조는 **Algorithm 1**로 표현됩니다:[1]

```
1. f에 Gaussian Process 사전분포 배치
2. 초기 공간충원 실험 설계(space-filling design)에 따라 n₀개 지점에서 f 관찰
3. while n ≤ N:
   a. 모든 데이터를 사용하여 f에 대한 사후확률분포 업데이트
   b. 현재 사후분포를 기반으로 획득함수를 최대화하는 xₙ 선택
   c. xₙ에서 yₙ = f(xₙ) 관찰
4. 최종 해: f(x)가 가장 큰 평가 지점 또는 사후평균 μₙ(x)가 가장 큰 지점 반환
```

#### 2.3 모델 구조

##### 2.3.1 Gaussian Process 회귀

베이지안 최적화의 핵심은 **Gaussian Process 회귀**입니다. 임의의 점 $$x_1, \ldots, x_k$$에서의 함수값들은 다변량 정규분포를 따릅니다:[1]

$$ f(x_{1:k}) \sim \text{Normal}(\mu_0(x_{1:k}), \Sigma_0(x_{1:k}, x_{1:k})) $$

**사후분포 계산**: $$n$$개의 관측값 $$f(x_{1:n})$$이 주어졌을 때, 새로운 지점 $$x$$에서의 조건부 분포는:[1]

$$ f(x)|f(x_{1:n}) \sim \text{Normal}(\mu_n(x), \sigma_n^2(x)) $$

$$ \mu_n(x) = \Sigma_0(x, x_{1:n})\Sigma_0(x_{1:n}, x_{1:n})^{-1}(f(x_{1:n}) - \mu_0(x_{1:n})) + \mu_0(x) $$

$$ \sigma_n^2(x) = \Sigma_0(x, x) - \Sigma_0(x, x_{1:n})\Sigma_0(x_{1:n}, x_{1:n})^{-1}\Sigma_0(x_{1:n}, x) $$

**핵심 특성**: 
- 사후평균 $$\mu_n(x)$$는 이전 평가 지점에서 보간합니다
- 사후분산 $$\sigma_n^2(x)$$는 관찰하지 않은 영역에서 증가합니다

##### 2.3.2 커널 함수 선택

두 가지 주요 커널이 사용됩니다:[1]

**Power Exponential 커널**: 

$$ \Sigma_0(x, x') = \alpha_0 \exp\left(-\sum_{i=1}^d \alpha_i(x_i - x'_i)^2\right) $$

**Matérn 커널**:

$$ \Sigma_0(x, x') = \alpha_0 \frac{2^{1-\nu}}{\Gamma(\nu)} \left(\sqrt{2\nu}||x - x'||\right)^{\nu} K_{\nu}(\sqrt{2\nu}||x - x'||) $$

##### 2.3.3 하이퍼파라미터 선택

하이퍼파라미터를 추정하는 **세 가지 방법**:[1]

1. **최대가능도추정(MLE)**: $$\hat{\eta} = \arg\max_{\eta} P(f(x_{1:n})|\eta)$$

2. **최대사후확률추정(MAP)**: $$\hat{\eta} = \arg\max_{\eta} P(\eta|f(x_{1:n})) = \arg\max_{\eta} P(f(x_{1:n})|\eta)P(\eta)$$

3. **완전 베이지안 접근**: 

$$ P(f(x)=y|f(x_{1:n})) = \int P(f(x)=y|f(x_{1:n}), \eta) P(\eta|f(x_{1:n})) d\eta \approx \frac{1}{J}\sum_{j=1}^J P(f(x)=y|f(x_{1:n}), \eta = \hat{\eta}_j) $$

#### 2.4 획득함수 상세 분석

##### 2.4.1 Expected Improvement (EI)

**개념**: 현재까지의 최선 관측값 $$f_n^* = \max_{m \leq n} f(x_m)$$을 초과할 예상 개선량입니다.[1]

$$ EI_n(x) := E_n\left[[f(x) - f_n^*]^+\right] $$

**폐쇄형 해**:[1]

$$ EI_n(x) = [\Delta_n(x)]^+ + \sigma_n(x)\phi\left(\frac{\Delta_n(x)}{\sigma_n(x)}\right) - |\Delta_n(x)|\Phi\left(\frac{\Delta_n(x)}{\sigma_n(x)}\right) $$

여기서:
- $$\Delta_n(x) := \mu_n(x) - f_n^*$$ (예상되는 개선)
- $$\phi$$: 표준정규분포의 확률밀도함수
- $$\Phi$$: 표준정규분포의 누적분포함수

**특성**: 
- **탐사-개발 트레이드오프**: 높은 기대값(착취, exploitation)과 높은 불확실성(탐사, exploration)을 모두 추구합니다.[1]
- 이전에 평가한 지점에서는 EI = 0입니다.[1]

##### 2.4.2 Knowledge Gradient (KG)

**개념**: 샘플링으로 인한 사후평균의 최댓값 증가를 측정합니다.[1]

```math
KG_n(x) := E_n[\mu^*_{n+1} - \mu^*_n | x_{n+1} = x]
```

여기서:
- $$\mu^*\_n := \max_{x'} \mu_n(x')$$: 현재 최적 사후평균
- $$\mu^*\_{n+1} := \max_{x'} \mu_{n+1}(x')$$: 샘플링 후 최적 사후평균

**계산 방법 (Algorithm 2)**:
```
1. μ*ₙ = max μₙ(x') 계산
2. J번 반복:
   - yₙ₊₁ ~ Normal(μₙ(x), σₙ²(x)) 시뮬레이션
   - 업데이트된 사후평균 μₙ₊₁ 계산
   - μ*ₙ₊₁ = max μₙ₊₁(x') 계산
   - Δ(j) = μ*ₙ₊₁ - μ*ₙ
3. KGₙ(x) ≈ (1/J)∑Δ(j)
```

**KG의 장점**:
- 노이즈가 있는 경우 EI보다 우수합니다.[1]
- 다중 충실도, 파생정보, 제약조건 등 복잡한 문제에서 실질적 성능 향상을 제공합니다.[1]

##### 2.4.3 Entropy Search (ES)와 Predictive Entropy Search (PES)

**Entropy Search**:[1]

```math
ES_n(x) = H(P_n(x^*)) - E_{f(x)}[H(P_n(x^* | f(x)))]
```

- $$x^*$$: 전역 최적점
- $$H(P_n(x^*))$$: 최적점 위치의 불확실성(엔트로피)

**Predictive Entropy Search**:[1]

```math
PES_n(x) = H(P_n(f(x))) - E_{x^*}[H(P_n(f(x) | x^*))]
```

***

### 3. 성능 향상 메커니즘

#### 3.1 기본 문제에서의 성능

| 측면 | 설명 |
|------|------|
| **EI 성능** | 소음이 없는 표준 문제에서 양호한 성능, 계산이 빠름 |
| **KG 성능** | 표준 문제에서 EI과 비슷하거나 약간 우수 |
| **ES/PES 성능** | 정보 기반 문제에서 우수, 계산이 더 복잡 |

#### 3.2 다중 단계 최적성 근처 성능

특히 주목할 점은 **실험적으로 검증된 근최적성**입니다:[1]

- **KG 획득함수**: 계산 가능한 다중 단계 최적 알고리즘의 98% 수준
- **ES 획득함수**: 1차원 확률적 근-찾기 문제에서 다중 단계 최적

이는 **현재의 단계별 최적 획득함수들이 이론적 한계에 매우 근접**함을 시사합니다.[1]

---

### 4. 일반화 성능 향상 가능성

#### 4.1 이론적 일반화 성능 분석

논문은 일반화 성능 향상의 주요 원천을 제시합니다:[1]

1. **커널 선택의 영향**: 커널이 참 함수의 특성을 얼마나 잘 반영하는지가 중요합니다
2. **하이퍼파라미터 최적화**: MAP/완전 베이지안 접근이 MLE보다 더 안정적 일반화를 제공합니다
3. **적응적 탐사-개발**: EI의 자동적 균형이 무작위 탐사보다 더 효율적입니다

#### 4.2 다양한 문제 설정에서의 일반화

**표준 문제 (소음 없음)**:
- 이론적으로 약 $$O(n^{-3+\delta})$$ 수렴률이 알려져 있습니다.[1]

**노이즈가 있는 경우**:
- **핵심 발견**: KG, ES, PES는 직접 적용 가능하며 최적성을 유지합니다
- **EI의 한계**: 직접 적용 불가, Scott et al.(2011)의 KGCP가 "가장 자연스러운 일반화"라고 논문은 주장합니다.[1]
- **성능**: "KG는 실질적 노이즈 문제에서 EI를 실질적으로 능가합니다"[1]

**수정된 기댓개선도 (Noisy Measurements에서)**:
$$ E_n[\mu^{**}_{n+1} - \mu^{**}_n | x_{n+1} = x] $$

여기서 $$\mu^{**}_n = \max_{i=1,...,n} \mu_n(x_i)$$는 평가된 지점들 중에서만 최적점을 선택합니다.[1]

#### 4.3 고차원 문제에서의 도전과 해결책

**제한사항**:[1]
- 표준 베이지안 최적화는 $$d \leq 20$$에 최적
- 고차원에서는 구조 활용이 필수

**해결 방향**:[1]
- **구조 식별**: 특정 변수의 중요도 학습
- **임의 임베딩**: 고차원 문제를 저차원으로 축소
- **가법 모델**: 약한 상호작용 가정 활용

***

### 5. 한계(Limitations)

#### 5.1 이론적 한계

1. **다중 단계 최적성 부재**:
   - 현재의 EI, KG, ES, PES는 $$N = n+1$$일 때만 최적[1]
   - 동적 프로그래밍은 "차원의 저주"로 인해 실무 적용 불가[1]
   - 그러나 실제로는 "98% 최적 성능"으로 충분할 수 있음[1]

2. **수렴률 분석 부족**:
   - Bull(2011)은 EI + 주기적 균등 샘플링에 대해서만 수렴률 제시[1]
   - 균등 샘플링 제거 시 수렴률이 동일한지 미지[1]

#### 5.2 실무적 한계

1. **계산 복잡성**:
   - Gaussian Process: $$O(n^3)$$ 계산 복잡성 (Cholesky 분해)
   - 수백 개 평가 이상에서 메모리/시간 제약[1]

2. **차원성 저주**:
   - 고차원 문제에서 획득함수 최적화 자체가 어려움[1]

3. **하이퍼파라미터 선택**:
   - 잘못된 커널 선택은 성능을 크게 저하[1]
   - MAP/완전 베이지안 접근도 계산량 증가[1]

#### 5.3 가정의 한계

1. **연속성 가정**: 불연속 함수에 부적합[1]
2. **블랙박스 가정**: 구조가 있는 문제에서 비효율[1]
3. **정상성 가정**: Snoek et al.(2014)의 입력 왜곡, Kersting et al.(2007)의 이분산 GP 등이 필요한 경우[1]

---

### 6. 연구 영향 및 향후 고려사항

#### 6.1 현재의 영향력

**광범위한 응용 분야**:[1]
- **기계학습**: 신경망 하이퍼파라미터 튜닝 (Snoek et al., 2012)
- **재료과학/화학**: 나노구조 설계, 열전도 물질 발굴
- **약물 발견**: 분자 설계의 순차적 실험 배치
- **공학**: 구조 최적화, 환경 모델 보정
- **강화학습**: 정책 최적화

#### 6.2 향후 연구 방향

논문은 5가지 주요 연구 방향을 제시합니다:[1]

**1) 심층 이론적 이해 필요**:
   - 다중 단계 최적 알고리즘의 실무적 가치
   - 유한 시간 수렴 한계의 발전
   - 임의 설정에서의 수렴률 분석

**2) 새로운 통계적 접근**:
   - GP 외의 모델 탐색 (예: 트리 기반 모델)
   - 응용 분야별 맞춤형 모델

**3) 고차원 확장성**:
   - 구조 자동 식별 알고리즘
   - 임의 임베딩의 효율성 개선
   - 적응적 차원 축소

**4) 특수 구조 활용**:
   - 병렬화 방법 고도화
   - 비계층적 다중 정보원 최적화
   - 환경 변동성 대응

**5) 중요 응용 분야 타게팅**:
   - **화학/화학공학/재료설계**: 수년 소요, 높은 비용의 물리 실험이 필요한 분야
   - 현재 많은 연구자가 베이지안 최적화의 잠재력을 모르는 상황[1]

#### 6.3 실무 적용 시 고려사항

**전략적 선택 가이드**:

| 상황 | 권장사항 | 이유 |
|------|---------|------|
| 저차원($$d \leq 10$$), 소음 없음 | EI 또는 KG | 계산 빠르고 안정적 |
| 중차원($$d \leq 20$$), 소음 있음 | KG 또는 PES | 노이즈 처리 우수 |
| 고차원($$d > 20$$) | 구조 활용 + 임의 임베딩 | 차원성 저주 극복 필수 |
| 병렬 평가 가능 | 병렬 KG | Wu & Frazier(2016) 알고리즘 |
| 다중 충실도 정보 | Multi-fidelity KG | 저비용 정보원 활용 |

**소프트웨어 생태계** (2018년 기준):[1]
- R: DiceKriging, DiceOptim, laGP
- Python: GPyOpt, MOE, Spearmint
- 특화: Cornell MOE (병렬 KG), GPFlow/GPyTorch (딥러닝 통합)

***

### 7. 결론

"A Tutorial on Bayesian Optimization"은 **형식적 이론과 실무적 알고리즘의 균형을 맞춘 획기적 가이드**입니다. 특히 **노이즈가 있는 경우의 Expected Improvement 일반화**는 이론적 엄밀성과 실용성을 동시에 제공합니다.

**핵심 기여의 재정의**:
- 베이지안 최적화의 확장 가능성을 구체적으로 제시
- 획득함수의 다양한 선택과 각각의 적용 조건 명확화
- 미래 연구의 구체적 방향 제시

**일반화 성능 관점에서의 의의**:
- **적응적 탐사-개발**: 무작위 탐사보다 $$O(n^{-3+\delta})$$ 수렴률로 우수
- **불확실성 명시화**: 사후분포를 통한 신뢰도 있는 결정
- **확장 문제 대응**: 노이즈, 병렬성, 다중 정보원에 강건

**실무 적용 효과**:
- 약물 발견, 재료 설계 등 극도로 비용이 높은 영역에서 **탐사 효율 수배 향상**
- 신경망 하이퍼파라미터 튜닝에서 **수용 가능한 성능으로의 시간 단축**

향후 연구는 **고차원 확장성**과 **다중 단계 최적 알고리즘의 실무화**에 집중할 것으로 예상되며, 이는 기계학습과 과학적 발견의 가속화를 가능하게 할 것입니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/f01978c8-0962-4dae-86f6-5237d3264757/1807.02811v1.pdf)
