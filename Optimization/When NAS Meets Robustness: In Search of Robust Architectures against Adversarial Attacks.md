# When NAS Meets Robustness: In Search of Robust Architectures against Adversarial Attacks

### 1. 핵심 주장 및 주요 기여 요약

**핵심 주장**

본 논문의 중심 논제는 신경망의 **적대적 로버스트니스(adversarial robustness)가 주로 학습 알고리즘과 손실 함수에만 의존하지 않으며, 네트워크 아키텍처 자체가 상당한 영향을 미친다**는 것입니다. 연구진은 아키텍처 관점에서 체계적으로 적대적 공격에 강건한 신경망의 패턴을 규명하고, 이를 바탕으로 일관되게 우수한 성능을 보이는 로버스트 아키텍처 계열(RobNets)을 제시합니다.[1]

**주요 기여**

논문의 세 가지 주요 기여는 다음과 같습니다:[1]

1. **밀집 연결 패턴의 중요성 발견**: 아키텍처 밀도(density)가 높을수록 적대적 공격에 대한 견고성이 증가한다는 강한 상관관계를 입증했습니다.

2. **계산 예산 제약 하에서의 최적 아키텍처 전략**: 제한된 파라미터 수에서 직접 연결 간선(direct edge)에 합성곱 연산을 추가하는 것이 더 효과적임을 발견했습니다.

3. **FSP(Flow of Solution Procedure) 행렬 기반 로버스트니스 지표 제시**: 네트워크의 깊은 층에서 FSP 행렬의 거리가 로버스트니스의 좋은 지표가 될 수 있음을 제시했습니다.

***

### 2. 해결하고자 하는 문제 및 제안 방법

**문제 정의**

기존 적대적 방어 연구는 다음 세 가지 측면에 집중했습니다:[1]

- 특화된 적대적 학습 알고리즘
- 손실 함수 및 정규화 기법
- 이미지 전처리 방법

그러나 네트워크 아키텍처 자체가 로버스트니스에 미치는 영향에 대한 체계적 연구는 부족했습니다. 논문은 다음 세 가지 핵심 질문을 제기합니다:[1]

1. 적대적 로버스트니스에 중요한 네트워크 아키텍처 패턴은 무엇인가?
2. 제한된 모델 용량 예산 내에서 파라미터를 어떻게 할당해야 로버스트니스를 효율적으로 향상시킬 수 있는가?
3. 로버스트 네트워크 아키텍처를 나타내는 통계적 지표는 무엇인가?

**제안 방법: 강건 아키텍처 탐색 프레임워크**

**One-shot NAS 기반 탐색**: 논문은 초대형 수퍼넷(supernet)을 한 번만 학습한 후, 여기서 샘플링된 서브네트워크를 적대적 학습으로 미세조정하는 방식을 채택합니다. 이를 통해 1,000개 이상의 아키텍처에 대한 로버스트니스를 효율적으로 평가할 수 있습니다.[1]

**적대적 로버스트니스 공식화**

네트워크의 적대적 로버스트니스는 다음과 같이 공식화됩니다:

$$
\min_{\theta} \mathbb{E}_{(x,y) \sim \mathcal{D}} \left[ \max_{x' \in \mathcal{S}} L(y, M(x'; \theta)) \right]
$$

여기서 $$\mathcal{S} = \{x' : \|x - x'\|_p < \epsilon\}$$는 허용된 섭동 범위이고, $$M$$은 모델, $$\mathcal{D}$$는 데이터 분포, $$L$$은 손실 함수입니다.[1]

**아키텍처 밀도(Architecture Density) 정의**

아키텍처 밀도는 다음과 같이 정의됩니다:[1]

$$
D = \frac{|E_{\text{connected}}|}{|E|} = \frac{\sum_{i,j,k} \alpha^{(i,j)}_k}{|E|}
$$

여기서 $$\alpha^{(i,j)}_k$$는 노드 i에서 j로의 엣지에서 k번째 연산의 선택 여부를 나타내는 이진 변수입니다.[1]

**FSP 행렬 기반 로버스트니스 지표**

FSP 행렬은 각 셀의 입출력 특성 맵 간의 그래미안을 계산합니다:[1]

$$
G_l(x; \theta) = \frac{\sum_{s=1}^{h} \sum_{t=1}^{w} F^{\text{in}}_{l,s,t}(x; \theta) \times F^{\text{out}}_{l,s,t}(x; \theta)}{h \times w}
$$

FSP 행렬 손실은:

$$
L^{\text{FSP}}_l = \frac{1}{N} \sum_{x} \|(G_l(x; \theta) - G_l(x'; \theta)\|^2_2
$$

깊은 층에서 FSP 거리가 작을수록 로버스트니스가 높습니다.[1]

***

### 3. 모델 구조 상세 설명

**검색 공간 설계**

논문의 검색 공간은 세포 기반(cell-based) 구조를 채택합니다. 각 셀은 다음과 같이 구성됩니다:[1]

- **노드 수**: 중간 노드 N = 4개
- **엣지**: 이전 두 셀의 출력과 중간 노드들을 연결
- **연산 풀**: 3×3 분리 가능 합성곱(separable convolution), 항등 연산(identity), 제로 연산(zero)

이는 기존 NAS의 과도하게 큰 연산 풀을 줄여 적대적 학습의 계산 부담을 완화합니다.[1]

**중요한 설계 선택**:

1. **다중 엣지 허용**: 두 노드 간에 여러 개의 연산을 배치 가능하게 하여 ResNet과 DenseNet 같은 고전적 아키텍처도 검색 공간에 포함되도록 합니다.

2. **밀집 연결 우선**: 직접 연결 간선과 스킵 연결 간선을 구분하여, 어느 유형의 연결이 더 로버스트하는지 분석합니다.

**강건 검색 알고리즘**

1. **수퍼넷 학습**: 모든 $$\alpha$$를 1로 설정하여 초대 네트워크 학습
2. **경로 드롭아웃**: 매 배치마다 임의로 일부 $$\alpha$$ 엘리먼트를 0으로 설정하여 특정 아키텍처 편향 방지
3. **적대적 학습**: PGD 적대적 학습으로 로버스트니스 확보
4. **미세조정**: 샘플링된 아키텍처를 3-5 에포크 추가 미세조정

---

### 4. 성능 향상 및 실험 결과

**CIFAR-10 벤치마크 결과**

표 1의 결과에 따르면 RobNet 계열은 기존 아키텍처 대비 현저한 성능 개선을 달성합니다:[1]

| 모델 | 자연 정확도 | PGD-100 | 파라미터 수 |
|------|-----------|---------|----------|
| ResNet-18 | 78.38% | 45.10% | 11.17M |
| WideResNet-28-10 | 86.43% | 46.90% | 36.48M |
| DenseNet-121 | 82.72% | 47.46% | 6.95M |
| **RobNet-large** | 78.57% | **49.24%** | 6.89M |
| **RobNet-free** | 82.79% | **52.57%** | 5.49M |

**주요 개선 사항**:

- **적대적 정확도 개선**: 약 5% 절대값 개선(47.5% → 52.6%)
- **파라미터 효율성**: 더 적은 파라미터로 우수한 성능 달성
- **멀티태스크 효과**: 자연 정확도와 적대적 로버스트니스 동시 개선

**다양한 데이터셋에 대한 전이성**

CIFAR-10에서 학습된 RobNet 아키텍처를 다른 데이터셋에 직접 적용한 결과:[1]

| 모델 | SVHN | CIFAR-100 | Tiny-ImageNet |
|------|------|----------|---------------|
| ResNet-50 | 47.23% | 22.38% | 19.12% |
| **RobNet-large** | 51.26% | 23.19% | 19.90% |
| **RobNet-free** | **55.59%** | **23.87%** | **20.87%** |

특히 SVHN에서 약 10% 성능 향상을 보입니다.[1]

**화이트박스 vs 블랙박스 공격**

논문은 다양한 공격 방식에 대해 평가합니다:[1]

- **화이트박스**: PGD-20, PGD-100, FGSM, DeepFool, MI-FGSM
- **블랙박스**: 전이 기반 공격(transfer-based attack)

RobNet-free는 모든 공격 유형에 대해 우수한 성능을 유지합니다.[1]

**기존 방어 기법과의 보완성**

특성 제거(feature denoising)와 같은 기존 방어 기법과 결합했을 때, RobNet은 더욱 향상된 성능을 보입니다.[1]

***

### 5. 일반화 성능 향상 관련 내용 (중점 분석)

**핵심 발견사항**

**1. 아키텍처 밀도와 로버스트니스의 상관관계**

논문의 핵심 발견은 **아키텍처 밀도가 높을수록 적대적 로버스트니스가 증가한다**는 것입니다. 이를 검증하기 위해 논문은 다음을 수행했습니다:[1]

- 1,000개 아키텍처의 t-SNE 시각화: 로버스트한 상위 300개와 취약한 하위 300개 아키텍처가 명확히 분리됨
- 선형 분류기 학습: 아키텍처 파라미터로부터 로버스트니스 예측 시 98.7% 정확도 달성
- 밀도-로버스트니스 상관 분석: 강한 양의 상관관계 확인

이러한 밀집 연결 패턴이 왜 일반화 성능을 향상시키는지에 대한 이론적 근거는 다음과 같습니다:[1]

- **정보 흐름 개선**: 밀집 연결은 계층 간 정보 흐름을 촉진하여 특성 표현의 다양성 증가
- **그래디언트 흐름**: 더 많은 경로를 통한 역전파는 더 안정적인 그래디언트 업데이트 제공
- **적대적 특성 학습**: 밀집 연결은 적대적 특성에 더 강건한 표현을 학습하도록 유도

**2. 계산 예산 제약 하에서의 최적 전략**

논문은 세 가지 계산 예산(작음, 중간, 큼)에서 아키텍처 설계의 영향을 분석했습니다:[1]

**직접 연결 vs 스킵 연결의 효과**:

- **소형 예산**: 직접 연결에 합성곱을 배치하는 것이 현저히 효과적 (상관 계수: 0.5 이상)
- **중형 예산**: 여전히 직접 연결의 합성곱이 유리하나 효과 감소
- **대형 예산**: 밀집 연결 패턴이 주요 기여 요소

이는 **저 자원 시나리오에서 구조적 설계가 매개변수 수보다 중요**함을 시사합니다.[1]

**3. FSP 행렬을 통한 일반화 메커니즘 분석**

셀 제약을 제거한 더 큰 검색 공간에서, 논문은 FSP 행렬이 로버스트니스의 신뢰할 만한 지표임을 발견했습니다:[1]

**FSP 거리의 의미**:

- **깊은 층에서의 중요성**: 네트워크의 깊은 층에서 FSP 거리가 크면, 깨끗한 데이터와 적대적 데이터의 특성 맵 간 큰 불일치 발생
- **로버스트니스 지표로의 활용**: FSP 거리가 작을수록 일관된 특성 표현 → 높은 로버스트니스

이는 **적대적 로버스트니스가 입력에 대한 내부 표현의 안정성과 밀접한 관련**이 있음을 시사합니다. 구체적으로:[1]

$$
\text{높은 로버스트니스} \Rightarrow \text{낮은 FSP 거리} \Rightarrow \text{특성 표현 안정성}
$$

**일반화 성능 향상의 메커니즘**

1. **다양한 데이터셋 전이성**: CIFAR-10에서 학습한 아키텍처가 SVHN, CIFAR-100, Tiny-ImageNet에서도 우수한 성능 유지[1]
   - 이는 RobNet의 밀집 구조가 데이터셋 독립적인 로버스트 특성 학습을 유도함을 의미

2. **공격 유형 독립성**: 다양한 공격(PGD, FGSM, DeepFool, MI-FGSM, AutoAttack)에 대한 일관된 성능[1]
   - 구조적 로버스트니스가 특정 공격이 아닌 일반적 적대적 노이즈에 대응

3. **조건부 독립성**: 기존 방어 기법(특성 제거)과 결합 시에도 상승 효과[1]
   - 아키텍처 기반 로버스트니스가 학습 알고리즘 기반 방어와 직교(orthogonal)

***

### 6. 논문의 한계

**인정된 한계**

1. **자연 정확도와의 트레이드오프**: 소형 RobNet 모델들이 WideResNet 대비 자연 정확도가 낮음 (78% vs 86%)[1]

2. **계산 비용**: 로버스트 아키텍처 탐색 자체가 상당한 적대적 학습을 요구하여 계산 비용이 여전히 높음

3. **검색 공간의 제약**: 셀 기반 설정에서 실제 아키텍처 공간의 작은 부분만 탐색
   - 이를 보완하기 위해 셀 제약 제거 실험 시행하나, 이마저도 FSP 필터링으로 제한

4. **이론적 근거 부재**: 밀집 연결이 왜 적대적 로버스트니스에 유리한지에 대한 수학적 증명 미흡

***

### 7. 앞으로의 연구에 미치는 영향 및 고려사항

**현재 연구 동향 (2023-2025)**

최신 연구들은 본 논문의 아이디어를 확장하고 있습니다:[2][3][4][5][6]

**1. 포괄적 로버스트니스 평가의 필요성**

2023-2024년 연구는 $$l_\infty$$ 노름만이 아닌 **다양한 노이즈 유형에 대한 로버스트니스 평가 필요성**을 강조합니다. 이는 본 논문의 한계를 보완합니다.[4]

**2. 벤치마크 데이터셋 구축**

최근 "NARes" 같은 포괄적 신경망 아키텍처 데이터셋이 구축되고 있습니다. 이는 RobNets의 발견을 체계적으로 검증하고 확장할 기반을 제공합니다.[7]

**3. 일반화와 견고성의 관계 규명**

2024년 연구는 **구조적 사전 정보를 통한 동시 일반화 및 로버스트니스 향상**을 목표로 합니다. 예를 들어, Elastic Dictionary Learning Networks(EDLNets)는 사전 학습 영감의 아키텍처 설계로 RobustBench에서 최첨단 결과를 달성했습니다.[8]

**4. 스파시티와 로버스트니스의 트레이드오프**

2024년 새로운 방향은 **에지 디바이스 배포를 위한 경량 로버스트 모델 설계**입니다. ANAS-P 같은 최신 방법은 프루닝 정책을 통해 계산 효율성과 로버스트니스를 동시 달성합니다.[5][9]

**향후 연구 시 고려할 점**

**1. 이론적 기초 강화**

본 논문은 주로 경험적 발견에 의존합니다. 향후 연구는:

- **신경 접선 커널(Neural Tangent Kernel, NTK) 이론**: 아키텍처 구조와 로버스트 일반화의 관계를 수학적으로 규명[4]
- **영향 함수(Influence Function)**: 아키텍처 설계 선택이 로버스트니스에 미치는 인과적 영향 분석[8]

**2. 다중 목표 최적화의 고도화**

현재는 로버스트니스와 자연 정확도의 트레이드오프가 존재합니다. 향후 방향:

- **파레토 최적 아키텍처 탐색**: 로버스트니스-정확도-효율성의 3중 목표 동시 달성[3][10]
- **적응적 방어 메커니즘**: 공격 유형별 최적 아키텍처 설계[6]

**3. 적대적 학습 방식의 통합**

최신 연구는 다양한 적대적 학습 방법(TRADES, MART, DPGD)과 아키텍처 탐색의 상호작용을 분석하고 있습니다.[11][10]

**4. 구조화된 로버스트니스 설계 원칙**

본 논문의 경험적 발견을 다음과 같이 체계화할 필요:

- **밀집 연결의 작동 메커니즘**: 왜 DenseNet 스타일이 우수한가?
- **계층별 역할 분화**: 얕은 층과 깊은 층에서 다른 최적 구조가 존재하는가?
- **특성 맵 기하학**: FSP 행렬이 나타내는 특성 공간의 기하학적 성질

**5. 실용적 배포 고려사항**

- **메모리 효율성**: 밀집 연결의 메모리 오버헤드 문제 해결
- **추론 속도**: 로버스트 아키텍처의 계산 복잡성 감소
- **라벨 효율성**: 적은 라벨로 로버스트 모델 학습

***

### 결론

"When NAS Meets Robustness"는 **신경망 아키텍처가 적대적 로버스트니스에 중대한 역할을 한다**는 중요한 통찰을 제공합니다. 밀집 연결 패턴, 계산 예산 하 최적 전략, FSP 행렬 지표라는 세 가지 발견은 향후 로버스트 신경망 설계의 기초가 되었습니다.[1]

2023-2025년 최신 연구는 본 논문을 다음과 같이 확장하고 있습니다:[10][2][3][5][6][7][4][8]

1. **이론적 엄밀성 강화**: NTK, 영향 함수 등으로 경험적 발견의 이론화
2. **포괄적 로버스트니스**: 다양한 노이즈와 공격 유형에 대한 동시 평가
3. **효율성과의 균형**: 스파시티, 메모리, 추론 속도 고려
4. **실전적 응용**: 에지 디바이스, 저자원 환경에 맞춘 설계

이러한 발전들은 본 논문의 핵심 아이디어(아키텍처 설계의 중요성)가 여전히 유효하며, 적대적 로버스트니스 연구의 새로운 패러다임을 제시했음을 보시했음을 보여줍니다.

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/728cb4d1-bf0a-43d3-9b5a-e635862d8a45/1911.10695v3.pdf)
[2](https://arxiv.org/abs/2203.03128)
[3](https://arxiv.org/html/2405.05502)
[4](https://arxiv.org/abs/2403.13134)
[5](https://www.frontiersin.org/articles/10.3389/fhpcp.2024.1301384/full)
[6](https://arxiv.org/html/2406.06792v1)
[7](https://openreview.net/forum?id=AZVvTBxTdZ)
[8](https://arxiv.org/abs/2502.00834)
[9](https://www.frontiersin.org/journals/high-performance-computing/articles/10.3389/fhpcp.2024.1301384/full)
[10](https://arxiv.org/abs/2405.05502)
[11](https://www.sciencedirect.com/science/article/abs/pii/S0925231225022714)
[12](https://arxiv.org/pdf/1906.11667.pdf)
[13](http://arxiv.org/pdf/2305.07308.pdf)
[14](http://arxiv.org/pdf/2301.03110.pdf)
[15](https://ieeexplore.ieee.org/document/10490151/)
[16](https://arxiv.org/html/2508.01845v1)
[17](https://proceedings.mlr.press/v130/xing21b.html)
[18](http://www.scitepress.org/Papers/2025/138267/138267.pdf)
[19](https://www.sciencedirect.com/science/article/abs/pii/S0925231225024713)
