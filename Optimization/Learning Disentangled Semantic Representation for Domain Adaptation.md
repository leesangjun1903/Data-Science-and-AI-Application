# Learning Disentangled Semantic Representation for Domain Adaptation

## 1. 핵심 주장과 주요 기여

본 논문은 **비지도 도메인 적응(Unsupervised Domain Adaptation)** 분야에서 기존 방법들이 얽혀있는(entangled) 특징 공간에서 도메인 불변 표현을 추출하려는 것과 달리, **분리된(disentangled) 잠재 공간**에서 의미론적 정보를 추출하는 새로운 패러다임을 제시합니다.[1]

**핵심 기여:**

- 데이터 생성 과정이 두 개의 독립적인 잠재 변수, 즉 **의미론적 잠재 변수(semantic latent variables, $$z_y$$)**와 **도메인 잠재 변수(domain latent variables, $$z_d$$)**에 의해 제어된다는 인과적 가정을 도입[1]
- Variational Auto-Encoder(VAE) 기반 재구성 아키텍처와 **이중 적대적 네트워크(dual adversarial network)**를 결합한 새로운 DSR(Disentangled Semantic Representation) 프레임워크 제안[1]
- 분리된 표현 학습이 오류를 감소시킨다는 이론적 분석 제공 및 목표 도메인 일반화 오류에 대한 상한(upper bound) 도출[1]
- Office-31과 Office-Home 벤치마크에서 최첨단 성능 달성: Office-31에서 평균 88.6%, Office-Home에서 평균 64.9%의 정확도 기록[1]

---

## 2. 해결하고자 하는 문제

### 2.1 도메인 시프트와 거짓 정렬 문제

기존 도메인 적응 방법들은 **거짓 정렬(false alignment) 문제**로 어려움을 겪습니다. 이는 도메인 정보와 의미론적 정보가 얽혀있는 복잡한 다양체 구조 때문에 발생합니다. 예를 들어, "돼지(pig)"와 "헤어드라이어(hair drier)"를 분류할 때, 분홍색 페파피그(Peppa Pig)는 시각적으로 분홍색 헤어드라이어와 유사하여 특징 공간에서 잘못 정렬될 수 있습니다.[1]

**기존 방법의 한계:**

- **특징 정렬 방법(Feature Alignment)**: MMD(Maximum Mean Discrepancy)를 사용하여 도메인 간 분포 차이를 최소화하지만, 얽힌 특징 공간에서 의미 정보가 보존되지 않음[1]
- **적대적 학습(Adversarial Learning)**: 도메인 판별기를 속이는 방식으로 표현을 추출하나, 도메인 정보가 완전히 제거되지 않음[1]
- **의미론적 정렬(Semantic Alignment)**: 유사 레이블(pseudo-label)이 필요하여 레이블링 정확도의 불확실성으로 인한 오류 누적 발생[1]

---

## 3. 제안 방법: DSR 모델 구조 및 수식

### 3.1 인과적 데이터 생성 모델

DSR은 데이터 $$x$$가 두 독립적인 잠재 변수에 의해 생성된다고 가정합니다:
- $$z_y \in \mathbb{R}^{K_y}$$: 의미론적 잠재 변수 (레이블과 관련)
- $$z_d \in \mathbb{R}^{K_d}$$: 도메인 잠재 변수 (도메인 특성과 관련)

**독립성 가정**: $$z_y \perp\!\!\!\perp z_d$$ (의미론적 변수와 도메인 변수는 서로 독립)[1]

### 3.2 모델 아키텍처

DSR 프레임워크는 두 개의 주요 블록으로 구성됩니다:[1]

**1) 재구성 블록 (Reconstruction Block)**

VAE를 사용하여 잠재 변수를 재구성합니다. 변분 하한(ELBO)은 다음과 같이 분해됩니다:

$$
L_{ELBO}(\phi_y, \phi_d, \theta_r) = -D_{KL}(q_{\phi_y}(z_y|G(x)) \| P(z_y)) - D_{KL}(q_{\phi_d}(z_d|G(x)) \| P(z_d)) + \mathbb{E}_{q_{\phi_y,d}(z_y,z_d|G(x))}[\log P_{\theta_r}(G(x)|z_y, z_d)]
$$

여기서:
- $$G(x)$$: 백본 특징 추출기 (예: ResNet)
- $$H_y(G(x); \phi_y)$$: 의미론적 인코더
- $$H_d(G(x); \phi_d)$$: 도메인 인코더
- $$P_{\theta_r}(G(x)|z_y, z_d)$$: 디코더[1]

**2) 분리 블록 (Disentanglement Block)**

이중 적대적 학습 모듈을 통해 두 잠재 변수를 분리합니다:

**① 의미론적 적대적 학습 모듈 (Label Adversarial Learning)**

의미 정보를 $$z_y$$로 끌어당기고 도메인 정보를 제거:

$$
L_{sem}(\phi_y, \theta_{y,y}, \theta_{y,d}) = \frac{\delta}{n_S} \sum_{x_i^s \in D_S} L_y(C_y(H_y(G(x); \phi_y); \theta_{y,y}), y_i) - \frac{\lambda}{n} \sum_{x_i \in (D_S, D_T)} L_d(C_d(H_y(G(x); \phi_y); \theta_{y,d}), d_i)
$$

- $$C_y$$: 레이블 분류기
- $$C_d$$: 도메인 분류기 (GRL 적용)
- $$\delta, \lambda$$: 균형 파라미터[1]

**② 도메인 적대적 학습 모듈 (Domain Adversarial Learning)**

도메인 정보를 $$z_d$$로 끌어당기고 의미 정보를 제거:

$$
L_{dom}(\phi_d, \theta_{d,d}, \theta_{d,y}) = \frac{1}{n} \sum_{x_i \in (D_S, D_T)} L_d(C_d(H_d(G(x); \phi_d); \theta_{d,d}), d_i) - \frac{\omega}{n} \sum_{x_i \in (D_S, D_T)} L_E(C_y(H_d(G(x); \phi_d); \theta_{d,y}))
$$

- $$L_E$$: 최대 엔트로피 손실 (비지도 목표 도메인 활용)
- $$\omega$$: 균형 파라미터[1]

**전체 목적 함수:**

$$
L(\phi_y, \theta_{y,d}, \theta_{y,y}, \phi_d, \theta_{d,d}, \theta_{d,y}, \theta_r) = L_{ELBO} + \beta L_{sem} + \gamma L_{dom}
$$

여기서 $$\beta = 1, \gamma = 1$$[1]

### 3.3 이론적 분석

**정리 1**: $$z_y \perp\!\!\!\perp z_d$$ 가정 하에, 분리된 표현의 오류는 다음과 같이 감소합니다:

$$
\epsilon_y^S(h) = \epsilon_S(h) - \alpha_S
$$
$$
\epsilon_y^T(h) = \epsilon_T(h) - \alpha_T
$$

여기서 $$\alpha_S = \mathbb{E}_{z_d \sim \tilde{D}_S}[C(z_d) - h(z_d)]$$는 도메인 변수에 의한 오류 기여도[1]

**정리 2**: 목표 도메인 오류의 상한:

$$
\epsilon_y^T(h) \leq \eta + \epsilon_y^S(h) + d_H(\tilde{D}_S, \tilde{D}_T)
$$

여기서 $$\eta = \epsilon_y^T(h^\*) + \alpha_T^\* + \epsilon_y^S(h^\*) + \alpha_S^* + \alpha_S - \alpha_T$$

[1]

이는 분리된 표현 학습이 소스 도메인 오류를 줄여 목표 도메인 일반화 성능을 개선함을 보여줍니다.

***

## 4. 실험 결과 및 성능 향상

### 4.1 Office-31 데이터셋

31개 클래스의 4,652개 이미지를 포함하는 세 도메인(Amazon, Webcam, DSLR)에서 평가:[1]

| 전이 작업 | DANN | CDAN-M | **DSR (제안)** |
|-----------|------|---------|----------------|
| D→A | 68.2 | 71.0 | **73.5** |
| W→A | 67.4 | 70.3 | **73.9** |
| A→W | 82.0 | 93.1 | **93.1** |
| 평균 | 82.2 | 87.7 | **88.6** |

**주요 성과**: 어려운 전이 작업(D→A, W→A)에서 큰 향상을 보이며, 이는 소스 도메인이 더 복잡한 시나리오를 가질 때 DSR의 분리된 의미론적 표현이 효과적임을 시사[1]

### 4.2 Office-Home 데이터셋

65개 클래스의 약 15,500개 이미지를 포함하는 네 도메인(Art, Clipart, Product, Real-world):[1]

| 전이 작업 | MSTN | CDAN-M | **DSR (제안)** |
|-----------|------|---------|----------------|
| Ar→Cl | 49.3 | 50.6 | **53.4** |
| Ar→Pr | 67.6 | 65.9 | **71.6** |
| Cl→Ar | 49.6 | 55.7 | **57.1** |
| 평균 | 60.9 | 62.8 | **64.9** |

**개선율**: CDAN-M 대비 **2.1% 향상**, 특히 Art와 Clipart 소스 도메인에서 뛰어난 성능[1]

### 4.3 Ablation Study

**이중 적대적 학습 모듈의 효과**:[1]
- DSR (완전 모델): 88.6% (Office-31 평균)
- DSR WD ($$\delta=1$$, 도메인 모듈 제거): 86.4%
- DSR WD ($$\delta=2$$): 86.7%

도메인 적대적 학습 모듈이 없으면 의미 정보가 손실되어 성능이 저하됨을 확인[1]

**t-SNE 시각화**: DSR이 DANN 및 MSTN보다 우수한 도메인 정렬을 달성하며 거짓 정렬 샘플 수가 현저히 적음[1]

***

## 5. 모델 일반화 성능 향상

### 5.1 분리된 표현의 일반화 메커니즘

DSR의 일반화 성능 향상은 다음 메커니즘에 기인합니다:

**① 도메인 불변 의미 추출**: $$z_y$$가 순수 의미론적 정보만 포함하도록 강제하여 도메인 변화에 강건한 표현 학습[1]

**② 이론적 오류 감소**: 정리 1에서 $$\epsilon_y^T(h) = \epsilon_T(h) - \alpha_T$$로, 도메인 정보 제거 시 목표 도메인 오류가 감소함을 증명[1]

**③ 일반화 상한 개선**: 정리 2는 소스 도메인 오류 $$\epsilon_y^S(h)$$를 줄이면 목표 도메인 오류 상한이 낮아짐을 보장[1]

**④ 의미론적 축 기반 분류**: 분리된 잠재 공간에서 의미론적 축($$z_y$$)만으로 분류 수행, 도메인 축($$z_d$$)의 영향 배제[1]

### 5.2 최신 연구 동향과의 연결

**2024-2025년 최신 연구**들은 DSR의 분리 패러다임을 확장하고 있습니다:

**① 표현 공간 분해(Representation Space Decomposition)**: DARSD(2025)는 명시적 표현 공간 분해를 통해 전이 가능한 지식을 분리하는 이론적으로 설명 가능한 프레임워크를 제안하며, 시계열 도메인 적응에서 DSR과 유사한 원리를 적용[2]

**② 인과 표현 학습(Causal Representation Learning)**: ICRL(2025)은 독립적 인과 관계 기반 도메인 일반화 모델을 제안하여 인과 요인과 비인과 요인을 분리, DSR의 $$z_y$$와 $$z_d$$ 독립성 가정을 인과적 관점에서 확장. CIRL(2022)은 인과 개입 모듈을 통해 각 차원의 표현이 인과 요인을 모방하도록 강제하여 일반화 능력 향상[3][4]

**③ 최소 충분 의미론(Minimal Semantic Sufficiency)**: MS-UDG(2024)는 비지도 도메인 일반화에서 최소 충분 의미 표현을 이론적으로 정의하고, 정보 분리 모듈(IDM)을 통해 의미와 변이 표현을 분리하여 DSR의 분리 개념을 더욱 정교화[5]

**④ 프롬프트 기반 분리(Prompt-based Disentanglement)**: 디센탱글드 프롬프트 표현(2024)은 CLIP과 같은 비전 기반 모델에서 LLM을 활용해 텍스트 프롬프트를 자동 분리하고 시각적 표현 학습을 유도하여 도메인 일반화 성능 향상[6][7]

**⑤ 다중 소스 도메인 적응**: 최신 연구들은 여러 소스 도메인에서 도메인 특화 정보와 도메인 불변 정보를 동시에 활용하는 방법을 탐구[8][9][10]

***

## 6. 한계점

### 6.1 데이터 규모 의존성

**소규모 도메인에서의 성능 저하**: DSLR 도메인(498개 이미지, 일부 클래스는 10개 미만)에서 DSR의 성능이 일부 비교 방법보다 낮음. 분리된 의미론적 표현을 재구성하기에 데이터가 불충분[1]

### 6.2 도메인 복잡성 제약

**모호한 샘플 처리 한계**: Real World(RW) 도메인처럼 모니터, 컴퓨터, 노트북이 같은 레이블로 태그된 모호한 샘플이 많은 경우, 의미 정보 분리가 어려움[1]

### 6.3 하이퍼파라미터 민감도

$$\delta, \lambda, \omega, \beta, \gamma$$ 등 여러 하이퍼파라미터가 필요하며, 데이터셋에 따른 최적 값 설정이 필요[1]

### 6.4 계산 복잡도

VAE 재구성과 이중 적대적 네트워크를 동시에 학습해야 하므로 계산 비용이 높음[1]

### 6.5 이론적 한계

**비지도 분리의 근본적 불가능성**: 최신 연구는 모델과 데이터 모두에 귀납적 편향 없이는 비지도 분리 표현 학습이 근본적으로 불가능함을 이론적으로 증명. DSR의 독립성 가정($$z_y \perp\!\!\!\perp z_d$$)은 강한 귀납적 편향이지만 실제 데이터에서 항상 성립한다는 보장이 없음[11]

**재구성-분리 트레이드오프**: 높은 분리도는 재구성 품질 저하를 초래하며, 이는 DSR의 ELBO 항과 분리 항 간 균형 문제로 나타남[12][13]

**조합적 일반화 실패**: 최근 연구는 고도로 분리된 표현이 생성 요인 값의 미확인 조합에 일반화하지 못함을 발견, 이는 DSR이 학습 중 관찰하지 못한 도메인-의미 조합에서 한계를 가질 수 있음을 시사[14]

***

## 7. 향후 연구 방향 및 고려 사항

### 7.1 최신 연구 기반 발전 방향

**① 소스 프리 도메인 적응(Source-Free Domain Adaptation)**

SFUDA(2024)는 소스 데이터에 동시 접근하지 않고 사전 학습된 모델을 목표 도메인에 적응시키는 프레임워크를 제안합니다. DSR을 SFUDA 설정으로 확장하여:[15][16]
- 사전 학습 단계에서 분리된 표현 학습
- 적응 단계에서 소스 데이터 없이 $$z_y$$만 활용한 전이

이는 데이터 프라이버시와 저장 제약이 있는 실제 응용에 적합[15]

**② 확산 모델 기반 분리(Diffusion-based Disentanglement)**

확산 모델을 DRL에 적용하는 최신 연구는 동적 가우시안 앵커링(DGA)을 통해 잠재 단위에 클러스터 구조와 결정 경계를 명시적으로 부여합니다. DSR에 확산 모델 통합 시:[17]
- 더 강건한 잠재 표현 학습
- 노이즈 제거 과정에서 분리된 특징 의존성 강화

**③ 다중 레벨 분리(Multi-level Disentanglement)**

ChameleonRS(2025)는 도메인 불변 특징과 도메인 특화 특징을 적응적으로 결합하는 타겟 강화 모듈(TEM)을 제안합니다. DSR 확장 방향:[18]
- 도메인 특화 정보($$z_d$$)를 완전히 폐기하지 않고 목표 도메인 특화 학습에 선택적 활용
- 다단계 특징 융합 전략 개발

**④ 대규모 데이터셋으로의 확장**

현재 분리 표현 학습은 생성 모델의 한계로 대규모 데이터셋에 확장하기 어렵습니다. 대조 학습(contrastive learning)과 DSR 통합:[19]
- VAE 대신 대조 학습 기반 인코더 사용
- SimCLR, MoCo 등과 결합한 분리 정규화

**⑤ 인과 구조 명시적 모델링**

ICRL, CIRL 등 인과 표현 학습 연구는 구조적 인과 모델(SCM)을 명시적으로 활용합니다. DSR 개선 방향:[4][3]
- $$z_y$$와 $$z_d$$ 간 인과 그래프 구축
- 인과 개입을 통한 반사실적(counterfactual) 데이터 생성
- 도메인 변화에 강건한 인과 메커니즘 학습

**⑥ 그래프 기반 분리(Graph-based Disentanglement)**

GEM(2024)은 계층적 잠재 그래프를 통해 속성 간 논리적 관계를 모델링합니다. DSR에 그래프 구조 통합:[20]
- 의미 속성 간 관계를 그래프로 표현
- 도메인 속성과 의미 속성의 상호작용 명시적 모델링

**⑦ 의료 영상 및 실시간 응용**

의료 영상 도메인 적응(2022)에서 DSR 원리 적용:[21]
- 다양한 스캐너/프로토콜에서 발생하는 도메인 시프트 해결
- 환자 프라이버시 보호를 위한 소스 프리 설정 결합
- 실시간 진단 시스템에서의 효율적 적응

### 7.2 연구 시 고려할 핵심 사항

**① 평가 지표 표준화**

분리 품질 측정을 위한 표준화된 지표(MIG, SAP, DCI 등) 사용 및 도메인 적응 성능과의 상관관계 명확화[22][23]

**② 해석 가능성과 성능 균형**

완전한 분리가 항상 최상의 다운스트림 성능을 보장하지 않으며, 응용에 따라 적절한 분리 수준 결정 필요[24][17]

**③ 귀납적 편향 설계**

데이터 특성에 맞는 귀납적 편향 설계(예: 이미지는 공간 구조, 시계열은 시간 의존성)[25][11]

**④ 합성-실제 데이터 전이**

합성 데이터에서 학습한 분리 표현을 실제 데이터로 전이하는 전략 연구[26][27]

**⑤ 다중 작업 학습(Multi-task Learning)**

분류, 세그멘테이션, 검출 등 여러 작업에서 분리된 표현의 전이 가능성 평가[28]

**⑥ 윤리적 고려사항**

편향(bias) 제거와 공정성(fairness) 측면에서 분리 표현 학습의 역할 및 한계 연구[25]

***

## 결론

본 논문의 DSR 모델은 도메인 적응 분야에 **분리된 잠재 표현 학습**이라는 새로운 패러다임을 제시하며, 이론적 근거와 실험적 검증을 통해 그 유효성을 입증했습니다. 특히 의미론적 정보와 도메인 정보를 명시적으로 분리함으로써 거짓 정렬 문제를 해결하고 목표 도메인 일반화 성능을 향상시켰습니다.[1]

**향후 연구에 미치는 영향**: DSR의 핵심 아이디어는 이후 소스 프리 도메인 적응, 인과 표현 학습, 프롬프트 기반 분리, 확산 모델 기반 분리 등 다양한 후속 연구에 영향을 미치고 있습니다. 특히 명시적 표현 공간 분해, 최소 충분 의미 표현, 독립 인과 관계 학습 등은 DSR의 이론적 기초를 더욱 발전시키고 있습니다.[7][2][5][3][6][4][17][15]

**실무적 시사점**: 의료 영상 분석, 시계열 센서 데이터, 의미론적 세그멘테이션 등 실제 응용에서 도메인 시프트 문제 해결을 위한 강력한 도구로 자리잡고 있으며, 데이터 프라이버시와 계산 효율성을 고려한 소스 프리 설정으로의 확장이 활발히 진행되고 있습니다 활발히 진행되고 있습니다.[44][10][13][19][46][39]

[1](https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/65988149/27e6087a-7dc3-4cd6-a674-7fc047eb1ee1/2012.11807v1.pdf)
[2](https://arxiv.org/html/2507.20968v3)
[3](https://www.nature.com/articles/s41598-025-96357-0)
[4](https://openaccess.thecvf.com/content/CVPR2022/papers/Lv_Causality_Inspired_Representation_Learning_for_Domain_Generalization_CVPR_2022_paper.pdf)
[5](https://arxiv.org/html/2509.15791v2)
[6](https://cvpr.thecvf.com/virtual/2024/poster/29375)
[7](https://arxiv.org/abs/2507.02288)
[8](https://arxiv.org/html/2404.13848v1)
[9](https://arxiv.org/html/2502.06272v1)
[10](https://arxiv.org/abs/2405.00749)
[11](https://arxiv.org/pdf/1811.12359.pdf)
[12](https://arxiv.org/pdf/2311.01686.pdf)
[13](https://arxiv.org/abs/2311.01686)
[14](https://arxiv.org/html/2204.02283v2)
[15](https://www.sciencedirect.com/science/article/abs/pii/S0925231223010445)
[16](https://openaccess.thecvf.com/content/CVPR2024/papers/Mitsuzumi_Understanding_and_Improving_Source-free_Domain_Adaptation_from_a_Theoretical_Perspective_CVPR_2024_paper.pdf)
[17](https://www.emergentmind.com/topics/disentangled-representation-learning-drl)
[18](https://www.sciencedirect.com/science/article/abs/pii/S0952197625010292)
[19](http://arxiv.org/pdf/2108.06613.pdf)
[20](https://proceedings.neurips.cc/paper_files/paper/2024/file/bac4d92b3f6decfe47eab9a5893dd1f6-Paper-Conference.pdf)
[21](https://pmc.ncbi.nlm.nih.gov/articles/PMC9011180/)
[22](https://www.mdpi.com/1424-8220/23/4/2362)
[23](https://pmc.ncbi.nlm.nih.gov/articles/PMC8578601/)
[24](https://papers.neurips.cc/paper_files/paper/2022/file/9f9ecbf4062842df17ec3f4ea3ad7f54-Paper-Conference.pdf)
[25](https://mcml.ai/publications/uer+24/)
[26](https://arxiv.org/html/2409.18017)
[27](https://nips.cc/virtual/2024/poster/95810)
[28](https://www.ijcai.org/proceedings/2024/424)
[29](http://arxiv.org/pdf/1805.08019.pdf)
[30](http://arxiv.org/pdf/2106.11915.pdf)
[31](https://arxiv.org/pdf/1809.01361.pdf)
[32](http://arxiv.org/pdf/2106.13292.pdf)
[33](http://arxiv.org/pdf/2201.01929.pdf)
[34](http://arxiv.org/pdf/1707.08475.pdf)
[35](https://openaccess.thecvf.com/content/CVPR2022/papers/Zhang_Towards_Principled_Disentanglement_for_Domain_Generalization_CVPR_2022_paper.pdf)
[36](https://www.sciencedirect.com/science/article/abs/pii/S0951832025002005)
[37](https://openreview.net/forum?id=552tedTByb)
[38](https://proceedings.neurips.cc/paper/2021/file/cfc5d9422f0c8f8ad796711102dbe32b-Paper.pdf)
[39](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/08861.pdf)
[40](https://arxiv.org/html/2510.14049v1)
[41](http://ieeexplore.ieee.org/document/10535904/)
[42](https://www.sciencedirect.com/science/article/abs/pii/S0893608025006379)
[43](https://dl.acm.org/doi/10.1145/3581783.3611725)
[44](https://dl.acm.org/doi/10.1016/j.engappai.2025.111029)
[45](https://ieeexplore.ieee.org/document/10684792/)
[46](https://arxiv.org/pdf/2209.05336.pdf)
[47](http://arxiv.org/pdf/2212.07699.pdf)
[48](https://arxiv.org/abs/2111.13839)
[49](https://mn.cs.tsinghua.edu.cn/xinwang/PDF/papers/2024_Disentangled%20Representation%20Learning.pdf)
[50](https://ieeexplore.ieee.org/document/10017290/)
[51](https://openreview.net/forum?id=hiwHaqFXGi)
[52](https://dl.acm.org/doi/10.1016/j.neunet.2024.106230)
[53](https://ieeexplore.ieee.org/document/10637999/)
[54](https://www.sciencedirect.com/science/article/pii/S0925231223010445)
