# DeepONet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators

**핵심 아이디어**  
DeepONet은 “함수”가 아닌 “함수를 다른 함수로 바꾸는 연산자(operator)”를 학습하는 특별한 신경망 구조입니다.  
- 예를 들어, 입력 함수 $$u(x)$$가 주어지면 DeepONet은 그 함수에 대한 어떤 출력 함수 $$G(u)(y)$$를 예측합니다.  
- 여기서 $$G$$는 우리가 배우려는 연산자이고, $$G(u)$$는 입력 함수 $$u$$를 연산자 $$G$$에 통과시켜 얻은 결과 함수입니다.

## 1. 왜 DeepONet이 필요한가?  
기존의 완전연결망(Fully Connected Network, FNN)은 함수→함수(함수 연산자) 학습에 한계가 있습니다.  
- FNN은 일반적인 함수 근사에 강하지만, 입력 전체 함수의 정보를 잡아내고 출력 함수 전체를 예측하는 데는 비효율적이며 **일반화 오류**(unseen 데이터에 대한 오차)가 큽니다.  
- DeepONet은 **연산자 만능근사 정리**(operator universal approximation theorem)에 영감을 받아, “입력 함수”와 “출력 위치”를 따로 처리해 이 문제를 해결합니다.

## 2. DeepONet 구조

```
입력: 
 1) 함수 u의 값 [u(x₁),…,u(xₘ)]  ← Branch Net(분기망)
 2) 출력 함수 평가 위치 y       ← Trunk Net(흉상망)
```

1. **Branch Net (분기망)**  
   - 역할: 입력 함수 $$u$$를 센서(sensor) 위치 $$x_1, …, x_m$$에서 샘플한 값들을 벡터로 받아 압축된 특징(feature) 벡터 $$b(u)\in\mathbb{R}^p$$로 변환합니다.  
   - 비유: 여러 센서로 측정된 온도·습도 값을 받아 “기후 지표” 몇 가지로 요약하는 과정과 유사합니다.

2. **Trunk Net (흉상망)**  
   - 역할: 우리가 출력 함수 값을 알고 싶은 지점 $$y$$를 받아, 출력 함수의 위치별 기여도 벡터 $$t(y)\in\mathbb{R}^p$$를 계산합니다.  
   - 비유: 특정 장소에 대한 날씨 예측 가중치를 계산하는 과정과 유사합니다.

3. **결합 & 출력**  

$$
     G(u)(y)\approx \sum_{k=1}^p b_k(u)t_k(y)+b_0,
   $$
   
   - Branch Net 출력 $$b_k(u)$$와 Trunk Net 출력 $$t_k(y)$$를 내적(inner product)해 최종 예측을 만듭니다.  
   - $$b_0$$는 추가 바이어스(bias) 항으로, 예측의 기본값을 조정합니다.

## 3. 중요한 개념 정리

1. **연산자(operator)**  
   - 함수 $$u$$를 다른 함수 $$G(u)$$로 바꾸는 ‘함수의 함수’입니다.  
   - 예: 미분 연산자 $$D$$는 $$u(x)$$를 $$u'(x)$$로 바꿉니다. DeepONet은 이처럼 복잡한 비선형 연산자까지 학습합니다.

2. **일반화 오류(generalization error)**  
   - 학습(훈련) 데이터가 아닌 새로운 데이터에 대한 예측 오차입니다.  
   - DeepONet은 구조적 편향(inductive bias)을 통해 일반화 오류를 줄여, 훈련에서 보지 못한 입력 함수에도 높은 정확도를 보입니다.

3. **만능근사 정리(universal approximation theorem)**  
   - 충분히 큰 신경망은 어떤 연속 함수(혹은 연산자)든 임의의 정확도로 근사할 수 있다는 이론입니다.  
   - DeepONet은 이 정리를 실제 모델로 구현해, 함수 공간→함수 공간까지 확대 적용합니다.

4. **지수/다항 수렴(exponential/polynomial convergence)**  
   - 학습 데이터 개수나 센서 수 등을 늘릴 때 오차가 얼마나 빠르게 줄어드는지를 나타냅니다.  
   - DeepONet은 사전 실험에서 작은 데이터만으로도 지수적으로 오차가 줄어드는 현상을 관찰했습니다.

## 4. DeepONet의 장점과 한계

### 장점  
- **효율적 일반화**: Branch/Trunk 분리 구조로 복잡한 함수 관계를 잘 포착해 보지 못한 데이터에도 강함.  
- **이론적 보장**: 센서 수, 네트워크 크기와 오차 관계를 수식으로 분석해 설계 기준 제공.  
- **빠른 수렴**: 작은 데이터셋에서도 지수적·고차 다항 수렴 관찰.

### 한계 및 개선 방향  
- **서브넷 아키텍처**: 현재는 간단한 완전연결망(FNN)만 사용. CNN, Attention 적용 연구 필요.  
- **고차원 확장**: 센서 위치 불규칙·고차원 도메인에서의 성능 검증이 더 필요.  
- **최적화·일반화 이론**: 왜 최적화 오류와 일반화 오류가 작게 유지되는지 이론적 해석 보강 필요.

## 5. 결론 및 앞으로 연구할 점

DeepONet은 입력 함수 정보를 구조적으로 분리해 처리함으로써, 기존 신경망보다 **연산자 학습**에서 훨씬 뛰어난 일반화 성능을 보입니다.  
앞으로는 CNN·Transformer와 같은 다양한 서브넷 적용, 고차원 도메인 확장, 최적화·일반화 이론 개발 등을 통해 DeepONet의 적용 범위와 이론적 기반을 더욱 강화할 수 있습니다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/232e8c71-d7b9-4523-9abe-a0080de96e69/1910.03193v3.pdf

**핵심 주장:**  
신경망은 단일 은닉층만으로도 비선형 연산자(함수공간→함수공간)를 임의 정확도로 근사할 수 있다는 연산자 만능 근사 정리를 실제로 구현한 네트워크 구조인 DeepONet을 제안한다.  

**주요 기여:**  
1. **연산자 학습 위한 구조 제안**  
   -  입력 함수 $$u$$의 센서 값 $$[u(x_1),\dots,u(x_m)]$$을 처리하는 **Branch Net**과, 출력 함수 평가 위치 $$y$$를 처리하는 **Trunk Net**의 두 서브넷을 결합한 **DeepONet** 아키텍처 도입.  
2. **이론적 분석**  
   -  센서 개수 $$m$$와 함수 공간 복잡도가 연산자 근사 오차에 미치는 영향을 정량적으로 분석(Theorem 2).  
3. **일반화 성능 개선**  
   -  Fully-connected Network 대비 일반화 오차가 현저히 작음을 수치 실험으로 입증(ODE, PDE 4개 사례).  
4. **고차 및 지수 수렴 관찰**  
   -  데이터셋 크기에 따라 반차수∼4차수 다항 수렴 및 소규모 영역에서 지수 수렴을 실험적으로 확인.  

## 1. 해결하고자 하는 문제  
- 함수가 아니라 **연산자** $$G: u\mapsto G(u)$$ (함수→함수)를 데이터 기반으로 학습하는 문제.  
- 기존 완전연결망(FNN)은 충분히 큰 네트워크에도 최적화·일반화 오차가 커 실용성 한계.  

## 2. 제안 방법  
### 2.1. 기본 아이디어 및 수식  
- 연산자 출력 $$G(u)(y)$$를 네트워크로 근사:  

$$
    G(u)(y) \approx \sum_{k=1}^p b_k(u)\,t_k(y) + b_0,
  $$

  여기서  
  -  $$b(u)=[b_1,\dots,b_p]$$는 Branch Net의 출력,  
  -  $$t(y)=[t_1,\dots,t_p]$$는 Trunk Net의 출력,  
  -  $$b_0$$는 마지막 바이어스.  

### 2.2. 네트워크 구조  
- **Branch Net**: 입력 $$[u(x_1),\dots,u(x_m)]$$ → 은닉층 → $$p$$차원 출력  
- **Trunk Net**: 입력 $$y\in\mathbb{R}^d$$ → 은닉층 → $$p$$차원 출력  
- **Unstacked DeepONet**(선택적 바이어스 포함): Branch/Trunk 단일 복합 구조로 메모리·계산 효율성 제고  

## 3. 성능 향상  
- **일반화 오차 감소**  
  - 선형 적분 연산자(antiderivative) 학습 실험에서 FNN 대비 테스트 MSE가 수백 배 개선.  
  - 비선형 ODE, 중력 진자, 확산-반응 PDE 등 다양한 사례에서 Branch/Trunk 분리 구조가 일반화 오차를 크게 줄임.  
- **수렴 속도**  
  - 데이터셋 크기 $$N$$에 대해 초기 영역에서 $$O(e^{-cN})$$ 지수 수렴, 이후 $$O(N^{-p})$$ 다항 수렴 관찰.  
- **센서 개수 분석**  
  - 센서 수 $$m$$가 적으면 오차가 $$\sim\alpha^{-m}$$ 지수적으로 감소, 이후 포화.  
  - 입력 함수 복잡도(길이스케일 $$l$$ inversely proportional to $$m$$) 및 예측 시간 $$T$$와 센서 수 관계 이론/실험 일치.  

## 4. 한계  
- **네트워크 크기·구조 최적화 부재**: 본 연구는 Sub-net에 FNN만 사용. CNN, Attention 등 미적용.  
- **이론적 일반화 보장 부족**: approximation error는 분석했으나 optimization/generalization error에 대한 이론적 해석 미흡.  
- **고차원 및 복잡 도메인에서의 확장성**: 고차원 출력 도메인, 불규칙 센서 배치에 대한 실험·이론 추가 필요.  

## 5. 일반화 성능 향상 관점  
- **인덕티브 바이어스** 부여: $$u$$와 $$y$$를 분리 처리함으로써 연산자의 조건부 함수 형태를 구조에 반영→과적합 억제.  
- **바이어스 추가 효과**: Branch Net 마지막 레이어와 최종 합산 단계에 바이어스를 추가하면 일반화 오차가 추가로 감소.  
- **Unstacked vs Stacked**: Unstacked 구성이 파라미터 수는 줄이면서 일반화 오차도 더 낮춤.  

## 6. 향후 연구 및 고려사항  
- **다양한 Sub-net 아키텍처 실험**: CNN, Transformer 기반 Trunk/Branch 적용으로 공간적·순차적 구조 활용 강화.  
- **일반화 이론 개발**: 최적화·일반화 오차를 수식으로 정량화하는 학습 이론 구축.  
- **고차원·비격자 도메인 확장**: 불규칙 센서, 고차원 출력 함수 학습 성능 검증 및 최적화.  
- **연산자 근사 한계 분석**: 심층·저폭 네트워크의 연산자 근사 능력 이론적 경계 연구.  

**결론:** DeepONet은 연산자 학습에 특화된 구조적 인덕티브 바이어스를 통해 기존 FNN 대비 일반화 성능을 획기적으로 개선하였으며, 향후 다양한 네트워크 아키텍처 및 일반화 이론 연구에 큰 기반을 제공한다.

[1] https://ppl-ai-file-upload.s3.amazonaws.com/web/direct-files/attachments/22370781/232e8c71-d7b9-4523-9abe-a0080de96e69/1910.03193v3.pdf
